{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3386c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613aa76",
   "metadata": {},
   "source": [
    "## System Description\n",
    "1. We have a set of COFs from a database. Each COF is characterized by a feature vector $$x_{COF} \\in X \\subset R^d$$ were d=14.\n",
    "\n",
    "\n",
    "2. We have **two different types** of simulations to calculate **the same material property $S_{Xe/Kr}$**. Therefore, we have a Single-Task/Objective (find the material with the optimal selevtivity), Multi-Fidelity problem. \n",
    "    1. low-fidelity  = Henry coefficient calculation - MC integration \n",
    "    2. high-fidelity = GCMC mixture simulation - 80:20 (Kr:Xe) at 298 K and 1.0 bar \n",
    "\n",
    "\n",
    "3. We will initialize the system with a few COFs at **both** fidelities in order to initialize the Covariance Matrix.\n",
    "    1. The fist COF will be the one closest to the center of the normalized feature space\n",
    "    2. The rest will be chosen to maximize diversity of the training set\n",
    "\n",
    "\n",
    "4. Each surrogate model will **only train on data acquired at its level of fidelity** (Heterotopic data). $$X_{lf} \\neq X_{hf} \\subset X$$\n",
    "    1. We could use the augmented EI acquisition function from [here](https://link.springer.com/content/pdf/10.1007/s00158-005-0587-0.pdf)\n",
    "    2. We could use a naive implementation of the [misoKG](https://papers.nips.cc/paper/2017/file/df1f1d20ee86704251795841e6a9405a-Paper.pdf) acquisition function\n",
    "    3. Helpful [tutorial](https://botorch.org/tutorials/discrete_multi_fidelity_bo)\n",
    "\n",
    "\n",
    "5. **kernel model**: \n",
    "    1.  We need a Gaussian Process (GP) that will give a *correlated output for each fidelity* i.e. we need a vector-valued kernel\n",
    "    2. Given the *cost aware* acquisition function, we anticipate the number of training points at each fidelity *will not* be equal (asymmetric scenario) $$n_{lf} > n_{hf}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7679eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from botorch.models import SingleTaskMultiFidelityGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch import fit_gpytorch_model\n",
    "from scipy.stats import norm\n",
    "from sklearn.decomposition import PCA\n",
    "import math \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "# config plot settings\n",
    "plt.rcParams[\"font.size\"] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa4fc540",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  attempting to fix Cholecky jitter error\n",
    "###\n",
    "from botorch.optim.fit import fit_gpytorch_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa45b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data - \n",
      "\tX: torch.Size([608, 14])\n",
      "\tfidelity: 0\n",
      "\t\ty: torch.Size([608])\n",
      "\t\tcost:  torch.Size([608])\n",
      "\tfidelity: 1\n",
      "\t\ty: torch.Size([608])\n",
      "\t\tcost:  torch.Size([608])\n",
      "\n",
      "Ensure features are normalized - \n",
      "max:\n",
      " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       dtype=torch.float64)\n",
      "min:\n",
      " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  Load Data\n",
    "###\n",
    "file = h5py.File(\"targets_and_normalized_features.jld2\", \"r\")\n",
    "# feature matrix\n",
    "X = torch.from_numpy(np.transpose(file[\"X\"][:]))\n",
    "# simulation data\n",
    "y = [torch.from_numpy(np.transpose(file[\"henry_y\"][:])), \n",
    "     torch.from_numpy(np.transpose(file[\"gcmc_y\"][:]))]\n",
    "# associated simulation costs\n",
    "cost = [torch.from_numpy(np.transpose(file[\"henry_total_elapsed_time\"][:])), \n",
    "        torch.from_numpy(np.transpose(file[\"gcmc_elapsed_time\"][:]))]\n",
    "\n",
    "# total number of COFs in data set\n",
    "nb_COFs = X.shape[0] \n",
    "\n",
    "print(\"raw data - \\n\\tX:\", X.shape)\n",
    "for f in range(2):\n",
    "    print(\"\\tfidelity:\", f)\n",
    "    print(\"\\t\\ty:\", y[f].shape)\n",
    "    print(\"\\t\\tcost: \", cost[f].shape)\n",
    "    \n",
    "    \n",
    "print(\"\\nEnsure features are normalized - \")\n",
    "print(\"max:\\n\", torch.max(X, 0).values)\n",
    "print(\"min:\\n\", torch.min(X, 0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99796cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average high-fidelity cost: 230.0783918372241 [min]\n",
      "average low-fidelity cost:  16.57287046034216 [min]\n",
      "average cost ratio:\t    13.444745568580501\n"
     ]
    }
   ],
   "source": [
    "print(\"average high-fidelity cost:\", torch.mean(cost[1]).item(), \"[min]\")\n",
    "print(\"average low-fidelity cost: \", torch.mean(cost[0]).item(), \"[min]\")\n",
    "print(\"average cost ratio:\\t   \", torch.mean(cost[1] / cost[0]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d14a9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10076.3052, dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_lf_cost = sum(cost[0])\n",
    "total_lf_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c5e4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(139887.6622, dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_hf_cost = sum(cost[1])\n",
    "total_hf_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f84bd4",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "#### Construct Initial Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9389e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find COF closest to the center of feature space\n",
    "def get_initializing_COF(X):\n",
    "    # center of feature space\n",
    "    feature_center = np.ones(X.shape[1]) * 0.5\n",
    "    # max possible distance between normalized features\n",
    "    return np.argmin(np.linalg.norm(X - feature_center, axis=1))\n",
    "\n",
    "def diverse_set(X, train_size):\n",
    "    # initialize with one random point; pick others in a max diverse fashion\n",
    "    ids_train = [get_initializing_COF(X)]\n",
    "    # select remaining training points\n",
    "    for j in range(train_size - 1):\n",
    "        # for each point in data set, compute its min dist to training set\n",
    "        dist_to_train_set = np.linalg.norm(X - X[ids_train, None, :], axis=2)\n",
    "        assert np.shape(dist_to_train_set) == (len(ids_train), nb_COFs)\n",
    "        min_dist_to_a_training_pt = np.min(dist_to_train_set, axis=0)\n",
    "        assert np.size(min_dist_to_a_training_pt) == nb_COFs\n",
    "        \n",
    "        # acquire point with max(min distance to train set) i.e. Furthest from train set\n",
    "        ids_train.append(np.argmax(min_dist_to_a_training_pt))\n",
    "    assert np.size(np.unique(ids_train)) == train_size # must be unique\n",
    "    return np.array(ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e61b6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct feature matrix of acquired points\n",
    "def build_X_train(acquired_set):\n",
    "    ids_acq = [j[0] for j in acquired_set]\n",
    "    fid_acq = torch.tensor([j[1] for j in acquired_set])\n",
    "    return torch.cat((X[ids_acq, :], fid_acq.unsqueeze(dim=-1)), dim=1)\n",
    "\n",
    "# construct output vector for acquired points\n",
    "def build_y_train(acquired_set):\n",
    "    for i, [cof_id, f_id] in enumerate(acquired_set):\n",
    "        y_t = y[f_id][cof_id].unsqueeze(-1)\n",
    "        if i == 0:\n",
    "            y_train = y_t # nitialize\n",
    "        else:\n",
    "            y_train = torch.cat((y_train, y_t))\n",
    "    return y_train.unsqueeze(-1)\n",
    "\n",
    "# construct vector to track accumulated cost of acquired points\n",
    "def build_cost(acquired_set):\n",
    "    for i, [cof_id, f_id] in enumerate(acquired_set):\n",
    "        c = torch.ones((1, 1), dtype=float) * cost[f_id][cof_id]\n",
    "        if i == 0:\n",
    "            costs_acquired = c # initialize\n",
    "        else:\n",
    "            costs_acquired = torch.cat((costs_acquired, c))\n",
    "            \n",
    "    return costs_acquired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "156b7a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_initializing_functions(X, y):\n",
    "#     # number of COFs to initialize with at each fidelity\n",
    "#     nb_COFs_initialization = 3\n",
    "#     # select COFs to train initial GP\n",
    "#     initializing_COFs = torch.from_numpy(np.array([1, 3, 4]))\n",
    "#     # track COFs acquired\n",
    "#     ids_acquired = torch.from_numpy(np.array([1, 3, 4]))\n",
    "#     print(\"Test -\\n\\tids acquired\", ids_acquired)\n",
    "#     # track the fidelity at which COFs are acquired\n",
    "#     fidelity_acquired = torch.from_numpy(np.array([1, 0, 0]))\n",
    "#     print(\"\\tfidelity acquired\", fidelity_acquired)\n",
    "#     # construct training sets\n",
    "#     X_train = build_X_train(ids_acquired, fidelity_acquired)\n",
    "#     y_train = build_y_train(ids_acquired, fidelity_acquired)\n",
    "#     # Test that the constructor functions are working properly\n",
    "#     assert np.allclose(X[1, :], X_train[0, :14])\n",
    "#     assert X_train[0, 14] == 1\n",
    "#     assert X_train[1, 14] == 0\n",
    "#     assert y_train[0] == y[0]\n",
    "#     return\n",
    "\n",
    "# test_initializing_functions(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d57717a",
   "metadata": {},
   "source": [
    "#### Surrogate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73c5e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_surrogate_model(X_train, y_train):\n",
    "    model = SingleTaskMultiFidelityGP(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        outcome_transform=Standardize(m=1), # m is the output dimension\n",
    "        data_fidelity=X_train.shape[1] - 1\n",
    "    )   \n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_model(mll, optimizer=fit_gpytorch_torch)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce88b3c",
   "metadata": {},
   "source": [
    "#### Acquisition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70bb7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate posterior mean and variance\n",
    "def mu_sigma(model, X, fidelity):\n",
    "    f = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) * fidelity\n",
    "    X_f = torch.cat((X, f), dim=1) # last col is associated fidelity\n",
    "    f_posterior = model.posterior(X_f)\n",
    "    return f_posterior.mean.squeeze().detach().numpy(), f_posterior.variance.squeeze().detach().numpy()\n",
    "\n",
    "# get the current \"effective best solution\"\n",
    "def get_y_max(acquired_set, desired_fidelity):\n",
    "    y_max = 0\n",
    "    for i, [cof_id, f_id] in enumerate(acquired_set):\n",
    "        if (f_id == desired_fidelity) & (y[f_id][cof_id].item() > y_max):\n",
    "            y_max = y[f_id][cof_id].item()\n",
    "    return y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "260b3f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.size()\n",
    "# model = train_surrogate_model(X_train, y_train)\n",
    "\n",
    "# model.covar_module\n",
    "\n",
    "# model.covar_module.base_kernel.power\n",
    "\n",
    "# model.covar_module.base_kernel.covar_module_biased.lengthscale = torch.rand(14)\n",
    "\n",
    "# model.covar_module.base_kernel.covar_module_unbiased.lengthscale\n",
    "\n",
    "# model.covar_module.base_kernel.covar_module_unbiased.distance_module.parameters\n",
    "\n",
    "# model.covar_module.base_kernel.covar_module_unbiased.p\n",
    "\n",
    "# model.covar_module.outputscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e69d1b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# efficient multi-fidelity correlation function\n",
    "###\n",
    "def mfbo_correlation_function(model, X, fidelity, acquired_set):\n",
    "    # given fidelity\n",
    "    f   = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) * fidelity\n",
    "    X_f = torch.cat((X, f), dim=1) # last col is associated fidelity\n",
    "    \n",
    "    #  high-fidelity\n",
    "    hf   = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) \n",
    "    X_hf = torch.cat((X, hf), dim=1) # last col is associated fidelity\n",
    "\n",
    "    # combine into a single tensor\n",
    "    X_all_fid = torch.cat((X_f, X_hf), dim=0)\n",
    "    \n",
    "    # get variance for each fidelity\n",
    "    var_f = torch.flatten(model.posterior(X_f).variance)\n",
    "    var_hf = torch.flatten(model.posterior(X_hf).variance) # variance\n",
    "    \n",
    "    # posterior covariance \n",
    "    cov = torch.diag(model(X_all_fid).covariance_matrix[:X_f.size()[0], X_f.size()[0]:])\n",
    "    \n",
    "    corr = cov / (torch.sqrt(var_f) * torch.sqrt(var_hf))\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76500045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "124d3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  Multi-fideltiy correlation \n",
    "#  corr[] = k - k_1K^{-1}k_0\n",
    "###\n",
    "def multi_fidelity_correlation(model, X, fidelity, acquired_set):\n",
    "    # get covariance matrix of acquired data points\n",
    "    sigma_yy  = model.covar_module(X_train).evaluate() \n",
    "    sigma_yy_inv = torch.inverse(sigma_yy) # take the inverse\n",
    "\n",
    "    # get posterior for fidelity f\n",
    "    f   = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) * fidelity\n",
    "    X_f = torch.cat((X, f), dim=1) # last col is associated fidelity\n",
    "    var_f = torch.flatten(model.posterior(X_f).variance)\n",
    "\n",
    "    # get posterior for high-fidelity\n",
    "    hf = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) \n",
    "    X_hf = torch.cat((X, hf), dim=1) # last col is associated fidelity\n",
    "    var_hf = torch.flatten(model.posterior(X_hf).variance)\n",
    "\n",
    "    # Compute the covariance between X_hf and X_f, using covariance kernel\n",
    "    sigma_xx = model.covar_module.forward(X_hf, X_f, diag=True) # want diag\n",
    "\n",
    "    # Compute the covariance between X_f and X_train \n",
    "    # rows are [k(x,s), (x_1, s_1), ..., k((x, s), (x_N, s_N))]\n",
    "    cov_f_and_data = model.covar_module.forward(X_f, X_train).evaluate()\n",
    "\n",
    "    # Compute the covariance between X_hf and X_train\n",
    "    # rows are [k(x,s'), (x_1, s_1), ..., k((x, s'), (x_N, s_N))]\n",
    "    cov_hf_and_data = model.covar_module.forward(X_hf, X_train).evaluate()\n",
    "\n",
    "    # perform matrix multiplication: k_f * K_inv * k_hf\n",
    "    sigma_reduction = torch.matmul(torch.matmul(cov_f_and_data, sigma_yy_inv), \n",
    "                       torch.t(cov_hf_and_data)).diag()\n",
    "    # calculate covariance\n",
    "    posterior_cov = sigma_xx - sigma_reduction\n",
    "    # calculate the correlation\n",
    "    corr = posterior_cov / (torch.sqrt(var_f) * torch.sqrt(var_hf))\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40fec2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85e47050",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  Cost ratio\n",
    "###\n",
    "def cost_ratio(fidelity, acquired_set, costs_acquired):\n",
    "    # get fidelities from acquired set\n",
    "    f_acq = torch.tensor([acq_[1].item() for acq_ in acquired_set])\n",
    "    \n",
    "    avg_cost_f  = torch.mean(costs_acquired[f_acq == fidelity]).item()\n",
    "    avg_cost_hf = torch.mean(costs_acquired[f_acq == 1]).item()\n",
    "    return avg_cost_hf / avg_cost_f\n",
    "\n",
    "###\n",
    "#  Expected Imrovement function, only uses hf\n",
    "###\n",
    "def EI_hf(model, X, acquired_set):\n",
    "    hf_mu, hf_sigma = mu_sigma(model, X, 1)\n",
    "    y_max = get_y_max(acquired_set, 1)\n",
    "    \n",
    "    z = (hf_mu - y_max) / hf_sigma\n",
    "    explore_term = hf_sigma * norm.pdf(z) \n",
    "    exploit_term = (hf_mu - y_max) * norm.cdf(z) \n",
    "    ei = explore_term + exploit_term\n",
    "    return np.maximum(ei, np.zeros(nb_COFs))\n",
    "\n",
    "###\n",
    "#  Acquisition function\n",
    "###\n",
    "def acquisition(model, X, fidelity, acquired_set, costs_acquired):\n",
    "    # expected improvement for high-fidelity\n",
    "    ei = EI_hf(model, X, acquired_set) \n",
    "    \n",
    "    # augmenting functions\n",
    "#     a1 = multi_fidelity_correlation(model, X, fidelity, acquired_set)\n",
    "    a1 = mfbo_correlation_function(model, X, fidelity, acquired_set)\n",
    "    \n",
    "    a2 = 1.0 # no systematic random error noise \n",
    "    a3 = cost_ratio(fidelity, acquired_set, costs_acquired)\n",
    "\n",
    "    acquisition_values = torch.from_numpy(ei) * a1 * a2 * a3\n",
    "    return acquisition_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd075cf",
   "metadata": {},
   "source": [
    "# Run MFBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eadc1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_initial_inputs(X, y, nb_COFs_initialization, discrete_fidelities):\n",
    "    initializing_COFs = diverse_set(X, nb_COFs_initialization)\n",
    "    init_flag = True \n",
    "    for i, cof_id in enumerate(initializing_COFs):\n",
    "        for j ,f_id in enumerate(discrete_fidelities):\n",
    "            acq_ = torch.tensor([[cof_id, f_id]], dtype=int)\n",
    "            if i == 0 and j == 0:\n",
    "                acquired_set = acq_ # initialize\n",
    "            else:\n",
    "                acquired_set = torch.cat((acquired_set, acq_))\n",
    "            \n",
    "    costs_acquired = build_cost(acquired_set)\n",
    "    return acquired_set, costs_acquired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c09823b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization - \n",
      "\n",
      "\tid acquired =  [25, 25, 494, 494, 523, 523]\n",
      "\tfidelity acquired =  [0, 1, 0, 1, 0, 1]\n",
      "\tcosts acquired =  [ 33.25071268 399.7576661   33.2388743  171.99848711   6.12068812\n",
      " 280.45236813]  [min]\n",
      "\n",
      "\tTraining data:\n",
      "\n",
      "\t\t X train shape =  torch.Size([6, 15])\n",
      "\t\t y train shape =  torch.Size([6, 1])\n",
      "\t\t training feature vector = \n",
      " tensor([0.1500, 0.4533, 0.1088, 0.5523, 0.4387, 0.1463, 0.3480, 0.2643, 0.0000,\n",
      "        0.1769, 0.2237, 0.0000, 0.0000, 0.3471, 0.0000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  construct initial inputs\n",
    "###\n",
    "discrete_fidelities = [0, 1] # set of discrete fidelities to select from\n",
    "nb_COFs_initialization = 3   # at each fidelity, number of COFs to initialize with\n",
    "nb_iterations = 100          # BO budget, includes initializing COFs\n",
    "\n",
    "acquired_set, costs_acquired = construct_initial_inputs(X, y, nb_COFs_initialization, discrete_fidelities)\n",
    "\n",
    "X_train = build_X_train(acquired_set)\n",
    "y_train = build_y_train(acquired_set)\n",
    "\n",
    "print(\"Initialization - \\n\")\n",
    "print(\"\\tid acquired = \", [acq_[0].item() for acq_ in acquired_set])\n",
    "print(\"\\tfidelity acquired = \", [acq_[1].item() for acq_ in acquired_set])\n",
    "print(\"\\tcosts acquired = \", costs_acquired.squeeze().detach().numpy(), \" [min]\")\n",
    "\n",
    "print(\"\\n\\tTraining data:\\n\")\n",
    "print(\"\\t\\t X train shape = \", X_train.shape)\n",
    "print(\"\\t\\t y train shape = \", y_train.shape)\n",
    "print(\"\\t\\t training feature vector = \\n\", X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6393366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###\n",
    "# #  Comparison TEST of Correlation functions\n",
    "# ###\n",
    "\n",
    "# model = train_surrogate_model(X_train, y_train)\n",
    "\n",
    "# fidelity = 0\n",
    "\n",
    "# # given fidelity\n",
    "# f   = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) * fidelity\n",
    "# X_f = torch.cat((X, f), dim=1) # last col is associated fidelity\n",
    "\n",
    "# #  high-fidelity\n",
    "# hf = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) \n",
    "# X_hf = torch.cat((X, hf), dim=1) # last col is associated fidelity\n",
    "\n",
    "# # c\n",
    "# X_all_fid = torch.cat((X_f, X_hf), dim=0)\n",
    "\n",
    "# # calling model.forward() returns the prior \n",
    "# # prior = torch.diag(model.forward(X_all_fid).covariance_matrix[:X_f.size()[0], X_f.size()[0]:])\n",
    "\n",
    "# # calling model._call_() returns the posterior\n",
    "# # posterior = torch.diag(model(X_all_fid).covariance_matrix[:X_f.size()[0], X_f.size()[0]:])\n",
    "\n",
    "# # call old correlation function\n",
    "# c1 = multi_fidelity_correlation(model, X, fidelity, acquired_set)\n",
    "\n",
    "# # call new correlation function\n",
    "# c2 = mfbo_correlation_function(model, X, fidelity, acquired_set)\n",
    "\n",
    "# [np.isclose(c1[i].item(), c2[i].item()) for i in range(c1.size()[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aeffc73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10/100: 8.649342013940094\n",
      "Iter 20/100: 6.261137550553084\n",
      "Iter 30/100: 4.990258879375678\n",
      "Iter 40/100: 4.189199617403134\n",
      "Iter 50/100: 3.9705665875735296\n",
      "Iter 60/100: 3.861769073961766\n",
      "Iter 70/100: 3.8169358792521293\n",
      "Iter 80/100: 3.795750757562434\n",
      "Iter 90/100: 3.7861843682757677\n",
      "Iter 100/100: 3.7794894791133067\n",
      "Iter 10/100: 7.646945835678672\n",
      "Iter 20/100: 5.585887635634202\n",
      "Iter 30/100: 4.477827559087131\n",
      "Iter 40/100: 3.7812309804197684\n",
      "Iter 50/100: 3.594931828310967\n",
      "Iter 60/100: 3.505939425908695\n",
      "Iter 70/100: 3.467344259644532\n",
      "Iter 80/100: 3.449124945154929\n",
      "Iter 90/100: 3.440125417338264\n",
      "Iter 100/100: 3.433559934208628\n",
      "Iter 10/100: 6.899188107904619\n",
      "Iter 20/100: 5.0859008568795225\n",
      "Iter 30/100: 4.110207791298418\n",
      "Iter 40/100: 3.510394913486166\n",
      "Iter 50/100: 3.338797727939354\n",
      "Iter 60/100: 3.2593365749530165\n",
      "Iter 70/100: 3.225232648462293\n",
      "Iter 80/100: 3.209389231525344\n",
      "Iter 90/100: 3.2016902440879482\n",
      "Iter 100/100: 3.1962046505342934\n",
      "Iter 10/100: 6.293461790718118\n",
      "Iter 20/100: 4.672706263158172\n",
      "Iter 30/100: 3.7878215570103566\n",
      "Iter 40/100: 3.2130539295230616\n",
      "Iter 50/100: 3.081611642488335\n",
      "Iter 60/100: 3.0158486122309958\n",
      "Iter 70/100: 2.985165504647732\n",
      "Iter 80/100: 2.969413315093588\n",
      "Iter 90/100: 2.9602847754629202\n",
      "Iter 100/100: 2.9525550622607017\n",
      "Iter 10/100: 5.815299150447821\n",
      "Iter 20/100: 4.347585689820585\n",
      "Iter 30/100: 3.5381873296475206\n",
      "Iter 40/100: 3.001664938891368\n",
      "Iter 50/100: 2.8917471358211424\n",
      "Iter 60/100: 2.834927554647076\n",
      "Iter 70/100: 2.8072546228682924\n",
      "Iter 80/100: 2.792177069853898\n",
      "Iter 90/100: 2.782536440277773\n",
      "Iter 100/100: 2.773771335506633\n",
      "Iter 10/100: 5.426783267329235\n",
      "Iter 20/100: 4.08507741123639\n",
      "Iter 30/100: 3.3402816540355644\n",
      "Iter 40/100: 2.8435209815829223\n",
      "Iter 50/100: 2.746571850648533\n",
      "Iter 60/100: 2.6956576455817993\n",
      "Iter 70/100: 2.6701512123773488\n",
      "Iter 80/100: 2.6557882058416222\n",
      "Iter 90/100: 2.6462144711011573\n",
      "Iter 100/100: 2.63730994543667\n",
      "Iter 10/100: 5.103065050478288\n",
      "Iter 20/100: 3.8667351277365207\n",
      "Iter 30/100: 3.1755784006125567\n",
      "Iter 40/100: 2.700338341156151\n",
      "Iter 50/100: 2.6253743057466594\n",
      "Iter 60/100: 2.582792139359754\n",
      "Iter 70/100: 2.5604916741028494\n",
      "Iter 80/100: 2.5474575570298685\n",
      "Iter 90/100: 2.538418260065245\n",
      "Iter 100/100: 2.5298223774269792\n",
      "Iter 10/100: 4.826416935589524\n",
      "Iter 20/100: 3.678925496357616\n",
      "Iter 30/100: 3.0336437058895944\n",
      "Iter 40/100: 2.581575253691952\n",
      "Iter 50/100: 2.516255587206882\n",
      "Iter 60/100: 2.477907421380549\n",
      "Iter 70/100: 2.4568984311993893\n",
      "Iter 80/100: 2.4439413674694404\n",
      "Iter 90/100: 2.4343745255073204\n",
      "Iter 100/100: 2.4249842445019274\n",
      "Iter 10/100: 4.594815215029669\n",
      "Iter 20/100: 3.5241821224925536\n",
      "Iter 30/100: 2.9262235465921336\n",
      "Iter 40/100: 2.5039290412915425\n",
      "Iter 50/100: 2.4433132264186206\n",
      "Iter 60/100: 2.405473925792314\n",
      "Iter 70/100: 2.3853592054802326\n",
      "Iter 80/100: 2.3733444396648546\n",
      "Iter 90/100: 2.3644282891050077\n",
      "Iter 100/100: 2.35584338956782\n",
      "Iter 10/100: 4.393407564079548\n",
      "Iter 20/100: 3.3883331273924617\n",
      "Iter 30/100: 2.8308134773842246\n",
      "Iter 40/100: 2.4385243485991515\n",
      "Iter 50/100: 2.379872235641992\n",
      "Iter 60/100: 2.3400113190015674\n",
      "Iter 70/100: 2.3221255076024763\n",
      "Iter 80/100: 2.310285407917344\n",
      "Iter 90/100: 2.3022991378407096\n",
      "Iter 100/100: 2.2944538221467834\n",
      "Iter 10/100: 4.222690739632132\n",
      "Iter 20/100: 3.277585767461454\n",
      "Iter 30/100: 2.765876079958703\n",
      "Iter 40/100: 2.4592538766229035\n",
      "Iter 50/100: 2.345263458678417\n",
      "Iter 60/100: 2.3111945964145146\n",
      "Iter 70/100: 2.291454646192737\n",
      "Iter 80/100: 2.282778910690038\n",
      "Iter 90/100: 2.2762308315521835\n",
      "Iter 100/100: 2.2706849961034443\n",
      "Iter 10/100: 4.064400777942294\n",
      "Iter 20/100: 3.1704101887779785\n",
      "Iter 30/100: 2.688997382688652\n",
      "Iter 40/100: 2.3795949179528497\n",
      "Iter 50/100: 2.2911850754105796\n",
      "Iter 60/100: 2.262992920854102\n",
      "Iter 70/100: 2.2427713187260023\n",
      "Iter 80/100: 2.2346965995283394\n",
      "Iter 90/100: 2.22926608108824\n",
      "Iter 100/100: 2.224376002881033\n",
      "Iter 10/100: 3.925195545809059\n",
      "Iter 20/100: 3.077004247936824\n",
      "Iter 30/100: 2.62313088964692\n",
      "Iter 40/100: 2.3351233241878653\n",
      "Iter 50/100: 2.211983311954852\n",
      "Iter 60/100: 2.1655563108129163\n",
      "Iter 70/100: 2.142698093952709\n",
      "Iter 80/100: 2.136310063479035\n",
      "Iter 90/100: 2.1335787351450506\n",
      "Iter 100/100: 2.132953950100359\n",
      "Iter 10/100: 3.7998960628328486\n",
      "Iter 20/100: 2.9912148708951882\n",
      "Iter 30/100: 2.559975514135015\n",
      "Iter 40/100: 2.2884407729415317\n",
      "Iter 50/100: 2.159846773941066\n",
      "Iter 60/100: 2.1196570858236576\n",
      "Iter 70/100: 2.097924440874768\n",
      "Iter 80/100: 2.0908554212304393\n",
      "Iter 90/100: 2.0884176652365274\n",
      "Iter 100/100: 2.087761131951725\n",
      "Iter 10/100: 3.6852028654799867\n",
      "Iter 20/100: 2.913123232505986\n",
      "Iter 30/100: 2.5013985945238857\n",
      "Iter 40/100: 2.2386913674667577\n",
      "Iter 50/100: 2.109193152071298\n",
      "Iter 60/100: 2.0779322466054464\n",
      "Iter 70/100: 2.0483434510761245\n",
      "Iter 80/100: 2.0430506579941565\n",
      "Iter 90/100: 2.03945556775899\n",
      "Iter 100/100: 2.038986188093032\n",
      "Iter 10/100: 3.5912020793908797\n",
      "Iter 20/100: 2.852931067937278\n",
      "Iter 30/100: 2.4706496228033994\n",
      "Iter 40/100: 2.2509469031569034\n",
      "Iter 50/100: 2.1011060584100405\n",
      "Iter 10/100: 3.498671603455202\n",
      "Iter 20/100: 2.789602569788293\n",
      "Iter 30/100: 2.4232994691883225\n",
      "Iter 40/100: 2.2160507631960815\n",
      "Iter 50/100: 2.06272421249772\n",
      "Iter 60/100: 2.040589307327433\n",
      "Iter 10/100: 3.413139982114318\n",
      "Iter 20/100: 2.7304385876011947\n",
      "Iter 30/100: 2.3775696044129533\n",
      "Iter 40/100: 2.1793069675554078\n",
      "Iter 50/100: 2.048203468002113\n",
      "Iter 10/100: 3.3327486139266775\n",
      "Iter 20/100: 2.673922203467613\n",
      "Iter 30/100: 2.331542260829286\n",
      "Iter 40/100: 2.1390354418962727\n",
      "Iter 50/100: 1.9913293775937426\n",
      "Iter 60/100: 1.9573327995238585\n",
      "Iter 70/100: 1.93754221146396\n",
      "Iter 80/100: 1.9311521259750544\n",
      "Iter 90/100: 1.928953167157519\n",
      "Iter 100/100: 1.9282570684768852\n",
      "Iter 10/100: 3.2622562290707653\n",
      "Iter 20/100: 2.626190308829846\n",
      "Iter 30/100: 2.2969373767245336\n",
      "Iter 40/100: 2.1146938995577536\n",
      "Iter 50/100: 1.9821112320868821\n",
      "Iter 10/100: 3.194740506225511\n",
      "Iter 20/100: 2.5796224736167863\n",
      "Iter 30/100: 2.2604623082082216\n",
      "Iter 40/100: 2.0837039940689057\n",
      "Iter 50/100: 1.9428514072781091\n",
      "Iter 60/100: 1.9052015799046127\n",
      "Iter 70/100: 1.8906934267771693\n",
      "Iter 80/100: 1.8868923839772624\n",
      "Iter 10/100: 3.133365796270738\n",
      "Iter 20/100: 2.536820814412389\n",
      "Iter 30/100: 2.226858992287798\n",
      "Iter 40/100: 2.0574244763402536\n",
      "Iter 50/100: 1.913851907511733\n",
      "Iter 10/100: 3.075373760012518\n",
      "Iter 20/100: 2.4967377028646958\n",
      "Iter 30/100: 2.1953443299254873\n",
      "Iter 40/100: 2.0305314509306873\n",
      "Iter 50/100: 1.8893683759254702\n",
      "Iter 10/100: 3.0233169273229845\n",
      "Iter 20/100: 2.4610412696355657\n",
      "Iter 30/100: 2.1686225493080826\n",
      "Iter 40/100: 2.0114772896845916\n",
      "Iter 50/100: 1.8789850031695214\n",
      "Iter 10/100: 2.974570187752337\n",
      "Iter 20/100: 2.427694310445159\n",
      "Iter 30/100: 2.143700563561043\n",
      "Iter 40/100: 1.9934863122526398\n",
      "Iter 50/100: 1.8694918892711518\n",
      "Iter 60/100: 1.8643503188740846\n",
      "Iter 10/100: 2.925579206793632\n",
      "Iter 20/100: 2.3927301997201833\n",
      "Iter 30/100: 2.1138770022646387\n",
      "Iter 40/100: 1.9659751992949086\n",
      "Iter 50/100: 1.8397204587246094\n",
      "Iter 10/100: 2.8838823856477003\n",
      "Iter 20/100: 2.3660544354807076\n",
      "Iter 30/100: 2.099636313678519\n",
      "Iter 40/100: 1.9657715447312332\n",
      "Iter 50/100: 1.8705232803153073\n",
      "Iter 60/100: 1.8179386379982314\n",
      "Iter 10/100: 2.843602157490977\n",
      "Iter 20/100: 2.339046635860503\n",
      "Iter 30/100: 2.080320174332826\n",
      "Iter 40/100: 1.9519259724707527\n",
      "Iter 50/100: 1.8616518321315878\n",
      "Iter 60/100: 1.8031436518018502\n",
      "Iter 10/100: 2.8022014327354055\n",
      "Iter 20/100: 2.309049196107231\n",
      "Iter 30/100: 2.054005379469585\n",
      "Iter 40/100: 1.927436575417014\n",
      "Iter 50/100: 1.8369578258846992\n",
      "Iter 60/100: 1.783121858273617\n",
      "Iter 10/100: 2.765017958475352\n",
      "Iter 20/100: 2.2839550513140914\n",
      "Iter 30/100: 2.036259667595048\n",
      "Iter 40/100: 1.917034247294188\n",
      "Iter 50/100: 1.8364372999040302\n",
      "Iter 60/100: 1.780182255998529\n",
      "Iter 70/100: 1.7630501251979427\n",
      "Iter 80/100: 1.7565251621382811\n",
      "Iter 90/100: 1.7549456996682775\n",
      "Iter 100/100: 1.7538730338159443\n",
      "Iter 10/100: 2.7301947494205745\n",
      "Iter 20/100: 2.2599534526033187\n",
      "Iter 30/100: 2.01701252753599\n",
      "Iter 40/100: 1.8996896816402074\n",
      "Iter 50/100: 1.8185886606552688\n",
      "Iter 60/100: 1.764204928533785\n",
      "Iter 70/100: 1.7556211194194278\n",
      "Iter 10/100: 2.694503534192059\n",
      "Iter 20/100: 2.23340541242152\n",
      "Iter 30/100: 1.9924870705698021\n",
      "Iter 40/100: 1.876706835663352\n",
      "Iter 50/100: 1.7953119375796405\n",
      "Iter 60/100: 1.7516382874298704\n",
      "Iter 10/100: 2.664842207976031\n",
      "Iter 20/100: 2.2135560394372185\n",
      "Iter 30/100: 1.9787088121050314\n",
      "Iter 40/100: 1.867457222869944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50/100: 1.7897560472251892\n",
      "Iter 60/100: 1.7341749226969698\n",
      "Iter 10/100: 2.6351001616517484\n",
      "Iter 20/100: 2.1930641003752513\n",
      "Iter 30/100: 1.9624464688665637\n",
      "Iter 40/100: 1.852833792992028\n",
      "Iter 50/100: 1.775338091328095\n",
      "Iter 60/100: 1.7230033295635667\n",
      "Iter 70/100: 1.704723657170295\n",
      "Iter 10/100: 2.6050576718970744\n",
      "Iter 20/100: 2.171835460415102\n",
      "Iter 30/100: 1.9443009853598003\n",
      "Iter 40/100: 1.8355030307388567\n",
      "Iter 50/100: 1.7577579047441774\n",
      "Iter 60/100: 1.7158409984276832\n",
      "Iter 10/100: 2.577057617685498\n",
      "Iter 20/100: 2.1521814819373506\n",
      "Iter 30/100: 1.927932570395605\n",
      "Iter 40/100: 1.82044753563224\n",
      "Iter 50/100: 1.7427805720783627\n",
      "Iter 60/100: 1.6908210532152093\n",
      "Iter 70/100: 1.6794558371419857\n",
      "Iter 10/100: 2.551723852237166\n",
      "Iter 20/100: 2.13473284910012\n",
      "Iter 30/100: 1.9142696341029926\n",
      "Iter 40/100: 1.8087536193827514\n",
      "Iter 50/100: 1.7318583932274199\n",
      "Iter 60/100: 1.6788105553409296\n",
      "Iter 70/100: 1.6662347090397773\n",
      "Iter 80/100: 1.6601535278635282\n",
      "Iter 90/100: 1.6585744803686406\n",
      "Iter 100/100: 1.6576691591952886\n",
      "Iter 10/100: 2.5279632562707257\n",
      "Iter 20/100: 2.1184439915776476\n",
      "Iter 30/100: 1.901791118783224\n",
      "Iter 40/100: 1.7981389440866091\n",
      "Iter 50/100: 1.7215544007929051\n",
      "Iter 60/100: 1.666057716913921\n",
      "Iter 10/100: 2.505061398986513\n",
      "Iter 20/100: 2.103051198940923\n",
      "Iter 30/100: 1.890228616287361\n",
      "Iter 40/100: 1.787903781475144\n",
      "Iter 50/100: 1.7109417391479909\n",
      "Iter 60/100: 1.6537436980042308\n",
      "Iter 10/100: 2.4807543711741675\n",
      "Iter 20/100: 2.0852679517619856\n",
      "Iter 30/100: 1.874158537524751\n",
      "Iter 40/100: 1.772374521097449\n",
      "Iter 50/100: 1.6945619923304505\n",
      "Iter 60/100: 1.6435604782618352\n",
      "Iter 10/100: 2.4575764952977677\n",
      "Iter 20/100: 2.068086892205211\n",
      "Iter 30/100: 1.8582432065585903\n",
      "Iter 40/100: 1.756841545654621\n",
      "Iter 50/100: 1.6773496016348999\n",
      "Iter 60/100: 1.6278231845822366\n",
      "Iter 10/100: 2.436465842979797\n",
      "Iter 20/100: 2.0536041456463487\n",
      "Iter 30/100: 1.846592440704433\n",
      "Iter 40/100: 1.745484555197878\n",
      "Iter 50/100: 1.6646197636481006\n",
      "Iter 60/100: 1.6239205602514706\n",
      "Iter 10/100: 2.416667420819999\n",
      "Iter 20/100: 2.039667306740586\n",
      "Iter 30/100: 1.8349626265275685\n",
      "Iter 40/100: 1.7347166658082829\n",
      "Iter 50/100: 1.6527954176459998\n",
      "Iter 60/100: 1.6131941962937548\n",
      "Iter 10/100: 2.38766594441601\n",
      "Iter 20/100: 2.0120303913482656\n",
      "Iter 30/100: 1.7959187816852222\n",
      "Iter 40/100: 1.6844285627335724\n",
      "Iter 50/100: 1.5918447139606828\n",
      "Iter 60/100: 1.5601601468440722\n",
      "Iter 10/100: 2.368961005093518\n",
      "Iter 20/100: 1.9990099090356779\n",
      "Iter 30/100: 1.7851678128059236\n",
      "Iter 40/100: 1.6743905210998722\n",
      "Iter 50/100: 1.58270014899101\n",
      "Iter 60/100: 1.551638614695808\n",
      "Iter 70/100: 1.5417132297341063\n",
      "Iter 80/100: 1.5381500741863219\n",
      "Iter 90/100: 1.5357262423712053\n",
      "Iter 100/100: 1.5347718429640254\n",
      "Iter 10/100: 2.346938915090341\n",
      "Iter 20/100: 1.978223432263521\n",
      "Iter 30/100: 1.75307968572351\n",
      "Iter 40/100: 1.5963578435851846\n",
      "Iter 50/100: 1.52175690262369\n",
      "Iter 60/100: 1.4629223430054572\n",
      "Iter 70/100: 1.4228208750262128\n",
      "Iter 10/100: 2.329851042437546\n",
      "Iter 20/100: 1.9664161589959823\n",
      "Iter 30/100: 1.7434958515902532\n",
      "Iter 40/100: 1.5867310363928848\n",
      "Iter 50/100: 1.5106137526078447\n",
      "Iter 60/100: 1.449185508933649\n",
      "Iter 70/100: 1.4137853664523077\n",
      "Iter 10/100: 2.3136646680054773\n",
      "Iter 20/100: 1.9554456812865812\n",
      "Iter 30/100: 1.7350658735597035\n",
      "Iter 40/100: 1.5750444261990666\n",
      "Iter 50/100: 1.5020245397395315\n",
      "Iter 60/100: 1.411318448627184\n",
      "Iter 70/100: 1.40359172737588\n",
      "Iter 10/100: 2.296940554282799\n",
      "Iter 20/100: 1.942996155826699\n",
      "Iter 30/100: 1.7236868276423383\n",
      "Iter 40/100: 1.56386219514651\n",
      "Iter 50/100: 1.4924477192172307\n",
      "Iter 60/100: 1.402859579384125\n",
      "Iter 70/100: 1.3925546180785007\n",
      "Iter 10/100: 2.2809414288468486\n",
      "Iter 20/100: 1.931472942153775\n",
      "Iter 30/100: 1.7133531150586758\n",
      "Iter 40/100: 1.5516807177825491\n",
      "Iter 50/100: 1.4818176390088025\n",
      "Iter 60/100: 1.3885505281803114\n",
      "Iter 70/100: 1.3811393591740408\n",
      "Iter 10/100: 2.2656301050895418\n",
      "Iter 20/100: 1.9206024998722901\n",
      "Iter 30/100: 1.7038785161414032\n",
      "Iter 40/100: 1.5395168019639631\n",
      "Iter 50/100: 1.4705885777744523\n",
      "Iter 60/100: 1.3780382123990758\n",
      "Iter 70/100: 1.3707196832220325\n",
      "Iter 10/100: 2.250795269826016\n",
      "Iter 20/100: 1.9099373538686135\n",
      "Iter 30/100: 1.6940154242856844\n",
      "Iter 40/100: 1.524380258605647\n",
      "Iter 50/100: 1.4387746434198518\n",
      "Iter 60/100: 1.388911853957711\n",
      "Iter 70/100: 1.3578950426380239\n",
      "Iter 80/100: 1.3582187229695668\n",
      "Iter 10/100: 2.2361110066460737\n",
      "Iter 20/100: 1.8992725185925456\n",
      "Iter 30/100: 1.684345417560033\n",
      "Iter 40/100: 1.512542251785003\n",
      "Iter 50/100: 1.4491754727939081\n",
      "Iter 60/100: 1.3536304374367127\n",
      "Iter 70/100: 1.3469610498112992\n",
      "Iter 10/100: 2.2228496590684115\n",
      "Iter 20/100: 1.8900641219664236\n",
      "Iter 30/100: 1.6773870962050967\n",
      "Iter 40/100: 1.5090192732847543\n",
      "Iter 50/100: 1.4260939209189196\n",
      "Iter 60/100: 1.3522526519501268\n",
      "Iter 70/100: 1.345342473572172\n",
      "Iter 80/100: 1.3440321429299649\n",
      "Iter 10/100: 2.2082278249460305\n",
      "Iter 20/100: 1.8790411644883753\n",
      "Iter 30/100: 1.6669168720230338\n",
      "Iter 40/100: 1.5064508670522125\n",
      "Iter 50/100: 1.4631280596800758\n",
      "Iter 10/100: 2.1949558033134866\n",
      "Iter 20/100: 1.8692639985159045\n",
      "Iter 30/100: 1.6578949657645912\n",
      "Iter 40/100: 1.495988231410587\n",
      "Iter 50/100: 1.451918887036744\n",
      "Iter 10/100: 2.1818966551845396\n",
      "Iter 20/100: 1.8596871806153406\n",
      "Iter 30/100: 1.648821682002471\n",
      "Iter 40/100: 1.4842430959827353\n",
      "Iter 50/100: 1.447591060087211\n",
      "Iter 10/100: 2.1690351946256117\n",
      "Iter 20/100: 1.8497881948798207\n",
      "Iter 30/100: 1.6390171556897433\n",
      "Iter 40/100: 1.4724733299785726\n",
      "Iter 50/100: 1.4369717142016374\n",
      "Iter 10/100: 2.157034044942625\n",
      "Iter 20/100: 1.8408974847837967\n",
      "Iter 30/100: 1.6305588589407372\n",
      "Iter 40/100: 1.4616709667660208\n",
      "Iter 50/100: 1.4278818248175824\n",
      "Iter 10/100: 2.1443499525559204\n",
      "Iter 20/100: 1.8311046026886444\n",
      "Iter 30/100: 1.620546754437021\n",
      "Iter 40/100: 1.447437142829238\n",
      "Iter 50/100: 1.4164021788883414\n",
      "Iter 10/100: 2.1328078950888796\n",
      "Iter 20/100: 1.8226960462167647\n",
      "Iter 30/100: 1.6125610514796156\n",
      "Iter 40/100: 1.4382374314934563\n",
      "Iter 50/100: 1.4084246775254148\n",
      "Iter 10/100: 2.122207935487546\n",
      "Iter 20/100: 1.8153499093404029\n",
      "Iter 30/100: 1.606073872313372\n",
      "Iter 40/100: 1.4275999724439175\n",
      "Iter 50/100: 1.397914809916493\n",
      "Iter 10/100: 2.1091565516372355\n",
      "Iter 20/100: 1.8043538866707056\n",
      "Iter 30/100: 1.5930062533416836\n",
      "Iter 40/100: 1.4062753291489338\n",
      "Iter 50/100: 1.4003101913062532\n",
      "Iter 10/100: 2.099258513010764\n",
      "Iter 20/100: 1.7975990482761042\n",
      "Iter 30/100: 1.5876417606851898\n",
      "Iter 40/100: 1.3974884549186048\n",
      "Iter 50/100: 1.3916860914637794\n",
      "Iter 10/100: 2.0998139772899562\n",
      "Iter 20/100: 1.803685503763547\n",
      "Iter 30/100: 1.608689584329685\n",
      "Iter 40/100: 1.4780628009657057\n",
      "Iter 50/100: 1.3890355184374312\n",
      "Iter 10/100: 2.0905042816686046\n",
      "Iter 20/100: 1.7971250384310402\n",
      "Iter 30/100: 1.6027027169387607\n",
      "Iter 40/100: 1.4705018536736096\n",
      "Iter 50/100: 1.3820572337303536\n",
      "Iter 10/100: 2.0808878804737705\n",
      "Iter 20/100: 1.7901992528671835\n",
      "Iter 30/100: 1.5963013222116884\n",
      "Iter 40/100: 1.467538971470741\n",
      "Iter 50/100: 1.3923436935398392\n",
      "Iter 10/100: 2.0722990298833572\n",
      "Iter 20/100: 1.78425139032042\n",
      "Iter 30/100: 1.5918196939640115\n",
      "Iter 40/100: 1.4638319976893053\n",
      "Iter 50/100: 1.3886981050275387\n",
      "Iter 10/100: 2.061151232944276\n",
      "Iter 20/100: 1.7752040603991652\n",
      "Iter 30/100: 1.5827352268335324\n",
      "Iter 40/100: 1.4602357977767941\n",
      "Iter 50/100: 1.3734542462099557\n",
      "Iter 10/100: 2.053273271680977\n",
      "Iter 20/100: 1.7701986392137075\n",
      "Iter 30/100: 1.5803368393984976\n",
      "Iter 40/100: 1.4625610682435097\n",
      "Iter 50/100: 1.3828391787217966\n",
      "Iter 10/100: 2.0447278384195537\n",
      "Iter 20/100: 1.7639670724222667\n",
      "Iter 30/100: 1.5741039360989213\n",
      "Iter 40/100: 1.4543715223263207\n",
      "Iter 50/100: 1.3755382469422033\n",
      "Iter 60/100: 1.358988265995024\n",
      "Iter 70/100: 1.3478280598235781\n",
      "Iter 10/100: 2.0355414367858553\n",
      "Iter 20/100: 1.7564924843937961\n",
      "Iter 30/100: 1.565124558780891\n",
      "Iter 40/100: 1.4391960166588695\n",
      "Iter 50/100: 1.354865922010242\n",
      "Iter 10/100: 2.0268958630640044\n",
      "Iter 20/100: 1.7494643659471096\n",
      "Iter 30/100: 1.5575414186487184\n",
      "Iter 40/100: 1.4308653250315757\n",
      "Iter 50/100: 1.3450657545677933\n",
      "Iter 10/100: 2.018601537461782\n",
      "Iter 20/100: 1.743086953027232\n",
      "Iter 30/100: 1.551093319772106\n",
      "Iter 40/100: 1.4232796610121363\n",
      "Iter 50/100: 1.3369837502852555\n",
      "Iter 10/100: 2.0106085344964653\n",
      "Iter 20/100: 1.7370654846006985\n",
      "Iter 30/100: 1.5450399033953903\n",
      "Iter 40/100: 1.4165020101815096\n",
      "Iter 50/100: 1.3299315285367679\n",
      "Iter 10/100: 2.002679480518346\n",
      "Iter 20/100: 1.7311118236728191\n",
      "Iter 30/100: 1.538990688259301\n",
      "Iter 40/100: 1.4091168704576205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50/100: 1.3219201905805935\n",
      "Iter 60/100: 1.3219586413509656\n",
      "Iter 70/100: 1.2748965259262994\n",
      "Iter 80/100: 1.2708928380389217\n",
      "Iter 90/100: 1.2679801990675619\n",
      "Iter 100/100: 1.2667383979632647\n",
      "Iter 10/100: 1.995836224131154\n",
      "Iter 20/100: 1.7264722824295384\n",
      "Iter 30/100: 1.5365854903406422\n",
      "Iter 40/100: 1.4174627714109953\n",
      "Iter 50/100: 1.3377010582713267\n",
      "Iter 60/100: 1.3165585438104423\n",
      "Iter 70/100: 1.2698348916388436\n",
      "Iter 80/100: 1.2661178491469696\n",
      "Iter 90/100: 1.2641662439010453\n",
      "Iter 100/100: 1.263645857361611\n",
      "Iter 10/100: 1.9884401587638536\n",
      "Iter 20/100: 1.7211614622521452\n",
      "Iter 30/100: 1.531619493502006\n",
      "Iter 40/100: 1.4105770221274212\n",
      "Iter 50/100: 1.331253018885275\n",
      "Iter 60/100: 1.2916301350131276\n",
      "Iter 70/100: 1.2648471209393315\n",
      "Iter 80/100: 1.2612123249977962\n",
      "Iter 90/100: 1.2592495204065137\n",
      "Iter 100/100: 1.2588501176649012\n",
      "Iter 10/100: 1.9819266601102956\n",
      "Iter 20/100: 1.7166469260451889\n",
      "Iter 30/100: 1.5276857808862256\n",
      "Iter 40/100: 1.4046259072039722\n",
      "Iter 50/100: 1.3248513875512147\n",
      "Iter 60/100: 1.3185461587200775\n",
      "Iter 70/100: 1.2657344558142465\n",
      "Iter 80/100: 1.2618328213468435\n",
      "Iter 90/100: 1.2586323200007867\n",
      "Iter 100/100: 1.257361598124263\n",
      "Iter 10/100: 1.9758056840831577\n",
      "Iter 20/100: 1.712360441625853\n",
      "Iter 30/100: 1.5240770144527191\n",
      "Iter 40/100: 1.4004743084324858\n",
      "Iter 50/100: 1.318335049451545\n",
      "Iter 60/100: 1.311090841353012\n",
      "Iter 70/100: 1.2585174532650836\n",
      "Iter 10/100: 1.968661321682088\n",
      "Iter 20/100: 1.7067275986983772\n",
      "Iter 30/100: 1.5178995483333644\n",
      "Iter 40/100: 1.3927544527438032\n",
      "Iter 50/100: 1.3097023940274939\n",
      "Iter 60/100: 1.3013970418992096\n",
      "Iter 70/100: 1.2505787366215353\n",
      "Iter 10/100: 1.962553413660528\n",
      "Iter 20/100: 1.702676984741984\n",
      "Iter 30/100: 1.5145858758798032\n",
      "Iter 40/100: 1.3857040748008176\n",
      "Iter 50/100: 1.3010059727081558\n",
      "Iter 60/100: 1.2864592181928838\n",
      "Iter 70/100: 1.2430558102713134\n",
      "Iter 10/100: 1.952464309605049\n",
      "Iter 20/100: 1.688622263314709\n",
      "Iter 30/100: 1.4865944413090268\n",
      "Iter 40/100: 1.333472707591393\n",
      "Iter 50/100: 1.224884015909379\n",
      "Iter 60/100: 1.1958121922381872\n",
      "Iter 70/100: 1.190684334323956\n",
      "Iter 80/100: 1.1864296393012046\n",
      "Iter 90/100: 1.18505274119093\n",
      "Iter 100/100: 1.184748677603654\n",
      "Iter 10/100: 1.9459660684985904\n",
      "Iter 20/100: 1.6837789764692253\n",
      "Iter 30/100: 1.4814569930925003\n",
      "Iter 40/100: 1.3256922860364133\n",
      "Iter 50/100: 1.217107346601309\n",
      "Iter 60/100: 1.1890084072228095\n",
      "Iter 70/100: 1.1841107523843846\n",
      "Iter 80/100: 1.1799408827276023\n",
      "Iter 90/100: 1.1786137916891435\n",
      "Iter 100/100: 1.1782864390107521\n",
      "Iter 10/100: 1.9394785201046671\n",
      "Iter 20/100: 1.6787470870712313\n",
      "Iter 30/100: 1.476221449619318\n",
      "Iter 40/100: 1.3189210361944521\n",
      "Iter 50/100: 1.2106460314805145\n",
      "Iter 60/100: 1.1829163611464522\n",
      "Iter 70/100: 1.1779036859252807\n",
      "Iter 80/100: 1.173752951091198\n",
      "Iter 90/100: 1.1724191779655844\n",
      "Iter 100/100: 1.172086805592556\n",
      "Iter 10/100: 1.9329156261327967\n",
      "Iter 20/100: 1.6735301089765533\n",
      "Iter 30/100: 1.470802199919717\n",
      "Iter 40/100: 1.311890287005228\n",
      "Iter 50/100: 1.2028318546839813\n",
      "Iter 60/100: 1.1747771958533582\n",
      "Iter 70/100: 1.1700892814584711\n",
      "Iter 80/100: 1.166286842419473\n",
      "Iter 90/100: 1.1649800624789777\n",
      "Iter 100/100: 1.1646484167412277\n",
      "Iter 10/100: 1.9266447487776255\n",
      "Iter 20/100: 1.6687317819239462\n",
      "Iter 30/100: 1.465946323501322\n",
      "Iter 40/100: 1.3048244518747123\n",
      "Iter 50/100: 1.2117884078547694\n",
      "Iter 60/100: 1.1668895270125057\n",
      "Iter 70/100: 1.162319904275159\n",
      "Iter 80/100: 1.1584106345198173\n",
      "Iter 90/100: 1.15721687192284\n",
      "Iter 100/100: 1.1569075792464074\n",
      "Iter 10/100: 1.9210367525886867\n",
      "Iter 20/100: 1.6651071626138367\n",
      "Iter 30/100: 1.4642833474904933\n",
      "Iter 40/100: 1.311062998614179\n",
      "Iter 50/100: 1.1995743703079371\n",
      "Iter 60/100: 1.187015019609114\n",
      "Iter 10/100: 1.9135768577774104\n",
      "Iter 20/100: 1.6567428144637597\n",
      "Iter 30/100: 1.4480796941856995\n",
      "Iter 40/100: 1.2722482526897843\n",
      "Iter 50/100: 1.178538902980365\n",
      "Iter 60/100: 1.1381859725763697\n",
      "Iter 10/100: 1.9077829448676893\n",
      "Iter 20/100: 1.6522022741961468\n",
      "Iter 30/100: 1.442920764518495\n",
      "Iter 40/100: 1.2639099689871491\n",
      "Iter 50/100: 1.1702050130802177\n",
      "Iter 60/100: 1.1426209633730602\n",
      "Iter 10/100: 1.90229934464245\n",
      "Iter 20/100: 1.6481577206040254\n",
      "Iter 30/100: 1.438333771253025\n",
      "Iter 40/100: 1.2562783530862376\n",
      "Iter 50/100: 1.1652057474901893\n",
      "Iter 60/100: 1.1271921696458533\n",
      "Iter 10/100: 1.8973063215978765\n",
      "Iter 20/100: 1.6445932656039215\n",
      "Iter 30/100: 1.4349756118689299\n",
      "Iter 40/100: 1.2509875280453042\n",
      "Iter 50/100: 1.1590050035106831\n",
      "Iter 60/100: 1.1290973262656259\n",
      "Iter 10/100: 1.891435946405936\n",
      "Iter 20/100: 1.6398182386837274\n",
      "Iter 30/100: 1.4298695348712327\n",
      "Iter 40/100: 1.2439045075453647\n",
      "Iter 50/100: 1.1505299787559344\n",
      "Iter 60/100: 1.1292961070670173\n",
      "Iter 10/100: 1.8825058204085656\n",
      "Iter 20/100: 1.6296043939744145\n",
      "Iter 30/100: 1.410478391504415\n",
      "Iter 40/100: 1.2097651158065315\n",
      "Iter 50/100: 1.1193156384052845\n",
      "Iter 60/100: 1.1046190507500977\n",
      "Iter 10/100: 1.8712136765782128\n",
      "Iter 20/100: 1.6148441790486256\n",
      "Iter 30/100: 1.385358101056112\n",
      "Iter 40/100: 1.1667438055049055\n",
      "Iter 50/100: 1.0516473416548981\n",
      "Iter 60/100: 1.0299454776924586\n",
      "Iter 70/100: 1.0259283245785913\n",
      "Iter 80/100: 1.023060462236726\n",
      "Iter 90/100: 1.0224523861002934\n",
      "Iter 100/100: 1.0221693729720769\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  Run Search\n",
    "###\n",
    "for i in range(nb_COFs_initialization * len(discrete_fidelities), nb_iterations + 1):\n",
    "    ###\n",
    "    #  Train Model\n",
    "    ###\n",
    "    model = train_surrogate_model(X_train, y_train)\n",
    "\n",
    "    ###\n",
    "    #  Evaluate Acquisition Function\n",
    "    ###\n",
    "    ids_acquired = torch.tensor([acq_[0].item() for acq_ in acquired_set])\n",
    "#     ids_acquired = torch.tensor(list(zip(*acquired_set))[0])\n",
    "\n",
    "    acquisition_values = []\n",
    "    f_id_acq    = -1 # dummy val we know will be overwritten\n",
    "    cof_id_acq  = -1\n",
    "    max_acq_val = 0\n",
    "    for fidelity in discrete_fidelities:\n",
    "        # evaluate acquisition function at given fidelity\n",
    "        f_acquisition_values = acquisition(model, X, fidelity, acquired_set, costs_acquired)\n",
    "        # sort in descending order\n",
    "        f_acquisition_sorted = f_acquisition_values.argsort(descending=True)\n",
    "        ### Strategy here: ####\n",
    "        #  1. loop through sorted indexes \n",
    "        #  2. check that the COF is in the list of acquired values with the given fidelity.\n",
    "        #     a) If the cof_id isn't in the acquired_set, then we don't need to check the fidelity\n",
    "        #     b) If it is in the acquired_set, then we have to check at which fidelity it was acquired\n",
    "        #  3. check if the acquisition value for the proposed cof_id at this fidelity is higher \n",
    "        #     than the highest acquisition values for the other ids and fidelities checked so far\n",
    "        #     a) if TRUE, store it -> becomes our new highest acquisition value to check against\n",
    "        #  4. once we've gone through all discrete fidelity levels, \n",
    "        #     we acquire the (cof_id, f_id) pair which had the highest value\n",
    "        ###\n",
    "        for sorted_id in f_acquisition_sorted:\n",
    "            if len(np.where(ids_acquired == sorted_id)[0]) == 0:\n",
    "                # this cof_id is not in the current acquired_set\n",
    "                f_id_max_aquisition = sorted_id.item()\n",
    "                break\n",
    "            elif (0 < len(np.where(ids_acquired == sorted_id)[0]) and \n",
    "                  len(np.where(ids_acquired == sorted_id)[0]) < len(discrete_fidelities)):\n",
    "                # check if this cof_id has already been sampled at both fidelities\n",
    "                if acquired_set[np.where(ids_acquired == sorted_id)[0].item()][1] != fidelity:\n",
    "                    # if the fidelity acquired for this COF is not the fidelity we are proposing, \n",
    "                    # store cof_id comparison (allow potential acquisition at proposed fidelity)\n",
    "                    f_id_max_aquisition = sorted_id.item()\n",
    "                    break\n",
    "        # check if proposed acquisition is the max across evaluated fidelities\n",
    "        if f_acquisition_values[f_id_max_aquisition] > max_acq_val:\n",
    "            # update max acquisition value\n",
    "            max_acq_val = f_acquisition_values[f_id_max_aquisition]\n",
    "            # update cof_id of max acquisition value\n",
    "            cof_id_acq  = f_id_max_aquisition\n",
    "            # update f_id of max acquisition value\n",
    "            f_id_acq = fidelity\n",
    "    ###\n",
    "    #  Updates\n",
    "    ###\n",
    "    # Update acquired_set\n",
    "    acq_ = torch.tensor([[cof_id_acq, f_id_acq]], dtype=int)\n",
    "    acquired_set = torch.cat((acquired_set, acq_))\n",
    "\n",
    "    # Update training sets and cost\n",
    "    X_train = build_X_train(acquired_set)\n",
    "    y_train = build_y_train(acquired_set)\n",
    "    costs_acquired = build_cost(acquired_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "615085b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of unique COfs sampled\n",
      "iteration we acquire top COF =  51\n",
      "accumulated cost up to observation of top COF =  1493.3083884596824  [min]\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# look at unique COFs acquired\n",
    "###\n",
    "ids_acquired = torch.tensor([acq_[0].item() for acq_ in acquired_set])\n",
    "unique_ids = len(np.unique(ids_acquired))\n",
    "print(\"total number of unique COfs sampled\")\n",
    "\n",
    "###\n",
    "#  Iterations until top COF and accumulated \n",
    "###\n",
    "top_cof = np.argmax(ids_acquired == np.argmax(y[1]))\n",
    "top_cof_acc_cost = sum(costs_acquired[:top_cof]).item() \n",
    "\n",
    "print(\"iteration we acquire top COF = \", top_cof.item() + 1)\n",
    "print(\"accumulated cost up to observation of top COF = \", top_cof_acc_cost, \" [min]\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f025c39a",
   "metadata": {},
   "source": [
    "# Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e808fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfbo_res = dict({'acquired_set': acquired_set,\n",
    "                 'costs_acquired': costs_acquired\n",
    "                })\n",
    "\n",
    "with open('mfbo_results_with_EI.pkl', 'wb') as file:\n",
    "    pickle.dump(mfbo_res, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6a7b6",
   "metadata": {},
   "source": [
    "## PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a56efdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fids_acquired = torch.tensor([acq_[1].item() for acq_ in acquired_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c00d7608",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_selectivity  = np.zeros(len(ids_acquired), dtype=float)\n",
    "selectivity_acquired = np.zeros(len(ids_acquired), dtype=float)\n",
    "net_cost  = np.zeros(len(ids_acquired), dtype=float)\n",
    "\n",
    "hl = 2 * nb_COFs_initialization\n",
    "y_max = 0\n",
    "\n",
    "for i in range(len(ids_acquired)):\n",
    "    net_cost[i] = sum(costs_acquired[:i])\n",
    "    if fids_acquired[i] == 1:\n",
    "        selectivity_acquired[i] = y[1][ids_acquired[i]]\n",
    "        if selectivity_acquired[i] > y_max:\n",
    "            y_max = selectivity_acquired[i]\n",
    "        max_selectivity[i] = y_max\n",
    "    else:\n",
    "        max_selectivity[i] = y_max\n",
    "        selectivity_acquired[i] = y[0][ids_acquired[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c3cf5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "plt.axvline(x=hl, label=\"initialization\", color=\"k\", alpha=0.25, linestyle=\"--\", lw=2)\n",
    "plt.plot(range(len(ids_acquired)), net_cost, label=\"cost\", color=\"tab:blue\")\n",
    "plt.legend(fontsize=12)\n",
    "plt.ylabel(\"accumulated cost [min]\")\n",
    "plt.xlim(xmin=0, xmax=nb_iterations)\n",
    "plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "plt.ylim(ymin=0, ymax=35000) #\n",
    "\n",
    "plt.subplot(2, 1, 2, sharex=ax1)\n",
    "plt.axhline(y=max(y[1]), label=\"global maximm\", color=\"tab:green\", ls=\"--\", lw=1.5)\n",
    "plt.axvline(x=hl, label=\"initialization\", color=\"k\", alpha=0.25, linestyle=\"--\", lw=2)\n",
    "plt.plot(range(len(ids_acquired)), max_selectivity, label=\"MFBO\", color=\"tab:red\", zorder=3)\n",
    "plt.ylim(ymin=0, ymax=20)\n",
    "plt.xlabel(\"# evaluated COFs\")\n",
    "plt.ylabel(\"max. $S_{Xe/Kr}$ acquired\")\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"figs/mfbo/multi_fidelity_bo_search_efficientcy_curve.png\", dpi=600, format=\"png\")\n",
    "# plt.savefig(\"figs/mfbo/multi_fidelity_bo_search_efficientcy_curve.pdf\", dpi=600, format=\"pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
