{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New, cleaned-up notebook to generate figures in the paper."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figures:\n",
    "    - Accumulated Cost Histogram \n",
    "    - MFBO Sarch Dynamics: S_max vs experiment and acc cost vs experiment\n",
    "    - Model Comparison Plot: S_max vs Cost for each type of search (SFBO, MFBO, random)\n",
    "    - Search Distrobution plot\n",
    "    - PCA MFBO Acquisition Dynamics: MFBO Acquisitions represented in 2D PCA space\n",
    "    - Feature Radar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.text as mpltxt\n",
    "import matplotlib.cm as cm\n",
    "import pickle # for .pkl files\n",
    "import h5py   # for .jld2 files\n",
    "import os\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "\n",
    "sns.set(style='ticks', palette='Set2', font_scale=1.5, rc={\"lines.linewidth\": 3})\n",
    "sns.despine()\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 1200\n",
    "save_plots = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_fidelities = [1/3, 2/3] # set of discrete fidelities (in ascending order) to select from"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  construct a single dictionary from those of all the runs\n",
    "###\n",
    "def get_bo_res(which_results: str, nb_run: int, norm_type):\n",
    "    assert \"results\" in which_results\n",
    "    # initialize dict to store results \n",
    "    bo_res = pickle.load(\n",
    "             open('search_results/{}/{}/{}_run_{}.pkl'.format(norm_type, \n",
    "                                                              which_results, \n",
    "                                                              which_results, 0), 'rb'))\n",
    "    for key in bo_res.keys():\n",
    "        bo_res[key] = []\n",
    "        \n",
    "    # iterate though the runs\n",
    "    for n in range(nb_run):\n",
    "        # get results dict for specified run\n",
    "        bo_res_file = pickle.load(\n",
    "                     open('search_results/{}/{}/{}_run_{}.pkl'.format(norm_type, \n",
    "                                                                      which_results, \n",
    "                                                                      which_results, n), 'rb'))\n",
    "        \n",
    "        # append results to end of list\n",
    "        for key in bo_res_file.keys():\n",
    "            key_res = bo_res_file[key]\n",
    "            bo_res[key].append(key_res)\n",
    "            \n",
    "    return bo_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  features and molecular simulation data\n",
    "###\n",
    "file = h5py.File(\"targets_and_{}_features.jld2\".format(normalization), \"r\")\n",
    "\n",
    "# feature matrix\n",
    "X = torch.from_numpy(np.transpose(file[\"X\"][:])) # ... Needs to be tensor?\n",
    "# simulation data\n",
    "y = [np.transpose(file[\"henry_y\"][:]), \n",
    "     np.transpose(file[\"gcmc_y\"][:])]\n",
    "\n",
    "# total number of COFs in data set\n",
    "nb_COFs = X.shape[0]\n",
    "\n",
    "###\n",
    "#  bayesian optimization data\n",
    "###\n",
    "# COF IDs used for initialization\n",
    "init_cof_ids_file = pickle.load(open('search_results/{}/initializing_cof_ids_{}.pkl'.format(normalization, \n",
    "                                                                           normalization), 'rb'))\n",
    "init_cof_ids = init_cof_ids_file['init_cof_ids']\n",
    "\n",
    "nb_COFs_initialization = len(init_cof_ids[0])\n",
    "nb_runs = len(init_cof_ids)\n",
    "\n",
    "# random search \n",
    "random_search_res = pickle.load(open('search_results/{}/random_search_results.pkl'.format(normalization), 'rb'))\n",
    "\n",
    "# multi-fidelity search\n",
    "mfbo_res = get_bo_res('mfbo_results', nb_runs, normalization)\n",
    "\n",
    "# single-fideliy search\n",
    "sfbo_res = get_bo_res('sfbo_results', nb_runs, normalization)\n",
    "\n",
    "# number of iterations per run\n",
    "nb_iters = len(mfbo_res['acquired_set'][0])\n",
    "\n",
    "###\n",
    "#  quick checks\n",
    "###\n",
    "# structure of data\n",
    "assert len(sfbo_res['ids_acquired'][0]) == nb_iters\n",
    "assert len(random_search_res['ids_acquired'][0]) == nb_iters\n",
    "assert sfbo_res['nb_COFs_initialization'][0] == nb_COFs_initialization\n",
    "\n",
    "# each run has the correct initializing COFs\n",
    "assert all([all(sfbo_res['ids_acquired'][r][:nb_COFs_initialization] == init_cof_ids[r]) \n",
    "            for r in range(nb_runs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the max number of iterations needed for any of the runs\n",
    "max_SFBO_iters = max(sfbo_res['BO_iter_top_cof_acquired'])\n",
    "max_MFBO_iters = max(mfbo_res['BO_iter_top_cof_acquired'])\n",
    "\n",
    "# the highest accumulated cost up to the max number of iterations needed\n",
    "max_SFBO_cost = np.max(sfbo_res['accumulated_cost'][:][:max_SFBO_iters+1])\n",
    "max_MFBO_cost = np.max(mfbo_res['accumulated_cost'][:][:max_MFBO_iters+1])\n",
    "\n",
    "\n",
    "print(\"The max number of iterations needed for any of the runs -\")\n",
    "print(\"\\tSFBO: {}\".format(max_SFBO_iters))\n",
    "print(\"\\tMFBO: {}\".format(max_MFBO_iters))\n",
    "print(\"The highest accumulated cost up to the max number of iterations needed -\")\n",
    "print(\"\\tSFBO: {} [hr]\".format(max_SFBO_cost))\n",
    "print(\"\\tMFBO: {} [hr]\".format(max_MFBO_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
