{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8613aa76",
   "metadata": {},
   "source": [
    "## System Description\n",
    "1. We have a set of COFs from a database. Each COF is characterized by a feature vector $$x_{COF} \\in X \\subset R^d$$ were d=14.\n",
    "\n",
    "\n",
    "2. We have **two different types** of simulations to calculate **the same material property $S_{Xe/Kr}$**. Therefore, we have a Single-Task/Objective (find the material with the optimal selevtivity), Multi-Fidelity problem. \n",
    "    1. low-fidelity  = Henry coefficient calculation - MC integration - cost=1\n",
    "    2. high-fidelity = GCMC mixture simulation - 80:20 (Kr:Xe) at 298 K and 1.0 bar - cost=30\n",
    "\n",
    "\n",
    "3. We will initialize the system with *two* COFs at both fidelities in order to initialize the Covariance Matrix.\n",
    "    - The fist COF will be the one closest to the center of the normalized feature space\n",
    "    - The second COF will be chosen at random\n",
    "\n",
    "\n",
    "4. Each surrogate model will **only train on data acquired at its level of fidelity** (Heterotopic data). $$X_{lf} \\neq X_{hf} \\subset X$$\n",
    "    1. We are using the augmented EI acquisition function from [here](https://link.springer.com/content/pdf/10.1007/s00158-005-0587-0.pdf)\n",
    "\n",
    "\n",
    "5. **kernel model**: \n",
    "    1.  We need a Gaussian Process (GP) that will give a *correlated output for each fidelity* i.e. we need a vector-valued kernel\n",
    "    2. Given the *cost aware* acquisition function, we anticipate the number of training points at each fidelity *will not* be equal (asymmetric scenario) $$n_{lf} > n_{hf}$$\n",
    "        - perhaps we can force the symmetric case, $n_{lf} = n_{hf} = n$, if we can include `missing` or `empty` entries in the training sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b61313",
   "metadata": {},
   "source": [
    "### Strategy\n",
    "1. Implement SingleTaskMultiFidelity Gp\n",
    "2. Get augmented EI working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7679eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from botorch.models import SingleTaskMultiFidelityGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch import fit_gpytorch_model\n",
    "\n",
    "from scipy.stats import norm\n",
    "import math \n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66a5cb",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa45b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data - \n",
      "X: torch.Size([608, 14])\n",
      "henry_y: torch.Size([608])\n",
      "gcmc_y:  torch.Size([608])\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(\"targets_and_normalized_features.jld2\", \"r\")\n",
    "# feature matrix\n",
    "X = torch.from_numpy(np.transpose(f[\"X\"][:]))\n",
    "# simulation data\n",
    "henry_y = torch.from_numpy(np.transpose(f[\"henry_y\"][:]))\n",
    "gcmc_y  = torch.from_numpy(np.transpose(f[\"gcmc_y\"][:]))\n",
    "# associated simulation costs\n",
    "henry_cost = torch.from_numpy(np.transpose(f[\"henry_total_elapsed_time\"][:]))\n",
    "gcmc_cost  = torch.from_numpy(np.transpose(f[\"gcmc_elapsed_time\"][:]))\n",
    "\n",
    "print(\"raw data - \\nX:\", X.shape)\n",
    "print(\"henry_y:\", henry_y.shape)\n",
    "print(\"gcmc_y: \", gcmc_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f84bd4",
   "metadata": {},
   "source": [
    "#### Construct initial imputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ccc0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# helper functions\n",
    "###\n",
    "# find COF closest to the center of feature space\n",
    "def get_initializing_COF(X):\n",
    "    # center of feature space\n",
    "    feature_center = np.ones(X.shape[1]) * 0.5\n",
    "    # max possible distance between normalized features\n",
    "    min_dist = X.shape[1] * np.sqrt(2)\n",
    "    min_id = 0 # dummy id \n",
    "    for i in range(0, nb_COFs - 1):\n",
    "        dist = np.sqrt(sum((X[i] - feature_center) * (X[i] - feature_center)).item())\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            min_id = i\n",
    "    return min_id\n",
    "\n",
    "# construct feature matrix of acquired points\n",
    "def build_X_train(ids_acquired, fidelity_acquired):\n",
    "    return torch.cat((X[ids_acquired, :], fidelity_acquired), dim=1)\n",
    "\n",
    "# construct output vector for acquired points\n",
    "def build_y_train(ids_acquired, fidelity_acquired):\n",
    "    train_y = torch.tensor((), dtype=torch.float64).new_zeros((ids_acquired.shape[0], 1))\n",
    "    for i, fid in enumerate(fidelity_acquired):\n",
    "        if fid == 0:\n",
    "            train_y[i][0] = henry_y[ids_acquired[i]]\n",
    "        else:\n",
    "            train_y[i][0] = gcmc_y[ids_acquired[i]]\n",
    "    return train_y\n",
    "\n",
    "# construct vector to track accumulated cost of acquired points\n",
    "def build_cost(ids_acquired, fidelity_acquired):\n",
    "    costs_acquired = torch.tensor((), dtype=torch.float64).new_zeros((ids_acquired.shape[0], 1))\n",
    "    for i, fid in enumerate(fidelity_acquired):\n",
    "        if fid == 0:\n",
    "            costs_acquired[i][0] = henry_cost[ids_acquired[i]]\n",
    "        else:\n",
    "            costs_acquired[i][0] = gcmc_cost[ids_acquired[i]]\n",
    "    return costs_acquired\n",
    "\n",
    "###\n",
    "#  construct initial inputs\n",
    "###\n",
    "nb_COFs = X.shape[0] # total number of COFs data points \n",
    "nb_COFs_initialization = 1\n",
    "\n",
    "ids_acquired = np.ones(nb_COFs_initialization, dtype=int) * get_initializing_COF(X)\n",
    "fidelity_acquired = torch.ones((nb_COFs_initialization, 1), dtype=int) # start with high-fidelity\n",
    "costs_acquired = build_cost(ids_acquired, fidelity_acquired)\n",
    "\n",
    "X_train = build_X_train(ids_acquired, fidelity_acquired)\n",
    "y_train = build_y_train(ids_acquired, fidelity_acquired)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c10ceba",
   "metadata": {},
   "source": [
    "## Run MFBO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d57717a",
   "metadata": {},
   "source": [
    "#### train surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c5e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_surrogate_model(X_train, y_train):\n",
    "    model = SingleTaskMultiFidelityGP(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        outcome_transform=Standardize(m=1), # m is the output dimension\n",
    "        data_fidelity=X_train.shape[1] - 1\n",
    "    )   \n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_model(mll)\n",
    "    return mll, model\n",
    "\n",
    "mll, model = train_surrogate_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce88b3c",
   "metadata": {},
   "source": [
    "### Acquisition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c01406a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate posterior mean and variance\n",
    "def mu_sigma(model, X, fidelity):\n",
    "    f = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) * fidelity\n",
    "    X_f = torch.cat((X, f), dim=1) # last col is associated fidelity\n",
    "    f_posterior = model.posterior(X_f)\n",
    "    return f_posterior.mean.squeeze().detach().numpy(), f_posterior.variance.squeeze().detach().numpy()\n",
    "\n",
    "# get the current \"effective best solution\" \n",
    "def get_y_max(ids_acquired, fidelity_acquired, desired_fidelity):\n",
    "    y_max = torch.tensor((), dtype=torch.float64).new_zeros(1)\n",
    "    for i, fid in enumerate(fidelity_acquired):\n",
    "        if (fid == 1 & desired_fidelity == 1):\n",
    "            if gcmc_y[ids_acquired[i]] > y_max:\n",
    "                y_max = gcmc_y[ids_acquired[i]]\n",
    "        elif (fid == 0 & desired_fidelity == 0):\n",
    "            if henry_y[ids_acquired[i]] > y_max:\n",
    "                y_max = henry_y[ids_acquired[i]]\n",
    "    return y_max.item()\n",
    "\n",
    "# Expected Imrovement function\n",
    "def EI_hf(model, X, ids_acquired, fidelity_acquired):\n",
    "    mu_hf, sigma_hf = mu_sigma(model, X, 1) # only use hf\n",
    "    y_max = get_y_max(ids_acquired, fidelity_acquired, 1)\n",
    "    \n",
    "    z = (mu_hf - y_max) / sigma_hf\n",
    "    explore_term = sigma_hf * norm.pdf(z)\n",
    "    exploit_term = (mu_hf - y_max) * norm.cdf(z)\n",
    "    ei = explore_term + exploit_term\n",
    "    return np.maximum(ei, np.zeros(nb_COFs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bb56822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_1(model, X, ids_acquired, fidelity_acquired):\n",
    "    # get posterior at each fidelity\n",
    "    lf_mu, lf_sigma = mu_sigma(model, X, 0)\n",
    "    hf_mu, hf_sigma = mu_sigma(model, X, 1)\n",
    "    # get \"best linear predictor\" at each fidelity\n",
    "    lf_y_max = get_y_max(ids_acquired, fidelity_acquired, 0)\n",
    "    hf_y_max = get_y_max(ids_acquired, fidelity_acquired, 1)\n",
    "    # calculate covariance\n",
    "    a1 = ((lf_mu - lf_y_max) * (hf_mu - hf_y_max)) / (lf_sigma * hf_sigma)\n",
    "    return a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cf4be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_2(model, X, ids_acquired, fidelity_acquired):\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa601c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cost ratio (α3)\n",
    "def cost_ratio(fidelity_acquired, costs_acquired):\n",
    "    avg_cost_hf = np.mean(costs_acquired[fidelity_acquired == 1])\n",
    "    avg_cost_lf = np.mean(costs_acquired[fidelity_acquired == 0])\n",
    "    return avg_cost_hf / avg_cost_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d12b5b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(608,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ei = EI_hf(model, X, ids_acquired, fidelity_acquired)\n",
    "ei.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8327a074",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean() received an invalid combination of arguments - got (dtype=NoneType, out=NoneType, axis=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_77359/858878362.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0macquisition_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mids_sorted_by_aquisition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquisiiton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_acquired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfidelity_acquired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosts_acquired\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_77359/858878362.py\u001b[0m in \u001b[0;36macquisiiton\u001b[0;34m(model, X, ids_acquired, fidelity_acquired, costs_acquired)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_acquired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfidelity_acquired\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_acquired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfidelity_acquired\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0ma3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfidelity_acquired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosts_acquired\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0macquisition_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mei\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_77359/4181642087.py\u001b[0m in \u001b[0;36mcost_ratio\u001b[0;34m(fidelity_acquired, costs_acquired)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# calculate the cost ratio (α3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcost_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfidelity_acquired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosts_acquired\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mavg_cost_hf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosts_acquired\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfidelity_acquired\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mavg_cost_lf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosts_acquired\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfidelity_acquired\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mavg_cost_hf\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mavg_cost_lf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3436\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3437\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3438\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3440\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "\u001b[0;31mTypeError\u001b[0m: mean() received an invalid combination of arguments - got (dtype=NoneType, out=NoneType, axis=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "def acquisiiton(model, X, ids_acquired, fidelity_acquired, costs_acquired):\n",
    "    # expected improvement\n",
    "    ei = EI_hf(model, X, ids_acquired, fidelity_acquired)\n",
    "    \n",
    "    # augmenting functions\n",
    "    a1 = augment_1(model, X, ids_acquired, fidelity_acquired)\n",
    "    a2 = augment_2(model, X, ids_acquired, fidelity_acquired)\n",
    "    a3 = cost_ratio(fidelity_acquired, costs_acquired)\n",
    "    \n",
    "    acquisition_values = ei * a1 * a2 * a3\n",
    "    return acquisition_values.argsort(descending=True)\n",
    "\n",
    "ids_sorted_by_aquisition = acquisiiton(model, X, ids_acquired, fidelity_acquired, costs_acquired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71591252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
