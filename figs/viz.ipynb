{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3015818",
   "metadata": {},
   "source": [
    "# Create Plots and Visualizations for Manuscript\n",
    "\n",
    "1. Preliminary Analyis \n",
    "2. BO Runtime Distribution Histogram\n",
    "3. Search Efficiency Curves\n",
    "    1. MFBO\n",
    "    2. Comparison of MFBO, SFBO, and Random Search \n",
    "    3. Search traces for ensemble of MFBO, SFBO, and Random Search \n",
    "4. PCA Acquisition Dynamics\n",
    "5. Feature Radar Plots \n",
    "6. Feature Correlation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.text as mpltxt\n",
    "import matplotlib.cm as cm\n",
    "import pickle # for .pkl files\n",
    "import h5py   # for .jld2 files\n",
    "import os\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  figure settings \n",
    "###\n",
    "sns.set(style='ticks', palette='Set2', font_scale=1.5, rc={\"lines.linewidth\": 3})\n",
    "sns.despine()\n",
    "# plt.rcParams.update({'font.size': 16})\n",
    "# plt.rcParams['figure.dpi'] = 1200 # 600-1200 for paper quality\n",
    "save_plots = False\n",
    "\n",
    "figs_for_gif = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3417d-dfe3-46a7-81e2-0774efc19b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pal = sns.color_palette('Set2')\n",
    "colors = [pal[4], pal[1]]\n",
    "fid_to_color = {\"high\": pal[1], \"low\": pal[4]}\n",
    "algo_to_color = {\"SFBO\": pal[3], \"MFBO\": pal[2], \"random\": pal[5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f61028-45fd-44bd-8b40-ce9d57175260",
   "metadata": {},
   "outputs": [],
   "source": [
    "pal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dabf8f4b",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e453ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fideltiy values\n",
    "lf_val = 1/3 # low-fidelity\n",
    "hf_val = 2/3 # high-fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4abc10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  construct a single dictionary from those of all the runs\n",
    "###\n",
    "def get_bo_res(which_results: str, nb_run: int):\n",
    "    assert \"results\" in which_results\n",
    "    # initialize dict to store results \n",
    "    bo_res = pickle.load(\n",
    "             open('../search_results/{}/{}_run_{}.pkl'.format(which_results, \n",
    "                                                              which_results, 0), 'rb'))\n",
    "    for key in bo_res.keys():\n",
    "        bo_res[key] = []\n",
    "        \n",
    "    # iterate though the runs\n",
    "    for n in range(nb_run):\n",
    "        # get results dict for specified run\n",
    "        bo_res_file = pickle.load(\n",
    "                      open('../search_results/{}/{}_run_{}.pkl'.format(which_results, \n",
    "                                                                      which_results, n), 'rb'))\n",
    "        \n",
    "        # append results to end of list\n",
    "        for key in bo_res_file.keys():\n",
    "            key_res = bo_res_file[key]\n",
    "            bo_res[key].append(key_res)\n",
    "            \n",
    "    return bo_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58059983",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  features and molecular simulation data\n",
    "###\n",
    "file = h5py.File(\"../run_BO/targets_and_normalized_features.jld2\", \"r\")\n",
    "\n",
    "# feature matrix\n",
    "X = torch.from_numpy(np.transpose(file[\"X\"][:])) \n",
    "\n",
    "# simulation data (targets)\n",
    "y = [np.transpose(file[\"henry_y\"][:]), \n",
    "     np.transpose(file[\"gcmc_y\"][:])]  \n",
    "\n",
    "# associated simulation costs\n",
    "cost = [np.transpose(file[\"henry_total_elapsed_time\"][:]), # [min]\n",
    "        np.transpose(file[\"gcmc_elapsed_time\"][:])]        # [min]\n",
    "\n",
    "# total number of COFs in data set\n",
    "nb_COFs = X.shape[0]\n",
    "\n",
    "###\n",
    "#  Bayesian optimization data\n",
    "###\n",
    "# COF IDs used for initialization\n",
    "init_cof_ids_file = pickle.load(open('../search_results/initializing_cof_ids_normalized.pkl', 'rb'))\n",
    "init_cof_ids = init_cof_ids_file['init_cof_ids']\n",
    "\n",
    "nb_COFs_initialization = len(init_cof_ids[0])\n",
    "nb_runs = len(init_cof_ids)\n",
    "\n",
    "# random search \n",
    "random_search_res = pickle.load(open('../search_results/random_search_results.pkl', 'rb'))\n",
    "\n",
    "# multi-fidelity search\n",
    "mfbo_res = get_bo_res('mfbo_results', nb_runs)\n",
    "\n",
    "# single-fideliy search\n",
    "sfbo_res = get_bo_res('sfbo_results', nb_runs)\n",
    "\n",
    "# number of iterations per run\n",
    "nb_iters = len(mfbo_res['acquired_set'][0])\n",
    "\n",
    "###\n",
    "#  quick checks\n",
    "###\n",
    "# structure of data\n",
    "assert len(sfbo_res['ids_acquired'][0]) == nb_iters\n",
    "assert len(random_search_res['ids_acquired'][0]) == nb_COFs # nb_iterations\n",
    "assert sfbo_res['nb_COFs_initialization'][0] == nb_COFs_initialization\n",
    "\n",
    "# each run has the correct initializing COFs\n",
    "assert all([all(sfbo_res['ids_acquired'][r][:nb_COFs_initialization] == init_cof_ids[r]) \n",
    "            for r in range(nb_runs)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6f5c423",
   "metadata": {},
   "source": [
    "## Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f096feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the max number of iterations needed for any of the runs\n",
    "max_SFBO_iters = max(sfbo_res['BO_iter_top_cof_acquired'])\n",
    "max_MFBO_iters = max(mfbo_res['BO_iter_top_cof_acquired'])\n",
    "\n",
    "# the highest accumulated cost up to the max number of iterations needed\n",
    "max_SFBO_cost = np.max(sfbo_res['accumulated_cost'][:][:max_SFBO_iters+1])\n",
    "max_MFBO_cost = np.max(mfbo_res['accumulated_cost'][:][:max_MFBO_iters+1])\n",
    "\n",
    "\n",
    "print(\"The max number of iterations needed for any of the runs -\")\n",
    "print(\"\\tSFBO: {}\".format(max_SFBO_iters))\n",
    "print(\"\\tMFBO: {}\".format(max_MFBO_iters))\n",
    "print(\"The highest accumulated cost up to the max number of iterations needed -\")\n",
    "print(\"\\tSFBO: {} [hr]\".format(max_SFBO_cost))\n",
    "print(\"\\tMFBO: {} [hr]\".format(max_MFBO_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  cost of doing an exhaustive low-fidelity search \n",
    "#  and itteraing down the list with high-fidelity simulations\n",
    "#  until you simulate the Top COF.\n",
    "###\n",
    "total_lf_cost = sum(cost[0]) / 60 # [hr]\n",
    "# sort COFs by selectivity in decenting order\n",
    "lf_y_sorted = y[0].argsort()[::-1]\n",
    "# get index of high-fidelity Top COF\n",
    "hf_top_cof_id =  np.where(lf_y_sorted == np.argmax(y[1]))[0].item()\n",
    "# add in the high-fidelity cost\n",
    "lf_exhaustive_search_cost = total_lf_cost + (sum(cost[1][lf_y_sorted[:hf_top_cof_id+1]]) / 60) # [hr]\n",
    "print(\"low-fidelity exhaustive search cost = \", lf_exhaustive_search_cost, \" [hr]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd39c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  cost of SFBO to find Top COF\n",
    "#  initialized with max diverse set\n",
    "###\n",
    "sfbo_res['BO_iter_top_cof_acquired'][0] # 87\n",
    "sfbo_res['ids_acquired'][0][87] # 375\n",
    "cost[1][375] / 60 # 16.71 [hrs], hf cost of TOP COF\n",
    "sfbo_cost = sum(sfbo_res['cost_acquired'][0][:sfbo_res['BO_iter_top_cof_acquired'][0]+1]) / 60 # [hr]\n",
    "print(\"cost of SFBO search to find Top COF: \" , sfbo_cost, \" hrs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65489e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total hf cost of \n",
    "mfbo_top_cof_id = mfbo_res['BO_iter_top_cof_acquired'][0] # 47\n",
    "mfbo_res['accumulated_cost'][0][mfbo_top_cof_id] # [hrs], 57.8\n",
    "print(\"cost of MFBO search to find Top COF: \" , mfbo_res['accumulated_cost'][0][mfbo_top_cof_id], \" hrs\")\n",
    "\n",
    "# How much does the MFBO cost compare to the SFBO cost?\n",
    "ratio_mfbo_sfbo = mfbo_res['accumulated_cost'][0][mfbo_top_cof_id] / sfbo_cost\n",
    "print(\"cost ratio of MFBO to SFBO search: \", ratio_mfbo_sfbo)\n",
    "\n",
    "# How much does the MFBO cost compared to a high-fidelity exhaustive search?\n",
    "gcmc_exhaustive_search_cost = sum(cost[1]) / 60 # [hrs], exhaustive high-fidelity search\n",
    "ratio_mfbo_exh = mfbo_res['accumulated_cost'][0][mfbo_top_cof_id] / gcmc_exhaustive_search_cost\n",
    "print(\"cost ratio of MFBO to GCMC exhaustive search: \", ratio_mfbo_exh)\n",
    "\n",
    "# How much of the MFBO search cost is due to high-fidelity evalutations?\n",
    "where_fids = np.where([mfbo_res['acquired_set'][0][:, 0] == 2/3])\n",
    "mfbo_hf_fraction = sum(mfbo_res['cost_acquired'][0][where_fids[1][:9]]) / 60 # [hrs]\n",
    "mfbo_hf_fraction /= mfbo_res['accumulated_cost'][0][mfbo_top_cof_id]\n",
    "print(\"proportion of high-fidelity cost in MFBO search: \", mfbo_hf_fraction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b5f1ef9",
   "metadata": {},
   "source": [
    "# Plot Search Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  get the distribution (mean, std) of an ensemble of searches\n",
    "###\n",
    "def get_distribution(res, maxes=False):\n",
    "    # initialize arrays for dist.\n",
    "    mu      = np.zeros(nb_iters)\n",
    "    sig_bot = np.zeros(nb_iters)\n",
    "    sig_top = np.zeros(nb_iters)\n",
    "    \n",
    "    ###\n",
    "    #  look at all runs and get the dist.\n",
    "    ###\n",
    "    for i in range(1, nb_iters+1):\n",
    "        if maxes:\n",
    "            # max value acquired up to this point (over all runs)       \n",
    "            vals_at_iter = np.array([max(res[r][:i]) for r in range(nb_runs)])\n",
    "        else:\n",
    "            # make an arrey of all the values at a given iteration\n",
    "            vals_at_iter = np.array([res[r][i-1] for r in range(nb_runs)])\n",
    "        assert np.size(vals_at_iter) == nb_runs\n",
    "        mu[i-1]      = np.mean(vals_at_iter)\n",
    "        sig_bot[i-1] = np.std(vals_at_iter[vals_at_iter < mu[i-1]])\n",
    "        sig_top[i-1] = np.std(vals_at_iter[vals_at_iter > mu[i-1]])\n",
    "        \n",
    "    return  mu, sig_bot, sig_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ebb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  when, on average, is the top COF located? \n",
    "###\n",
    "mfbo_mean_iter_top_cof = int(np.round(np.mean(mfbo_res['BO_iter_top_cof_acquired'])))\n",
    "sfbo_mean_iter_top_cof = int(np.round(np.mean(sfbo_res['BO_iter_top_cof_acquired'])))\n",
    "\n",
    "print(\"Average iterations to locate top COF - \")\n",
    "print(\"MFBO:\\t\", mfbo_mean_iter_top_cof)\n",
    "print(\"SFBO:\\t\", sfbo_mean_iter_top_cof)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc35a8eb",
   "metadata": {},
   "source": [
    "### BO Ruuntime Distribution Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb01c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  make a histogram of the distribution of accumulated cost \n",
    "###\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "width = 14\n",
    "bins = np.array([int(width*i) for i in range(int(500 / width))])\n",
    "\n",
    "for i, res, search_type in zip([0, 1], [sfbo_res, mfbo_res], [\"SFBO\", \"MFBO\"]):\n",
    "    x = []\n",
    "    # color\n",
    "    color = algo_to_color[search_type]\n",
    "    \n",
    "    for r in range(nb_runs):\n",
    "        n = res['BO_iter_top_cof_acquired'][r]\n",
    "        x.append(res['accumulated_cost'][r][n])\n",
    "    \n",
    "    print(search_type, \" max search time = \", np.max(x))\n",
    "    print(search_type, \" avg search time = \", np.mean(x))\n",
    "    plt.axvline(x=np.mean(x), color=color, linestyle=\"--\", lw=1.5, alpha=0.6)\n",
    "    plt.hist(x, bins, label=search_type, color=color, alpha=0.5, zorder=10)\n",
    "\n",
    "\n",
    "###\n",
    "#  axis settings\n",
    "###\n",
    "plt.xlim(xmin=0)\n",
    "plt.xlabel('accumulated runtime to find optimal COF [hr]')\n",
    "plt.ylabel('# BO searches')\n",
    "plt.legend()\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "if save_plots:\n",
    "    plt.savefig(\"./hist_accumulated_cost_destribution.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bba26341",
   "metadata": {},
   "source": [
    "## Search Efficientcy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8bdf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "#  get the maximum selectivity from a running list\n",
    "###\n",
    "def get_y_maxes_acquired(y_acquired):\n",
    "    nb_iters = len(y_acquired)\n",
    "    return [max(y_acquired[:i+1]) for i in range(nb_iters)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6560010",
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_to_marker = {\"low\": \"x\", \"high\": \"s\"}\n",
    "ms = 22\n",
    "\n",
    "###\n",
    "#  define constants useful for plotting\n",
    "###\n",
    "iter_start = 2 * nb_COFs_initialization\n",
    "iter_top_cof_acquired = mfbo_res['BO_iter_top_cof_acquired'][0] \n",
    "iter_range = np.array(range(nb_iters)) \n",
    "\n",
    "\n",
    "_fids = mfbo_res['acquired_set'][0][:, 0]\n",
    "mfbo_ymax_acq = mfbo_res['y_max_acquired'][0][:iter_top_cof_acquired+1]\n",
    "mfbo_acc_cost = mfbo_res['accumulated_cost'][0][:iter_top_cof_acquired+1]\n",
    "\n",
    "###\n",
    "#  plot\n",
    "###\n",
    "gridspec_kw={'width_ratios': [6, 2], 'height_ratios': [4, 4]} # set ratios\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, gridspec_kw=gridspec_kw, figsize=(8, 7))\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "#  search efficiency vs accumulated cost\n",
    "#  include scatter for search start and stop\n",
    "###\n",
    "ax[0,0].scatter(np.where(_fids[:iter_top_cof_acquired+1] == lf_val)[0][1:], \n",
    "                mfbo_ymax_acq[_fids[:iter_top_cof_acquired+1] == lf_val][1:],    \n",
    "                label=r\"$\\ell=1/3$ (low)\",\n",
    "                ec=fid_to_color[\"low\"], marker=fid_to_marker[\"low\"], s=ms, zorder=10) \n",
    "\n",
    "ax[0,0].scatter(np.where(_fids[:iter_top_cof_acquired+1] == hf_val)[0], \n",
    "                mfbo_ymax_acq[_fids[:iter_top_cof_acquired+1] == hf_val],   \n",
    "                label=r\"$\\ell=2/3$ (high)\",\n",
    "                ec=fid_to_color[\"high\"], marker=fid_to_marker[\"high\"], s=ms, zorder=10)\n",
    "\n",
    "ax[0,0].axvspan(0, iter_start+0.5, color='C7', alpha=0.25, lw=0)\n",
    "\n",
    "plt.setp(ax[0,0].get_xticklabels(), visible=False) # remove yticklabels\n",
    "\n",
    "\n",
    "###  \n",
    "#  global maximum\n",
    "###\n",
    "ax[0,0].axhline(y=max(y[1]), color=\"gray\", ls=\"--\", lw=1.5)\n",
    "ax[0,0].text(10.0, max(y[1]), \n",
    "             \"largest high-fidelity\\nXe/Kr selectivity\\namong all COFs\",\n",
    "          # r\"$\\max_{\\mathbf{x} \\in \\mathcal{X}}\\, y^{(\\ell=2/3)}(\\mathbf{x})$\", \n",
    "           color=\"black\", fontsize=12, ha=\"center\", va=\"center\",\n",
    "           bbox=dict(boxstyle=\"round\",\n",
    "               ec=(1., 1., 1., 0.8),\n",
    "               fc=(1., 1., 1., 0.8),\n",
    "               )\n",
    "         )\n",
    "\n",
    "\n",
    "###\n",
    "#  histogram of selectivities\n",
    "###\n",
    "hist_cbar = sns.color_palette(\"husl\", 8)\n",
    "ax[0,1].hist(y[1], color=hist_cbar[7], alpha=0.5, orientation='horizontal')\n",
    "ax[0,1].sharey(ax[0,0])\n",
    "# ax[0,1].set_xscale('log')\n",
    "ax[0,1].set_xlabel('# COFs')\n",
    "plt.setp(ax[0,1].get_yticklabels(), visible=False) # remove yticklabels\n",
    "\n",
    "\n",
    "###\n",
    "#  Accumulated cost\n",
    "###\n",
    "ax[1,0].sharex(ax[0,0])\n",
    "\n",
    "\n",
    "ax[1,0].scatter(np.where(_fids[:iter_top_cof_acquired+1] == lf_val)[0][1:], \n",
    "                mfbo_acc_cost[_fids[:iter_top_cof_acquired+1] == lf_val][1:], \n",
    "                marker=fid_to_marker[\"low\"], ec=fid_to_color[\"low\"], s=ms, zorder=10) # fc=\"none\",\n",
    "\n",
    "ax[1,0].scatter(np.where(_fids[:iter_top_cof_acquired+1] == hf_val)[0], \n",
    "                mfbo_acc_cost[_fids[:iter_top_cof_acquired+1] == hf_val], \n",
    "                marker=fid_to_marker[\"high\"], ec=fid_to_color[\"high\"], s=ms, zorder=10)\n",
    "\n",
    "ax[1,0].axvspan(0, iter_start + 0.5, color='C7', alpha=0.25, lw=0)\n",
    "\n",
    "ax[1,0].set_ylim(ymin=-0, ymax=60)\n",
    "ax[1,0].set_xlabel('simulation #, $n$')\n",
    "ax[1,0].set_ylabel(\"accumulated\\nruntime [hr]\")\n",
    "# plt.setp(ax[1,0].get_xticklabels(), visible=False) # remove yticklabels\n",
    "\n",
    "\n",
    "###\n",
    "#  remove extra axis\n",
    "###\n",
    "plt.delaxes(ax[1,1])\n",
    "\n",
    "###\n",
    "#  axis settings\n",
    "###\n",
    "# search efficiency \n",
    "ax[0,0].set_xlim(xmin=-0, xmax=50)\n",
    "ax[0,0].set_ylim(ymin=0, ymax=20)\n",
    "ax[0,0].set_ylabel(\"largest high-fidelity\\nXe/Kr selectivity\\namong acquired COFs\")\n",
    "    #r'$\\max_{\\mathbf{x} \\in \\mathcal{A}}\\, y^{(\\ell=2/3)}(\\mathbf{x})$')\n",
    "ax[0,0].legend(title=\"fidelity\", loc=4, ncol=1)\n",
    "plt.subplots_adjust(hspace=-12, wspace=0)\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "if save_plots:\n",
    "    plt.savefig(\"./MFBO_multipanel.pdf\", bbox_inches=\"tight\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 4))  \n",
    "# markers = dict({0 : '+', 1: 'x'})\n",
    "\n",
    "for i, res, search_type in zip([0, 1], [sfbo_res, mfbo_res], [\"SFBO\", \"MFBO\"]):\n",
    "    # color\n",
    "    color = algo_to_color[search_type]\n",
    "    \n",
    "    # important indexes\n",
    "    print(search_type)\n",
    "    iter_start = nb_COFs_initialization * (i + 1) - 1 # i + 1 is convenient hack :)\n",
    "    print(iter_start)\n",
    "    iter_top_cof_acquired = res['BO_iter_top_cof_acquired'][0]\n",
    "    print(iter_top_cof_acquired)\n",
    "    print(res['accumulated_cost'][0][iter_top_cof_acquired])\n",
    "    \n",
    "    iter_range = np.array(range(nb_iters)) # range(iter_start, nb_iters)\n",
    "    \n",
    "    ###\n",
    "    #  search efficiency vs accumulated cost\n",
    "    ###\n",
    "    plt.plot(res['accumulated_cost'][0][iter_start:iter_top_cof_acquired + 1], \n",
    "             res['y_max_acquired'][0][iter_start:iter_top_cof_acquired + 1],    \n",
    "             label=search_type, \n",
    "             color=color, zorder=10)\n",
    "\n",
    "    # start and stop\n",
    "    plt.scatter([res['accumulated_cost'][0][iter_start]], \n",
    "                [res['y_max_acquired'][0][iter_start]],  \n",
    "                color=color, marker=\"o\", zorder=100)\n",
    "    \n",
    "    plt.scatter([res['accumulated_cost'][0][iter_top_cof_acquired]], \n",
    "                res['y_max_acquired'][0][iter_top_cof_acquired+1],  \n",
    "                color=color, marker=\"s\", zorder=100)\n",
    "    \n",
    "\n",
    "###\n",
    "#  random search (high-fidelity, l=1)\n",
    "###\n",
    "iter_stop = np.max(mfbo_res['BO_iter_top_cof_acquired']) + 1\n",
    "# accumulated cost\n",
    "acc_cost_mu, acc_cost_sig_bot, acc_cost_sig_top = get_distribution(random_search_res['accumulated_cost'])\n",
    "\n",
    "plt.plot(acc_cost_mu[:iter_stop], \n",
    "         random_search_res['y_rs_max_mu'][:iter_stop], \n",
    "         label=\"random\", color=algo_to_color[\"random\"], zorder=2)\n",
    "\n",
    "plt.fill_between(acc_cost_mu[:iter_stop], \n",
    "                 random_search_res['y_rs_max_mu'][:iter_stop] - \n",
    "                 random_search_res['y_rs_max_sig_bot'][:iter_stop], \n",
    "                 random_search_res['y_rs_max_mu'][:iter_stop] + \n",
    "                 random_search_res['y_rs_max_sig_top'][:iter_stop], \n",
    "                 alpha=0.25, color=algo_to_color[\"random\"], zorder=1)\n",
    "\n",
    "# start and stop\n",
    "plt.scatter([acc_cost_mu[0]], [random_search_res['y_rs_max_mu'][0]],\n",
    "            color=algo_to_color[\"random\"], marker=\"o\", zorder=100)\n",
    "\n",
    "# plt.scatter([acc_cost_mu[iter_stop-1]], [random_search_res['y_rs_max_mu'][iter_stop-1]],   \n",
    "#             color=\"C2\", marker=\"s\", zorder=100)\n",
    "\n",
    "###  \n",
    "#  global maximum\n",
    "###\n",
    "plt.axhline(y=max(y[1]), color=\"gray\", ls=\"--\", lw=1.5)\n",
    "plt.text(150.0, max(y[1]) + 0.25, \n",
    "         \"largest high-fidelity\\nXe/Kr selectivity\\namong all COFs\", fontsize=12,\n",
    "            bbox=dict(boxstyle=\"round\",\n",
    "               ec=(1., 1., 1., 0.8),\n",
    "               fc=(1., 1., 1., 0.8),\n",
    "               ),\n",
    "         ha=\"center\",\n",
    "          # r\"$\\max_{\\mathbf{x} \\in \\mathcal{X}}\\, y^{(\\ell=2/3)}(\\mathbf{x})$\", \n",
    "           color=\"black\")\n",
    "\n",
    "###\n",
    "#  axis settings\n",
    "###\n",
    "# search efficiency \n",
    "plt.xlim(xmin=0, xmax=350)\n",
    "plt.ylim(ymin=0)\n",
    "plt.xlabel(\"accumulated runtime [hr]\")\n",
    "plt.ylabel(\"largest high-fidelity\\nXe/Kr selectivity\\namong acquired COFs\")\n",
    "           #r'$\\max_{\\mathbf{x} \\in \\mathcal{A}}\\, y^{(\\ell=2/3)}(\\mathbf{x})$')\n",
    "\n",
    "# dummy plots for legend\n",
    "p_empty_cir = plt.plot([], marker='o', linestyle='none', \n",
    "                          markerfacecolor='none', markeredgecolor='grey', label='initialization')\n",
    "p_empty_sqr = plt.plot([], marker='s', linestyle='none', \n",
    "                          markerfacecolor='none', markeredgecolor='grey', label='top COF\\nfound')\n",
    "\n",
    "plt.legend(loc=4, ncol=2, fontsize=13)\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "if save_plots:\n",
    "    plt.savefig(\"./AccCost_vs_SearchEfficiency.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3924a925",
   "metadata": {},
   "source": [
    "### Plot Search Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e716bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "# loop over search types\n",
    "for i, res, search_type in zip([0, 1], [sfbo_res, mfbo_res], [\"SFBO\", \"MFBO\"]):\n",
    "    # color\n",
    "    color = algo_to_color[search_type]\n",
    "\n",
    "    # loop over search results\n",
    "    for j in range(len(res['y_max_acquired'])):\n",
    "        # zorder\n",
    "        z = np.random.randint(100)\n",
    "        # important indexes\n",
    "        iter_start = nb_COFs_initialization * (i + 1) - 1 # i + 1 is convenient hack :)\n",
    "        iter_top_cof_acquired = res['BO_iter_top_cof_acquired'][j]   \n",
    "        iter_range = np.array(range(nb_iters)) # range(iter_start, nb_iters)\n",
    "    \n",
    "        ###\n",
    "        #  search efficiency vs accumulated cost\n",
    "        ###\n",
    "        plt.plot(res['accumulated_cost'][j][iter_start:iter_top_cof_acquired + 1], \n",
    "                res['y_max_acquired'][j][iter_start:iter_top_cof_acquired + 1],    \n",
    "                color=color, zorder=z, alpha=0.25)\n",
    "\n",
    "        # start and stop\n",
    "        plt.scatter([res['accumulated_cost'][j][iter_start]], \n",
    "                    [res['y_max_acquired'][j][iter_start]],  \n",
    "                    fc=\"none\", ec=color, marker=\"o\", lw=1.5, zorder=z)\n",
    "        \n",
    "        plt.scatter([res['accumulated_cost'][j][iter_top_cof_acquired]], \n",
    "                    res['y_max_acquired'][j][iter_top_cof_acquired+1],  \n",
    "                    fc=\"none\", ec=color, marker=\"s\", lw=1.5, zorder=z)\n",
    "\n",
    "\n",
    "###\n",
    "#  random search traces\n",
    "###\n",
    "rs_ids_acquired = np.random.choice(range(len(random_search_res['ids_acquired'])), replace=False, size=100)\n",
    "# track how many of these runs find the Top COF\n",
    "rs_acquired_top_cof = 0\n",
    "# loop over selected runs\n",
    "for i, rs_search_id in enumerate(rs_ids_acquired):\n",
    "    z = np.random.randint(100)\n",
    "    rs_ids = random_search_res['ids_acquired'][rs_search_id]\n",
    "    rs_y_maxes = get_y_maxes_acquired(y[1][rs_ids.tolist()].tolist())\n",
    "    acq_top_cof = False\n",
    "    if np.argmax(y[1]) in rs_ids:\n",
    "        iter_stop = np.argmax(rs_y_maxes)\n",
    "        acq_top_cof = True\n",
    "        rs_acquired_top_cof += 1\n",
    "    else:\n",
    "        iter_stop = len(rs_y_maxes)\n",
    "    # in the event that the top COF is the initial entry\n",
    "    if iter_stop == 0:\n",
    "        iter_stop = 1\n",
    "\n",
    "    plt.plot(random_search_res['accumulated_cost'][rs_search_id].tolist()[:iter_stop], \n",
    "             rs_y_maxes[:iter_stop], \n",
    "             color=algo_to_color[\"random\"], alpha=0.1, zorder=z)\n",
    "    \n",
    "    # start and stop\n",
    "    plt.scatter([random_search_res['accumulated_cost'][rs_search_id].tolist()[0]], \n",
    "                [rs_y_maxes[0]],  \n",
    "                fc=\"none\", ec=algo_to_color[\"random\"], marker=\"o\", lw=1.5, zorder=z)\n",
    "    \n",
    "    if acq_top_cof:\n",
    "        plt.scatter([random_search_res['accumulated_cost'][rs_search_id].tolist()[iter_stop]], \n",
    "                    [rs_y_maxes[iter_stop]],  \n",
    "                    fc=\"none\", ec=algo_to_color[\"random\"], marker=\"s\", lw=1.5, zorder=z)\n",
    "\n",
    "print(rs_acquired_top_cof)\n",
    "\n",
    "###  \n",
    "#  global maximum\n",
    "###\n",
    "plt.axhline(y=max(y[1]), color=\"gray\", ls=\"--\", lw=1.5)\n",
    "plt.text(200.0, max(y[1]) + 0.4, \n",
    "         \"largest high-fidelity Xe/Kr selectivity among all COFs\",\n",
    "          # r\"$\\max_{\\mathbf{x} \\in \\mathcal{X}}\\, y^{(\\ell=2/3)}(\\mathbf{x})$\", \n",
    "           color=\"gray\", fontsize=12)\n",
    "\n",
    "###\n",
    "#  axis settings\n",
    "###\n",
    "# search efficiency \n",
    "plt.xlim(xmin=0, xmax=750)\n",
    "plt.ylim(ymin=0)\n",
    "plt.xlabel(\"accumulated runtime [hr]\")\n",
    "plt.ylabel(\"largest high-fidelity\\nXe/Kr selectivity\\namong acquired COFs\")\n",
    "    #r'$\\max_{\\mathbf{x} \\in \\mathcal{A}}\\, y^{(\\ell=2/3)}(\\mathbf{x})$')\n",
    "\n",
    "###\n",
    "#  dummy plots for legend labels\n",
    "###\n",
    "plt.plot([], [], label='SFBO', color=algo_to_color[\"SFBO\"])\n",
    "plt.plot([], [], label='MFBO', color=algo_to_color[\"MFBO\"])\n",
    "plt.plot([], [], label='random', color=algo_to_color[\"random\"])\n",
    "p_empty_cir = plt.plot([], marker='o', linestyle='none', \n",
    "                          markerfacecolor='none', markeredgecolor='grey', label='initialization')\n",
    "p_empty_sqr = plt.plot([], marker='s', linestyle='none', \n",
    "                          markerfacecolor='none', markeredgecolor='grey', label='top COF\\nfound')\n",
    "\n",
    "plt.legend(loc=4, ncol=2)\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "if save_plots:\n",
    "    plt.savefig(\"./AccCost_vs_SearchEfficiency_AllRuns.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04c7a88e",
   "metadata": {},
   "source": [
    "# Pirinciple Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d271a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X_2D = pca.transform(X)\n",
    "\n",
    "###\n",
    "#  test point\n",
    "###\n",
    "a = torch.from_numpy(np.array([X[:, i].mean() for i in range(X.size()[1])]))\n",
    "X_center = pca.transform(a.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad16c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_name = cm.summer_r # sequential colormap (reversed)\n",
    "\n",
    "###\n",
    "#  low dimensional (PCA) visualization of the entire dataset\n",
    "###\n",
    "fig = plt.figure()\n",
    "plt.scatter(X_2D[:, 0], X_2D[:, 1], c=y[1], cmap=cmap_name, s=10, alpha=0.6)\n",
    "\n",
    "###\n",
    "#  axis commands\n",
    "###\n",
    "ax_lim = max([np.max(X_2D), abs(np.min(X_2D))]) + 0.2\n",
    "plt.xlim([-ax_lim, ax_lim])\n",
    "plt.ylim([-ax_lim, ax_lim])\n",
    "\n",
    "plt.xticks()\n",
    "plt.yticks()\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "cb = plt.colorbar(fraction=0.03, pad=0.04)\n",
    "cb.set_label(label=\"$y^{(\\ell=2/3)}_{Xe/Kr}$\")\n",
    "\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "\n",
    "plt.tight_layout()\n",
    "if save_plots:\n",
    "    plt.savefig(\"./PCA_feature_space_colored_by_GCMC_Selectivity.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b90dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = 6\n",
    "acq = mfbo_res['acquired_set'][0][:nb]\n",
    "lf_acq = acq[acq[:, 0] == lf_val, :] # low-fidelity\n",
    "lf_acq[:nb, 1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b383baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_acq = acq[acq[:, 0] == hf_val, :] # high-fidelity\n",
    "hf_acq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_step = np.ceil((mfbo_res['BO_iter_top_cof_acquired'][0] - 2*nb_COFs_initialization) / 5)\n",
    "\n",
    "nb_acquired = [2*nb_COFs_initialization + i*int(panel_step) for i in range(6)]\n",
    "\n",
    "nb_acquired[len(nb_acquired) - 1] = mfbo_res['BO_iter_top_cof_acquired'][0] + 1 # have to adjust the indexing\n",
    "\n",
    "# set up figure and image grid\n",
    "fig = plt.figure(figsize=[3*6.4 + 0.5, 4.8*2 + 0.5])\n",
    "\n",
    "grid = ImageGrid(fig, 111,          # as in plt.subplot(111)\n",
    "                 nrows_ncols=(2, 3),\n",
    "                 axes_pad=0.2,\n",
    "                 share_all=True,\n",
    "                 cbar_location=\"right\",\n",
    "                 cbar_mode=\"single\",\n",
    "                 cbar_size=\"7%\",\n",
    "                 cbar_pad=0.15,\n",
    "                 )\n",
    "\n",
    "# add data to image grid\n",
    "for (i, nb), ax in zip(enumerate(nb_acquired), grid):\n",
    "    acq = mfbo_res['acquired_set'][0][:nb]\n",
    "    lf_acq = acq[acq[:, 0] == lf_val, :] # low-fidelity\n",
    "    hf_acq = acq[acq[:, 0] == hf_val, :] # high-fidelity\n",
    "    assert len(lf_acq) + len(hf_acq) == len(acq)\n",
    "\n",
    "    ###\n",
    "    #  plot PCA for all COFs\n",
    "    ###\n",
    "    pca_base = ax.scatter(X_2D[:, 0], X_2D[:, 1], c=y[1], cmap=cmap_name,\n",
    "                             facecolor='none', s=15, alpha=0.8) \n",
    "    \n",
    "\n",
    "    ###\n",
    "    #  indicate top COF\n",
    "    #  arrow is drawn from (x, y) to (x+dx, y+dy)\n",
    "    ###\n",
    "    top_cof_id = np.argmax(y[1])\n",
    "    eps = 0.12\n",
    "    ax.arrow(X_2D[top_cof_id, 0]-eps, X_2D[top_cof_id, 1]+eps, eps*0.7, -eps*0.7,\n",
    "             head_width=0.025, color='k', alpha=0.6)\n",
    "    ax.text(X_2D[top_cof_id, 0]-3.95*eps, X_2D[top_cof_id, 1]+1.2*eps, 'optimal\\n   COF', color=\"grey\")\n",
    "\n",
    "    ###\n",
    "    #  indicate acquired points at the given iteration\n",
    "    ###\n",
    "    # low-fidelity\n",
    "    ax.scatter(X_2D[lf_acq[:nb, 1].astype(int), 0], X_2D[lf_acq[:nb, 1].astype(int), 1], \n",
    "                  label=\"$\\ell=1/3$ (low-fidelity)\",\n",
    "                  color='k', marker='x', s=35, lw=0.45, zorder=2) \n",
    "    # high-fidelity\n",
    "    ax.scatter(X_2D[hf_acq[:nb, 1].astype(int), 0], X_2D[hf_acq[:nb, 1].astype(int), 1], \n",
    "               label=\"$\\ell=2/3$ (high-fidelity)\",\n",
    "               fc='none', ec='k', marker='s', s=40, lw=0.5, zorder=10)\n",
    "    \n",
    "\n",
    "    \n",
    "    # subplot titles --- use ax.text \n",
    "    if i == 0:\n",
    "        ax.set_title('(initialization)')\n",
    "    ax.text(0.5, 1.0, '$n=${} simulations'.format(nb_acquired[i]), ha='center')\n",
    "        \n",
    "    ax.tick_params(axis='x')\n",
    "    ax.set_aspect('equal', 'box')\n",
    "\n",
    "###\n",
    "#  colorbar\n",
    "###\n",
    "cb = ax.cax.colorbar(pca_base)\n",
    "# cb.set_label(label=\"$y^{(\\ell=2/3)}_{Xe/Kr}$\", fontsize=24)\n",
    "cb.set_label(label=\"high-fidelity Xe/Kr selectivity\", fontsize=24)\n",
    "\n",
    "###\n",
    "#  axis commands\n",
    "###\n",
    "grid[0].legend(loc=(0.013, 0.013))\n",
    "fig.text(0.155, 0.52, 'principal component 2', ha='center', va='center', rotation='vertical', fontsize=24)\n",
    "fig.text(0.52, 0.05, 'principal component 1', ha='center', fontsize=24)\n",
    "\n",
    "grid[0].set_xlim([-ax_lim, ax_lim])\n",
    "grid[0].set_ylim([-ax_lim, ax_lim])\n",
    "\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig(\"./MFBO_PCA_dynamics.pdf\", bbox_inches=\"tight\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5349979",
   "metadata": {},
   "source": [
    "### make PCA figs to compile into a GIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39181c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if figs_for_gif:\n",
    "    iter_stop = mfbo_res['BO_iter_top_cof_acquired'][0] - 2*nb_COFs_initialization\n",
    "\n",
    "    nb_acquired = [2*nb_COFs_initialization + i for i in range(iter_stop)]\n",
    "\n",
    "    nb_acquired[len(nb_acquired) - 1] = mfbo_res['BO_iter_top_cof_acquired'][0] + 1 # have to adjust the indexing\n",
    "\n",
    "\n",
    "\n",
    "    # add data to image grid\n",
    "    for (i, nb) in enumerate(nb_acquired):\n",
    "        acq = mfbo_res['acquired_set'][0][:nb]\n",
    "        lf_acq = acq[acq[:, 0] == lf_val, :] # low-fidelity\n",
    "        hf_acq = acq[acq[:, 0] == hf_val, :] # high-fidelity\n",
    "        assert len(lf_acq) + len(hf_acq) == len(acq)\n",
    "\n",
    "        ###\n",
    "        #  figure\n",
    "        ###\n",
    "        fig = plt.figure(figsize=(6, 6), dpi=300)\n",
    "        cmap_name = cm.summer_r # sequential colormap (reversed)\n",
    "        grid = ImageGrid(fig, 111,          # as in plt.subplot(111)\n",
    "                    nrows_ncols=(1, 1),\n",
    "                    axes_pad=0.2,\n",
    "                    share_all=True,\n",
    "                    cbar_location=\"right\",\n",
    "                    cbar_mode=\"single\",\n",
    "                    cbar_size=\"7%\",\n",
    "                    cbar_pad=0.15,\n",
    "                    )\n",
    "\n",
    "        ax = grid[0]\n",
    "        ###\n",
    "        #  plot PCA for all COFs\n",
    "        ###\n",
    "        pca_base = ax.scatter(X_2D[:, 0], X_2D[:, 1], c=y[1], cmap=cmap_name,\n",
    "                                facecolor='none', s=15, alpha=0.8) \n",
    "        \n",
    "\n",
    "        ###\n",
    "        #  indicate top COF\n",
    "        #  arrow is drawn from (x, y) to (x+dx, y+dy)\n",
    "        ###\n",
    "        top_cof_id = np.argmax(y[1])\n",
    "        eps = 0.12\n",
    "        ax.arrow(X_2D[top_cof_id, 0]-eps, X_2D[top_cof_id, 1]+eps, eps*0.7, -eps*0.7,\n",
    "                head_width=0.025, color='k', alpha=0.6)\n",
    "        ax.text(X_2D[top_cof_id, 0]-3.95*eps, X_2D[top_cof_id, 1]+1.2*eps, 'optimal\\n   COF', color=\"grey\")\n",
    "\n",
    "        ###\n",
    "        #  indicate acquired points at the given iteration\n",
    "        ###\n",
    "        # low-fidelity\n",
    "        ax.scatter(X_2D[lf_acq[:nb, 1].astype(int), 0], X_2D[lf_acq[:nb, 1].astype(int), 1], \n",
    "                    label=\"$\\ell=1/3$ (low-fidelity)\",\n",
    "                    color='k', marker='x', s=35, lw=0.45, zorder=2) \n",
    "        # high-fidelity\n",
    "        ax.scatter(X_2D[hf_acq[:nb, 1].astype(int), 0], X_2D[hf_acq[:nb, 1].astype(int), 1], \n",
    "                label=\"$\\ell=2/3$ (high-fidelity)\",\n",
    "                fc='none', ec='k', marker='s', s=40, lw=0.5, zorder=10)\n",
    "\n",
    "        # subplot titles --- use ax.text \n",
    "        if i == 0:\n",
    "            ax.text(0.1, 1.0, '(initialization) {} experiments'.format(nb_acquired[i]), ha='center')\n",
    "            # ax.text('(initialization)')\n",
    "        else:\n",
    "            ax.text(0.5, 1.0, '{} experiments'.format(nb_acquired[i]), ha='center')\n",
    "            \n",
    "        ax.tick_params(axis='x')\n",
    "        ax.set_aspect('equal', 'box')\n",
    "\n",
    "        ###\n",
    "        #  colorbar\n",
    "        ###\n",
    "        cb = ax.cax.colorbar(pca_base)\n",
    "        # cb.set_label(label=\"$y^{(\\ell=2/3)}_{Xe/Kr}$\", fontsize=24)\n",
    "        cb.set_label(label=\"high-fidelity Xe/Kr\\nselectivity\", fontsize=24)\n",
    "\n",
    "        \n",
    "\n",
    "        ###\n",
    "        #  axis commands\n",
    "        ###\n",
    "        grid[0].legend(loc=(0.013, 0.013))\n",
    "        # fig.text(0.155, 0.52, 'principal component 2', ha='center', va='center', rotation='vertical', fontsize=24)\n",
    "        fig.text(-0.025, 0.52, 'principal component 2', ha='center', va='center', rotation='vertical', fontsize=24)\n",
    "        # fig.text(0.52, 0.05, 'principal component 1', ha='center', fontsize=24)\n",
    "        fig.text(0.52, 0.035, 'principal component 1', ha='center', fontsize=24)\n",
    "\n",
    "        grid[0].set_xlim([-ax_lim, ax_lim])\n",
    "        grid[0].set_ylim([-ax_lim, ax_lim])\n",
    "\n",
    "        if save_plots:\n",
    "            plt.savefig(\"./pca_dynamics/MFBO_PCA_dynamics_{}.png\".format(i), bbox_inches=\"tight\", format=\"png\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "006bc77b",
   "metadata": {},
   "source": [
    "# Radar Plot of Feature Vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e2d9ad9",
   "metadata": {},
   "source": [
    "custom scale on each axis adapted from code [here](https://datascience.stackexchange.com/questions/6084/how-do-i-create-a-complex-radar-chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e704fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  load data\n",
    "###\n",
    "cof_file = h5py.File(\"top_COF_feature_vector.jld2\", \"r\")\n",
    "values = np.array(cof_file['features']).tolist() # has 14 entries\n",
    "print(\"Top COF ID = \", top_cof_id)\n",
    "print(\"Top COF feature vector:\\n\", values)\n",
    "\n",
    "# descriptors\n",
    "property_type = ['geometric', 'chemical']\n",
    "descriptors = []\n",
    "\n",
    "for prop in property_type:\n",
    "    filename = \"../descriptors/{}_properties.csv\".format(prop)\n",
    "    df = pd.read_csv(filename)\n",
    "    for descriptor in df.columns:\n",
    "        if descriptor != \"crystal_name\": \n",
    "            descriptors.append(descriptor)\n",
    "            \n",
    "###\n",
    "#  fix labels for plotting\n",
    "###\n",
    "pretty_des_names = dict({'pore_diameter_Å': 'pore\\ndiameter [Å]', \n",
    "                         'void_fraction': 'void fraction',\n",
    "                         'surface_area_m²g⁻¹': 'surface area [m² g⁻¹]',\n",
    "                         'crystal_density': 'crystal density [kg m⁻³]'\n",
    "                        })\n",
    "\n",
    "for n, des in enumerate(descriptors):\n",
    "    if des in pretty_des_names.keys():\n",
    "        descriptors[n] = pretty_des_names[des] + ''\n",
    "    else:\n",
    "        descriptors[n] = descriptors[n] + \"\"\n",
    "        \n",
    "print(\"feature labels: \\n\", descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e58a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _scale_data(data, ranges):\n",
    "    \"\"\"scales data[1:] to ranges[0]\"\"\"\n",
    "    for d, (y1, y2) in zip(data[1:], ranges[1:]):\n",
    "        assert (y1 <= d <= y2) or (y2 <= d <= y1)\n",
    "    x1, x2 = ranges[0]\n",
    "    sdata = [data[0]] \n",
    "    for d, (y1, y2) in zip(data[1:], ranges[1:]):\n",
    "        sdata.append((d - y1) / (y2 - y1) * (x2 - x1) + x1)\n",
    "    return sdata\n",
    "\n",
    "class ComplexRadar():\n",
    "    def __init__(self, fig, variables, ranges, n_ordinate_levels=6):\n",
    "        # divide circle into equal parts\n",
    "        angles = np.arange(0, 360, 360./len(variables))\n",
    "        \n",
    "        # make a list of the axes (one per dscriptor variable)\n",
    "        # [0.1, 0.1, 0.9, 0.9]\n",
    "        axes = [fig.add_axes([0.0, 0.0, 1.0, 1.0], polar=True, label=\"axes{}\".format(i)) \n",
    "                for i in range(len(variables))]\n",
    "        \n",
    "        # put variable name at the correct angle\n",
    "        # adjust rotation of text for readability\n",
    "        l, text = axes[0].set_thetagrids(angles, labels=variables, fontsize=26)\n",
    "        [txt.set_rotation(angle-90) for txt, angle in zip(text, angles)] \n",
    "        \n",
    "        # overlay each axis\n",
    "        for ax in axes[1:]:\n",
    "            ax.patch.set_visible(False)\n",
    "            ax.grid(\"off\", lw=1)\n",
    "            ax.xaxis.set_visible(False)\n",
    "            \n",
    "        # specify grid labels\n",
    "        for i, ax in enumerate(axes): \n",
    "            # ax.set_axisbelow(False)\n",
    "            ax.yaxis.set_zorder(0)\n",
    "\n",
    "            grid = np.linspace(*ranges[i], num=n_ordinate_levels)\n",
    "            gridlabel = [] #[\"{0:.2f}\".format(round(x, 2)) for x in grid]\n",
    "            for j, x in enumerate(grid):\n",
    "                if j == 0 or j == len(grid)-1:\n",
    "                    gridlabel.append(\"{0:.1f}\".format(round(x, 2)))\n",
    "                else:\n",
    "                    gridlabel.append('')\n",
    "            \n",
    "            gridlabel[0] = \"\" # clean up origin\n",
    "\n",
    "            lines, labels = ax.set_rgrids(grid, labels=gridlabel, angle=angles[i], fontsize=20, color='grey') \n",
    "            \n",
    "            ###\n",
    "            #  Go through labels and adjust alignment based on where\n",
    "            #  it is in the circle.\n",
    "            ###\n",
    "            for label in labels:\n",
    "                if angles[i] == 0:\n",
    "                    label.set_horizontalalignment('right')\n",
    "                    label.set_verticalalignment('bottom')\n",
    "                elif 0 < angles[i] < 55:\n",
    "                    label.set_horizontalalignment('right')\n",
    "                    label.set_verticalalignment('top')\n",
    "                elif 55 <= angles[i] < 90:\n",
    "                    label.set_horizontalalignment('right')\n",
    "                    label.set_verticalalignment('top')\n",
    "                elif 90 <= angles[i] < 180:\n",
    "                    label.set_horizontalalignment('left')\n",
    "                    label.set_verticalalignment('top')\n",
    "                elif angles[i] == 180.0:\n",
    "                    label.set_horizontalalignment('left')\n",
    "                    label.set_verticalalignment('bottom')\n",
    "                elif 180 < angles[i] < 225:\n",
    "                    label.set_horizontalalignment('left')\n",
    "                    label.set_verticalalignment('bottom')\n",
    "                elif 225 <=  angles[i] < 270:\n",
    "                    label.set_horizontalalignment('left')\n",
    "                    label.set_verticalalignment('bottom')\n",
    "                elif 270 <=  angles[i] < 300:\n",
    "                    label.set_horizontalalignment('right')\n",
    "                    label.set_verticalalignment('bottom')\n",
    "                elif 300 <= angles[i]:\n",
    "                    label.set_horizontalalignment('right')\n",
    "                    label.set_verticalalignment('baseline')\n",
    "            \n",
    "            # if i == 0:\n",
    "            #     ax.set_zorder(10)\n",
    "            # else:\n",
    "            #     ax.set_zorder(10)\n",
    "            ax.spines[\"polar\"].set_visible(False)\n",
    "            ax.set_ylim(*ranges[i])\n",
    "        \n",
    "        ###    \n",
    "        #  variables for plotting\n",
    "        ###\n",
    "        self.angle = np.deg2rad(np.r_[angles, angles[0]])\n",
    "        self.ranges = ranges\n",
    "        self.ax = axes[0]\n",
    "\n",
    "        \n",
    "    def plot(self, data, *args, **kw):\n",
    "        sdata = _scale_data(data, self.ranges)\n",
    "        self.ax.plot(self.angle, np.r_[sdata, sdata[0]], *args, **kw)\n",
    "        # put this one on top so gridlines don't overlap data\n",
    "        self.ax.set_zorder(100)\n",
    "        \n",
    "        self.ax.spines[\"polar\"].set_visible(True)\n",
    "\n",
    "        ###\n",
    "        #  Go through labels and adjust alignment based on where\n",
    "        #  it is in the circle.\n",
    "        ###\n",
    "        for label, angle in zip(self.ax.get_xticklabels(), self.angle):\n",
    "            ang = np.rad2deg(angle)\n",
    "            if ang == 0:\n",
    "                label.set_horizontalalignment('left')\n",
    "                label.set_verticalalignment('center_baseline')\n",
    "            elif 0 < ang < 90:\n",
    "                label.set_horizontalalignment('left')\n",
    "                label.set_verticalalignment('center_baseline')\n",
    "            elif 55 <= ang < 90:\n",
    "                label.set_horizontalalignment('right')\n",
    "                label.set_verticalalignment('bottom')\n",
    "            elif 90 <= ang < 180:\n",
    "                label.set_horizontalalignment('center')\n",
    "                label.set_verticalalignment('center_baseline')\n",
    "            elif ang == 180.0:\n",
    "                label.set_horizontalalignment('center')\n",
    "                label.set_verticalalignment('center')\n",
    "            elif 180 < ang < 225:\n",
    "                label.set_horizontalalignment('center')\n",
    "                label.set_verticalalignment('center_baseline')\n",
    "            elif 225 <=  ang < 270:\n",
    "                label.set_horizontalalignment('center')\n",
    "                label.set_verticalalignment('center_baseline')\n",
    "            elif 270 <=  ang:\n",
    "                label.set_horizontalalignment('left')\n",
    "                label.set_verticalalignment('center')\n",
    "        ###        \n",
    "        #  make the pannel transparent so you can see the \n",
    "        #  plot labels below it\n",
    "        ###\n",
    "        self.ax.patch.set_alpha(0.0)\n",
    "\n",
    "    def fill(self, data, *args, **kw):\n",
    "        sdata = _scale_data(data, self.ranges)\n",
    "        self.ax.fill(self.angle, np.r_[sdata, sdata[0]], *args, **kw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45edec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  data\n",
    "###\n",
    "variables = tuple(descriptors)\n",
    "data = tuple(values)\n",
    "# ymax will be 10**(base) \n",
    "ranges = []\n",
    "for val in values:\n",
    "    if 0 <= val <= 1:\n",
    "        base = 0\n",
    "    else:\n",
    "        base = int(np.ceil(np.log10(val)))\n",
    "    ranges.append((0, 10**base))\n",
    "    \n",
    "###\n",
    "#  plotting\n",
    "###\n",
    "fig1 = plt.figure(figsize=(8, 8)) \n",
    "radar = ComplexRadar(fig1, variables, ranges)\n",
    "radar.plot(data, color='red', alpha=1.0, lw=3) \n",
    "# radar.fill(data, color='red', alpha=0.25)\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig(\"./top_COF_raw_feature_vector_radar.pdf\", bbox_inches=\"tight\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c5eae14",
   "metadata": {},
   "source": [
    "### radar plot multiple cofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de8050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  get COF ids \n",
    "###\n",
    "num_at_performance = 15 # how many ids to get\n",
    "\n",
    "# np.argsort() is in ascending order, so top COFs at the end of list\n",
    "poor_performning_cofs = np.argsort(y[1])[:num_at_performance]\n",
    "print(\"IDs of top performing COFs: \", poor_performning_cofs)\n",
    "\n",
    "high_performing_cofs = np.argsort(y[1])[-num_at_performance:]\n",
    "print(\"IDs of top performing COFs: \", high_performing_cofs)\n",
    "\n",
    "# compile into a single list\n",
    "cof_ids_to_include = [poor_performning_cofs, high_performing_cofs]\n",
    "performing_cofs = np.array([item for sublist in cof_ids_to_include for item in sublist])\n",
    "\n",
    "\n",
    "###\n",
    "#  load in data\n",
    "###\n",
    "targets_and_features = h5py.File(\"targets_and_raw_features.jld2\", \"r\")\n",
    "# keys: ['X', 'gcmc_elapsed_time', 'gcmc_y', 'henry_total_elapsed_time', 'henry_y'\n",
    "# targets_and_features.keys()\n",
    "cof_feature_values = np.array(targets_and_features['X'])\n",
    "print('shape of feature matrix: {}'.format(cof_feature_values.shape)) # (14, 608) => each featue is a \n",
    "# len(cof_feature_values[:, 0]) # 14, features for a given COF\n",
    "# len(cof_feature_values[1])    # 608, given feature for all COFs\n",
    "\n",
    "\n",
    "###\n",
    "#  get feature vector for desired COFs\n",
    "###\n",
    "performing_cof_features = cof_feature_values[:, performing_cofs]\n",
    "\n",
    "\n",
    "###\n",
    "#  construct data for radar plot\n",
    "###\n",
    "variables = tuple(descriptors) # descriptors defined above\n",
    "values = performing_cof_features\n",
    "data = [tuple(v) for v in values.transpose()]\n",
    "# len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb6c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  get data ranges for grid\n",
    "###\n",
    "ranges = [(0, 0) for i in range(len(values))] \n",
    "for k, feature in enumerate(values):\n",
    "    for val in feature:\n",
    "        if 0 <= val <= 1:\n",
    "            base = 0\n",
    "        else: \n",
    "            base = int(np.ceil(np.log10(val)))\n",
    "\n",
    "        if int(ranges[k][1]) <= 10**base:\n",
    "            ranges[k] = tuple([0, 10**base])\n",
    "\n",
    "print(ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5aa921",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#  plotting\n",
    "###\n",
    "cpl = sns.color_palette(\"hls\", 8)\n",
    "fig1 = plt.figure(figsize=(8, 8)) \n",
    "radar = ComplexRadar(fig1, variables, ranges)\n",
    "\n",
    "# define a color set\n",
    "bottom_c = sns.color_palette(\"husl\", 8)[0]\n",
    "top_c = sns.color_palette(\"husl\", 8)[3]\n",
    "\n",
    "for j, d in enumerate(data):\n",
    "    if j < num_at_performance:\n",
    "        color = bottom_c\n",
    "    else:\n",
    "        color = top_c\n",
    "    radar.plot(d, color=color, alpha=0.45, lw=2) \n",
    "    # radar.fill(d, color=color, alpha=0.15)\n",
    "\n",
    "###\n",
    "#  dummy plots for legend labels\n",
    "###\n",
    "p_empty_sqr = plt.plot([], linestyle='-', label='top COFs', color=top_c, alpha=0.45)\n",
    "\n",
    "p_empty_cir = plt.plot([], linestyle='-', label='bottom COFs', color=bottom_c, alpha=0.45)\n",
    "\n",
    "plt.legend(loc=[1.05, 0.00], ncol=1, title='performance')\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig(\"./compare_COFs_raw_feature_vectors_radar.pdf\", bbox_inches=\"tight\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26274e54",
   "metadata": {},
   "source": [
    "# Plot Correlation of Features to Selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  features and molecular simulation data\n",
    "###\n",
    "normalization = \"normalized\" \n",
    "raw_feature_file = h5py.File(\"targets_and_raw_features.jld2\".format(normalization), \"r\")\n",
    "\n",
    "# feature matrix\n",
    "X_raw = torch.from_numpy(np.transpose(raw_feature_file[\"X\"][:])) \n",
    "\n",
    "# simulation data\n",
    "y_raw = [np.transpose(raw_feature_file[\"henry_y\"][:]), \n",
    "     np.transpose(raw_feature_file[\"gcmc_y\"][:])]  \n",
    "\n",
    "# associated simulation costs\n",
    "raw_cost = [np.transpose(raw_feature_file[\"henry_total_elapsed_time\"][:]), # [min]\n",
    "        np.transpose(raw_feature_file[\"gcmc_elapsed_time\"][:])]        # [min]\n",
    "\n",
    "X_raw.shape\n",
    "print(\"X_raw[i, :] - each row (i) is a COF\")\n",
    "print(\"X_raw[:, j] - each column (j) is a feature\")\n",
    "print(\"list of features:\")\n",
    "descriptors[0] = 'pore diameter [Å]' # need to clean up name\n",
    "print(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0531c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptors[0] = 'pore diameter [Å]' # need to clean up name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb9cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the features and plot the correlatins\n",
    "for i, des in enumerate(descriptors):\n",
    "    lbl_fs = 24 # label fontsize\n",
    "    if i > 3:\n",
    "        lbl_fs = 36\n",
    "\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.scatter(X_raw[:, i], y_raw[1], fc=\"none\", ec=\"C2\")\n",
    "    #  kinetic diameter of Kr (~3.60 Å) and Xe (~4.1 Å)\n",
    "    if 'diameter' in des:\n",
    "        # plt.axvline(x=3.60, label=\"Kr\", color='k', lw=0.5, linestyle=\":\")\n",
    "        plt.axvline(x=3.96, label=\"Xe 4.1 Å\", color='k', lw=0.5, linestyle=\"--\")\n",
    "        plt.legend(title=r\"Kinetic diameter\", fontsize=20, title_fontsize=20)\n",
    "\n",
    "    if des in ['B', 'O', 'C', 'H', 'Si', 'N', 'S', 'P', 'halogens', 'metals']:\n",
    "        plt.xlabel(\"fraction \" + des, fontsize=lbl_fs)\n",
    "    else:\n",
    "        plt.xlabel(des, fontsize=lbl_fs)\n",
    "\n",
    "    plt.ylabel(r\"$y^{(\\ell=2/3)}(\\mathbf{x})$\", fontsize=lbl_fs)\n",
    "    \n",
    "    plt.xlim(xmin=0)\n",
    "    if X_raw[:, i].max().item() < 1.1:\n",
    "        plt.xlim(xmax=1.0)\n",
    "\n",
    "    plt.ylim(ymin=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_plots:\n",
    "        if ('[' in des):\n",
    "            # remove units from filename\n",
    "            nn = np.where(['[' in s for s in des.split()])[0].item()\n",
    "            fig_name = des.split()[:nn]\n",
    "        else:\n",
    "            fig_name = des.split()\n",
    "        \n",
    "        plt.savefig(\"./feature_correlations/selectivity_vs_{}.pdf\".format(\"_\".join(fig_name)), format='pdf')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "23d6f7179e0bc929ef338139025b84bf12b8362d4f462c6c3a682d200e09aab4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
