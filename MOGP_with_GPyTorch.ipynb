{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1b630d1",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "1. figure out the shape issue with the model inputs\n",
    "    - currently: `model.num_outputs = 5` (pretty sure this is due to num training pts)\n",
    "    - what are `task_feature`\n",
    "    - maybe look at input_constructor\n",
    "    - can it handle heterotopic data? We are only training henry on henry data and gcmc on gcmc data.\n",
    "2. look over GPyTorch models\n",
    "    - figure out how to define the MultiTask model\n",
    "    - consider just writing this notebook in python\n",
    "3. Write MultiFidelity Expectied Improvement Acquisition function\n",
    "4. Perform BO and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7fef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2\n",
    "using PyPlot\n",
    "using StatsBase # Statistics\n",
    "using Distributions\n",
    "\n",
    "using PyCall\n",
    "@pyimport torch \n",
    "@pyimport gpytorch\n",
    "@pyimport botorch\n",
    "\n",
    "\n",
    "# config plot settings\n",
    "PyPlot.matplotlib.style.use(\"ggplot\")\n",
    "rcParams = PyPlot.PyDict(PyPlot.matplotlib.\"rcParams\")\n",
    "rcParams[\"font.size\"] = 16;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803e9004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Symbol}:\n",
       " :X\n",
       " :henry_y\n",
       " :gcmc_y"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#  load data\n",
    "###\n",
    "@load joinpath(pwd(), \"targets_and_normalized_features.jld2\") X henry_y gcmc_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888c8e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject tensor([[ 0.8622,  0.8699],\n",
       "        [-0.8699, -0.8621]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#  Randomly select COFs to train GP\n",
    "###\n",
    "nb_COFs_initialization = 2\n",
    "ids_acquired_gcmc  = StatsBase.sample(1:length(gcmc_y), nb_COFs_initialization, replace=false)\n",
    "ids_acquired_henry = StatsBase.sample(1:length(henry_y), nb_COFs_initialization, replace=false)\n",
    "\n",
    "###\n",
    "#  construct input tensors\n",
    "###\n",
    "train_X = torch.from_numpy(X[ids_acquired, :])   # feature vectors\n",
    "y1 = torch.from_numpy(henry_y[ids_acquired])     # low-fidelity\n",
    "y2 = torch.from_numpy(gcmc_y[ids_acquired_gcmc]) # high-fidelity\n",
    "\n",
    "\n",
    "y_acquired = torch.stack([y1, y2], -1)\n",
    "# standardize outputs using *only currently acquired data*\n",
    "y_acquired = (y_acquired - torch.mean(y_acquired)) / torch.std(y_acquired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bb0170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP(train_X, train_Y, \n",
    "#     iteration_fidelity=None, data_fidelity=None, linear_truncated=True, nu=2.5, likelihood=None, \n",
    "#     outcome_transform=None, input_transform=None)\n",
    "# \n",
    "# \n",
    "# botorch.models.model_list_gp_regression.ModelListGP()\n",
    "# botorch.models.gpytorch.MultiTaskGPyTorchModel\n",
    "# botorch.models.gp_regression.SingleTaskGP(train_X, train_Y, likelihood=\"None\")\n",
    "# model = botorch.models.gp_regression.SingleTaskGP(train_X, y_acquired)\n",
    "# model = botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP(train_X, y_acquired, data_fidelity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e4f003c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject MultiTaskGP(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (noise_prior): GammaPrior()\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (mean_module): ConstantMean()\n",
       "  (covar_module): ScaleKernel(\n",
       "    (base_kernel): MaternKernel(\n",
       "      (lengthscale_prior): GammaPrior()\n",
       "      (raw_lengthscale_constraint): Positive()\n",
       "    )\n",
       "    (outputscale_prior): GammaPrior()\n",
       "    (raw_outputscale_constraint): Positive()\n",
       "  )\n",
       "  (task_covar_module): IndexKernel(\n",
       "    (raw_var_constraint): Positive()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#  Construct GP\n",
    "#  note - I should be able to include the noise if I add it to the data dictionary -> FixedNoiseMultiTaskGP\n",
    "###\n",
    "task_feature = 2\n",
    "model = botorch.models.multitask.MultiTaskGP(train_X, y_acquired, task_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78e98ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7bc93be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject ExactMarginalLogLikelihood(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (noise_prior): GammaPrior()\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (model): MultiTaskGP(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): GammaPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ConstantMean()\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): MaternKernel(\n",
       "        (lengthscale_prior): GammaPrior()\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (outputscale_prior): GammaPrior()\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "    (task_covar_module): IndexKernel(\n",
       "      (raw_var_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "# mll = gpytorch.mlls.SumMarginalLogLikelihood(model.likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b72933a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "PyError ($(Expr(:escape, :(ccall(#= /home/ng/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:43 =# @pysym(:PyObject_Call), PyPtr, (PyPtr, PyPtr, PyPtr), o, pyargsptr, kw))))) <class 'RuntimeError'>\nRuntimeError('The size of tensor a (2) must match the size of tensor b (7) at non-singleton dimension 1')\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/fit.py\", line 124, in fit_gpytorch_model\n    mll, _ = optimizer(mll, track_iterations=False, **kwargs)\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/optim/fit.py\", line 239, in fit_gpytorch_scipy\n    res = minimize(\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 623, in minimize\n    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\", line 306, in _minimize_lbfgsb\n    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/optimize.py\", line 261, in _prepare_scalar_function\n    sf = ScalarFunction(fun, x0, args, grad, hess,\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 140, in __init__\n    self._update_fun()\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 233, in _update_fun\n    self._update_fun_impl()\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in update_fun\n    self.f = fun_wrapped(self.x)\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 134, in fun_wrapped\n    return fun(np.copy(x), *args)\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n    self._compute_if_needed(x, *args)\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n    fg = self.fun(x, *args)\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/optim/utils.py\", line 220, in _scipy_objective_and_grad\n    raise e  # pragma: nocover\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/optim/utils.py\", line 214, in _scipy_objective_and_grad\n    loss = -mll(*args).sum()\n  File \"/home/ng/.local/lib/python3.8/site-packages/gpytorch/module.py\", line 30, in __call__\n    outputs = self.forward(*inputs, **kwargs)\n  File \"/home/ng/.local/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\", line 62, in forward\n    res = output.log_prob(target)\n  File \"/home/ng/.local/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py\", line 147, in log_prob\n    return super().log_prob(value)\n  File \"/home/ng/.local/lib/python3.8/site-packages/torch/distributions/multivariate_normal.py\", line 209, in log_prob\n    diff = value - self.loc\n",
     "output_type": "error",
     "traceback": [
      "PyError ($(Expr(:escape, :(ccall(#= /home/ng/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:43 =# @pysym(:PyObject_Call), PyPtr, (PyPtr, PyPtr, PyPtr), o, pyargsptr, kw))))) <class 'RuntimeError'>\nRuntimeError('The size of tensor a (2) must match the size of tensor b (7) at non-singleton dimension 1')\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/fit.py\", line 124, in fit_gpytorch_model\n    mll, _ = optimizer(mll, track_iterations=False, **kwargs)\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/optim/fit.py\", line 239, in fit_gpytorch_scipy\n    res = minimize(\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 623, in minimize\n    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\", line 306, in _minimize_lbfgsb\n    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/optimize.py\", line 261, in _prepare_scalar_function\n    sf = ScalarFunction(fun, x0, args, grad, hess,\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 140, in __init__\n    self._update_fun()\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 233, in _update_fun\n    self._update_fun_impl()\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in update_fun\n    self.f = fun_wrapped(self.x)\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 134, in fun_wrapped\n    return fun(np.copy(x), *args)\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n    self._compute_if_needed(x, *args)\n  File \"/home/ng/.local/lib/python3.8/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n    fg = self.fun(x, *args)\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/optim/utils.py\", line 220, in _scipy_objective_and_grad\n    raise e  # pragma: nocover\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/optim/utils.py\", line 214, in _scipy_objective_and_grad\n    loss = -mll(*args).sum()\n  File \"/home/ng/.local/lib/python3.8/site-packages/gpytorch/module.py\", line 30, in __call__\n    outputs = self.forward(*inputs, **kwargs)\n  File \"/home/ng/.local/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\", line 62, in forward\n    res = output.log_prob(target)\n  File \"/home/ng/.local/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py\", line 147, in log_prob\n    return super().log_prob(value)\n  File \"/home/ng/.local/lib/python3.8/site-packages/torch/distributions/multivariate_normal.py\", line 209, in log_prob\n    diff = value - self.loc\n",
      "",
      "Stacktrace:",
      "  [1] pyerr_check",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/exception.jl:62 [inlined]",
      "  [2] pyerr_check",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/exception.jl:66 [inlined]",
      "  [3] _handle_error(msg::String)",
      "    @ PyCall ~/.julia/packages/PyCall/3fwVL/src/exception.jl:83",
      "  [4] macro expansion",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/exception.jl:97 [inlined]",
      "  [5] #107",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:43 [inlined]",
      "  [6] disable_sigint",
      "    @ ./c.jl:458 [inlined]",
      "  [7] __pycall!",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:42 [inlined]",
      "  [8] _pycall!(ret::PyObject, o::PyObject, args::Tuple{PyObject}, nargs::Int64, kw::PyObject)",
      "    @ PyCall ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:29",
      "  [9] _pycall!",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:11 [inlined]",
      " [10] (::PyObject)(args::PyObject; kwargs::Base.Iterators.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:max_retries,), Tuple{Int64}}})",
      "    @ PyCall ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:86",
      " [11] top-level scope",
      "    @ In[8]:1",
      " [12] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [13] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "botorch.fit.fit_gpytorch_model(mll, max_retries=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90fa9274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject tensor([0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64,\n",
       "       grad_fn=<ExpandBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optput = model(train_X)\n",
    "optput.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa7ae870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optput._covar.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2645f11",
   "metadata": {},
   "source": [
    "#### BO function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0af5b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# # Arguments\n",
    "# - `X`: feature matrix\n",
    "# - `y`: target vector\n",
    "# - `nb_iterations`: maximum number of BO iterations (experiment budget)\n",
    "# - `which_acquisition`: which acquisition function to implement\n",
    "# ` `store_explore_exploit_terms`: whether or not to keep track of the explore and exploit \n",
    "#                                  terms from the acqisition for the acquired material at each iteration\n",
    "# - `sample_gp`: whether or not to store sample GP functions\n",
    "# - `initialize_with`: specify which and/or how many materials to initialize the search\n",
    "# - `kwargs`: dictionary of optional keyword arguments\n",
    "# \"\"\"\n",
    "# function run_bayesian_optimization(X, y1, y2, nb_iterations::Int, \n",
    "#                                    nb_COFs_initialization::Int;\n",
    "#                                    which_acquisition::Symbol=:EI,\n",
    "#                                    store_explore_exploit_terms::Bool=false,\n",
    "#                                    sample_gp::Bool=false,\n",
    "#                                    initialize_with::Union{Array{Int, 1}, Nothing}=nothing,\n",
    "#                                    kwargs::Dict{Symbol, Any}=Dict{Symbol, Any}())\n",
    "#     # quick checks\n",
    "#     @assert nb_iterations > nb_COFs_initialization \"More initializations than itterations not allowed.\"\n",
    "#     @assert which_acquisition in [:EI] \"Acquisition function not supported:\\t $(which_acquisition)\"\n",
    "    \n",
    "#     # create array to store explore-explot terms if needed\n",
    "#     if store_explore_exploit_terms\n",
    "#         # store as (explore, exploit, fidelity)\n",
    "#         explore_exploit_balance = Tuple{Float64, Float64, Int64}[]\n",
    "#     end\n",
    "    \n",
    "#     ###\n",
    "#     #  1. randomly select COF IDs for training initial GP\n",
    "#     ###\n",
    "#     if isnothing(initialize_with)\n",
    "#         ids_acquired = StatsBase.sample(1:nb_COFs, nb_COFs_initialization, replace=false)\n",
    "#         @assert length(unique(ids_acquired)) == nb_COFs_initialization\n",
    "#     else\n",
    "#         # initialize using a specified set of indecies\n",
    "#         ids_acquired = initialize_with\n",
    "#         fidelity = 1\n",
    "#         @assert length(unique(ids_acquired)) == nb_COFs_initialization\n",
    "#     end\n",
    "#     # initialize using ONLY the high-fidelity results\n",
    "#     x = X[ids_acquired, :]\n",
    "#     train_X = torch.from_numpy(x)       # feature vectors\n",
    "#     y1 = torch.from_numpy(gcmc_y[ids_acquired])  # low-fidelity\n",
    "#     y2 = torch.from_numpy(gcmc_y[ids_acquired])  # high-fidelity\n",
    "#     train_y = torch.stack([y1, y2], -1)\n",
    "#     # standardize outputs using *only currently acquired data*\n",
    "#     y_acquired = (y_acquired - torch.mean(y_acquired)) / torch.std(y_acquired)\n",
    "    \n",
    "#     # uses ICM [here](https://botorch.org/api/models.html#multitaskgp)\n",
    "#     # botorch.models.multitask.MultiTaskGP(train_X, train_Y, task_feature, \n",
    "#     #     task_covar_prior=None, output_tasks=None, \n",
    "#     #     rank=None, input_transform=None, outcome_transform=None)\n",
    "#     model = botorch.models.multitask.MultiTaskGP(train_X, train_Y, -1)\n",
    "    \n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67c43a6",
   "metadata": {},
   "source": [
    "## RUN MTBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233c55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
