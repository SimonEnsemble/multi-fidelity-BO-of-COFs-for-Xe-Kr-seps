{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1b630d1",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "1. figure out the shape issue with the model inputs\n",
    "    - currently: `model.num_outputs = 5` (pretty sure this is due to num training pts)\n",
    "    - what are `task_feature`\n",
    "    - maybe look at input_constructor\n",
    "    - can it handle heterotopic data? We are only training henry on henry data and gcmc on gcmc data.\n",
    "2. look over GPyTorch models\n",
    "    - figure out how to define the MultiTask model\n",
    "    - consider just writing this notebook in python\n",
    "3. Write MultiFidelity Expectied Improvement Acquisition function\n",
    "4. Perform BO and plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f25d10b",
   "metadata": {},
   "source": [
    "## System Description\n",
    "1. We have a set of COFs from a database. Each COF is characterized by a feature vector $$x_{COF} \\in X \\subset R^d$$ were d=14.\n",
    "\n",
    "\n",
    "2. We have **two different types** of simulations to calculate **the same material property $S_{Xe/Kr}$**. Therefore, we have a Single-Task/Objective (find the material with the optimal selevtivity), Multi-Fidelity problem. \n",
    "    1. low-fidelity  = Henry Coefficient calculation - MC integration - cost=1\n",
    "    2. high-fidelity = GCMC mixture simulation - 80:20 (Kr:Xe) at 298 K and 1.0 bar - cost=30\n",
    "\n",
    "\n",
    "3. We will initialize the system with *two* COFs at both fidelities in order to initialize the Covariance Matrix.\n",
    "    - The fist COF will be the one closest to the center of the normalized feature space\n",
    "    - The second COF will be chosen at random\n",
    "\n",
    "\n",
    "4. Each surrogate model will **only train on data acquired at its level of fidelity** (Heterotopic data). $$X_{lf} \\neq X_{hf} \\subset X$$\n",
    "    1. We are using the augmented EI acquisition function from [here](https://link.springer.com/content/pdf/10.1007/s00158-005-0587-0.pdf)\n",
    "\n",
    "\n",
    "5. **kernel model**: \n",
    "    1.  We need a Gaussian Process (GP) that will give a *correlated output for each fidelity* i.e. we need a vector-valued kernel\n",
    "    2. Given the *cost aware* acquisition function, which imposes a fidelity hierarchy, we anticipate the number of training points at each fidelity *will not* be equal (asymmetric scenario) $$n_{lf} > n_{hf}$$\n",
    "        - perhaps we can force the symmetric case, $n_{lf} = n_{hf} = n$, if we can include `missing` or `empty` entries in the training sets.\n",
    "\n",
    "\n",
    "Note: even though we have heterotopic data in an asymmetric scenario -- due to hierarchical, multi-fidelity -- we can still use a symmetric multi-output GP. \n",
    "\n",
    "#### Strategy\n",
    "We are going to attempt to use the Intrinsic Coregionalization Model (ICM) -- a symmetric, multi-output GP (MOGP) -- along with the augmented EI acquisition function to identify the optimally slective COF in database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7fef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2\n",
    "using PyPlot\n",
    "using StatsBase # Statistics\n",
    "using Distributions\n",
    "\n",
    "using PyCall\n",
    "@pyimport torch \n",
    "@pyimport gpytorch\n",
    "@pyimport botorch\n",
    "\n",
    "\n",
    "# config plot settings\n",
    "PyPlot.matplotlib.style.use(\"ggplot\")\n",
    "rcParams = PyPlot.PyDict(PyPlot.matplotlib.\"rcParams\")\n",
    "rcParams[\"font.size\"] = 16;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0457fef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  example\n",
    "###\n",
    "train_X = torch.rand(20, 4)\n",
    "train_Y = train_X.pow(2).sum(dim=-1, keepdim=true)\n",
    "model = botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP(train_X, train_Y, data_fidelity=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbebf366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08ffb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c6b0f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject ExactMarginalLogLikelihood(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (noise_prior): GammaPrior()\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (model): SingleTaskMultiFidelityGP(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): GammaPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ConstantMean()\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): LinearTruncatedFidelityKernel(\n",
       "        (raw_power_constraint): Positive()\n",
       "        (power_prior): GammaPrior()\n",
       "        (covar_module_unbiased): MaternKernel(\n",
       "          (lengthscale_prior): GammaPrior()\n",
       "          (raw_lengthscale_constraint): Positive()\n",
       "          (distance_module): Distance()\n",
       "        )\n",
       "        (covar_module_biased): MaternKernel(\n",
       "          (lengthscale_prior): GammaPrior()\n",
       "          (raw_lengthscale_constraint): Positive()\n",
       "          (distance_module): Distance()\n",
       "        )\n",
       "      )\n",
       "      (outputscale_prior): GammaPrior()\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "botorch.fit.fit_gpytorch_model(mll, max_retries=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e828840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Symbol}:\n",
       " :X\n",
       " :henry_y\n",
       " :gcmc_y"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#  load data\n",
    "###\n",
    "@load joinpath(pwd(), \"targets_and_normalized_features.jld2\") X henry_y gcmc_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36806c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14-element Vector{Float64}:\n",
       " 0.006426269579626523\n",
       " 0.19186685507929027\n",
       " 0.5030387259825977\n",
       " 0.6277566164161331\n",
       " 0.5349395204896041\n",
       " 0.42291262109265054\n",
       " 0.7543285744454562\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.9699383580246026\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dba3ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(608, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8cc9f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject tensor([0.0333, 1.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fidelities = torch.tensor([0.5, 0.75, 1.0], **tkwargs)\n",
    "c1 = 1       # low-fidelity absolute cost\n",
    "c2 = 30 * c1 # high-fidelity absolute cost\n",
    "\n",
    "function cost_function(cl::Int64, cm::Float64)\n",
    "    return cl/cm\n",
    "end\n",
    "\n",
    "fidelity_cost = torch.from_numpy([c1/c2, c2/c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a3b374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  Randomly select COFs to train GP\n",
    "###\n",
    "nb_henry_init = 2 # assuming asymmetric, heterotopic scenario\n",
    "nb_gcmc_init  = 2\n",
    "ids_acquired_henry = StatsBase.sample(1:length(henry_y), nb_henry_init, replace=false)\n",
    "ids_acquired_gcmc  = StatsBase.sample(1:length(gcmc_y),  nb_gcmc_init, replace=false)\n",
    "@assert ! any([id in ids_acquired_gcmc for id in ids_acquired_henry]) \"data not heterotopic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a72048a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject tensor([[0.4479, 0.6000, 0.5181, 0.1963, 0.2187, 0.1991, 0.1015, 0.1028, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2303, 0.9000, 0.5653, 0.3508, 0.4941, 0.3773, 0.0000, 0.0974, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "#  construct input tensors\n",
    "###\n",
    "train_X1 = torch.from_numpy(X[ids_acquired_henry, :])\n",
    "train_X2 = torch.from_numpy(X[ids_acquired_gcmc, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ca899d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject tensor([[0.3216, 0.7000, 0.6009, 0.3101, 0.3860, 0.3409, 0.0000, 0.0513, 0.0000,\n",
       "         0.2061, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0101, 0.5000, 0.6240, 0.6346, 0.7929, 0.7044, 0.2284, 0.1157, 0.5909,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4479, 0.6000, 0.5181, 0.1963, 0.2187, 0.1991, 0.1015, 0.1028, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2303, 0.9000, 0.5653, 0.3508, 0.4941, 0.3773, 0.0000, 0.0974, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = torch.cat((train_X1, train_X2)) # feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5179f131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject tensor([[ 0.3046,  1.1003],\n",
       "        [-1.2982, -0.1066]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = torch.from_numpy(henry_y[ids_acquired_henry]) # low-fidelity\n",
    "y2 = torch.from_numpy(gcmc_y[ids_acquired_gcmc])   # high-fidelity\n",
    "\n",
    "y_acquired = torch.stack((y1, y2))\n",
    "# standardize outputs using *only currently acquired data*\n",
    "y_acquired = (y_acquired - torch.mean(y_acquired)) / torch.std(y_acquired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb0ad5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_acquired.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5ec112e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject tensor([0.0101, 0.5000, 0.6240, 0.6346, 0.7929, 0.7044, 0.2284, 0.1157, 0.5909,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train_X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78c8e8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bb0170f",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "PyError ($(Expr(:escape, :(ccall(#= /home/ng/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:43 =# @pysym(:PyObject_Call), PyPtr, (PyPtr, PyPtr, PyPtr), o, pyargsptr, kw))))) <class 'botorch.exceptions.errors.BotorchTensorDimensionError'>\nBotorchTensorDimensionError('Expected X and Y to have the same number of dimensions (got X with dimension 1 and Y with dimension 2.')\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/models/gp_regression_fidelity.py\", line 112, in __init__\n    super().__init__(\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/models/gp_regression.py\", line 100, in __init__\n    self._validate_tensor_args(X=transformed_X, Y=train_Y)\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/models/gpytorch.py\", line 83, in _validate_tensor_args\n    raise BotorchTensorDimensionError(message)\n",
     "output_type": "error",
     "traceback": [
      "PyError ($(Expr(:escape, :(ccall(#= /home/ng/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:43 =# @pysym(:PyObject_Call), PyPtr, (PyPtr, PyPtr, PyPtr), o, pyargsptr, kw))))) <class 'botorch.exceptions.errors.BotorchTensorDimensionError'>\nBotorchTensorDimensionError('Expected X and Y to have the same number of dimensions (got X with dimension 1 and Y with dimension 2.')\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/models/gp_regression_fidelity.py\", line 112, in __init__\n    super().__init__(\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/models/gp_regression.py\", line 100, in __init__\n    self._validate_tensor_args(X=transformed_X, Y=train_Y)\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/models/gpytorch.py\", line 83, in _validate_tensor_args\n    raise BotorchTensorDimensionError(message)\n",
      "",
      "Stacktrace:",
      "  [1] pyerr_check",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/exception.jl:62 [inlined]",
      "  [2] pyerr_check",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/exception.jl:66 [inlined]",
      "  [3] _handle_error(msg::String)",
      "    @ PyCall ~/.julia/packages/PyCall/3fwVL/src/exception.jl:83",
      "  [4] macro expansion",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/exception.jl:97 [inlined]",
      "  [5] #107",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:43 [inlined]",
      "  [6] disable_sigint",
      "    @ ./c.jl:458 [inlined]",
      "  [7] __pycall!",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:42 [inlined]",
      "  [8] _pycall!(ret::PyObject, o::PyObject, args::Tuple{PyObject, PyObject}, nargs::Int64, kw::PyObject)",
      "    @ PyCall ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:29",
      "  [9] _pycall!(ret::PyObject, o::PyObject, args::Tuple{PyObject, PyObject}, kwargs::Base.Iterators.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:data_fidelity,), Tuple{Int64}}})",
      "    @ PyCall ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:11",
      " [10] (::PyObject)(::PyObject, ::Vararg{PyObject, N} where N; kwargs::Base.Iterators.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:data_fidelity,), Tuple{Int64}}})",
      "    @ PyCall ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:86",
      " [11] top-level scope",
      "    @ In[12]:10",
      " [12] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [13] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "# botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP(train_X, train_Y, \n",
    "#     iteration_fidelity=None, data_fidelity=None, linear_truncated=True, nu=2.5, likelihood=None, \n",
    "#     outcome_transform=None, input_transform=None)\n",
    "# \n",
    "# \n",
    "# botorch.models.model_list_gp_regression.ModelListGP()\n",
    "# botorch.models.gpytorch.MultiTaskGPyTorchModel\n",
    "# botorch.models.gp_regression.SingleTaskGP(train_X, train_Y, likelihood=\"None\")\n",
    "# model = botorch.models.gp_regression.SingleTaskGP(train_X, y_acquired)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e4f003c",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "PyError ($(Expr(:escape, :(ccall(#= /home/ng/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:43 =# @pysym(:PyObject_Call), PyPtr, (PyPtr, PyPtr, PyPtr), o, pyargsptr, kw))))) <class 'botorch.exceptions.errors.BotorchTensorDimensionError'>\nBotorchTensorDimensionError('Expected X and Y to have the same number of dimensions (got X with dimension 1 and Y with dimension 2.')\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/models/multitask.py\", line 126, in __init__\n    self._validate_tensor_args(X=transformed_X, Y=train_Y)\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/models/gpytorch.py\", line 83, in _validate_tensor_args\n    raise BotorchTensorDimensionError(message)\n",
     "output_type": "error",
     "traceback": [
      "PyError ($(Expr(:escape, :(ccall(#= /home/ng/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:43 =# @pysym(:PyObject_Call), PyPtr, (PyPtr, PyPtr, PyPtr), o, pyargsptr, kw))))) <class 'botorch.exceptions.errors.BotorchTensorDimensionError'>\nBotorchTensorDimensionError('Expected X and Y to have the same number of dimensions (got X with dimension 1 and Y with dimension 2.')\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/models/multitask.py\", line 126, in __init__\n    self._validate_tensor_args(X=transformed_X, Y=train_Y)\n  File \"/home/ng/.local/lib/python3.8/site-packages/botorch/models/gpytorch.py\", line 83, in _validate_tensor_args\n    raise BotorchTensorDimensionError(message)\n",
      "",
      "Stacktrace:",
      "  [1] pyerr_check",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/exception.jl:62 [inlined]",
      "  [2] pyerr_check",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/exception.jl:66 [inlined]",
      "  [3] _handle_error(msg::String)",
      "    @ PyCall ~/.julia/packages/PyCall/3fwVL/src/exception.jl:83",
      "  [4] macro expansion",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/exception.jl:97 [inlined]",
      "  [5] #107",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:43 [inlined]",
      "  [6] disable_sigint",
      "    @ ./c.jl:458 [inlined]",
      "  [7] __pycall!",
      "    @ ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:42 [inlined]",
      "  [8] _pycall!(ret::PyObject, o::PyObject, args::Tuple{PyObject, PyObject, Int64}, nargs::Int64, kw::Ptr{Nothing})",
      "    @ PyCall ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:29",
      "  [9] _pycall!(ret::PyObject, o::PyObject, args::Tuple{PyObject, PyObject, Int64}, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ PyCall ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:11",
      " [10] (::PyObject)(::PyObject, ::Vararg{Any, N} where N; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ PyCall ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:86",
      " [11] (::PyObject)(::PyObject, ::Vararg{Any, N} where N)",
      "    @ PyCall ~/.julia/packages/PyCall/3fwVL/src/pyfncall.jl:86",
      " [12] top-level scope",
      "    @ In[13]:6",
      " [13] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [14] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  Construct GP\n",
    "#  note - I should be able to include the noise if I add it to the data dictionary -> FixedNoiseMultiTaskGP\n",
    "###\n",
    "# task_feature = 1\n",
    "# model = botorch.models.multitask.MultiTaskGP(train_X, y_acquired, task_feature)\n",
    "\n",
    "model = botorch.models.gp_regression_fidelity.SingleTaskMultiFidelityGP(train_X, y_acquired, data_fidelity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f78e98ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: model not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: model not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[14]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "model.num_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7bc93be",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: model not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: model not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[15]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "# mll = gpytorch.mlls.SumMarginalLogLikelihood(model.likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b72933a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: mll not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: mll not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[16]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "botorch.fit.fit_gpytorch_model(mll, max_retries=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90fa9274",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: model not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: model not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[17]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "optput = model(train_X)\n",
    "optput.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa7ae870",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: optput not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: optput not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[18]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "optput._covar.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2645f11",
   "metadata": {},
   "source": [
    "#### BO function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0af5b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# # Arguments\n",
    "# - `X`: feature matrix\n",
    "# - `y`: target vector\n",
    "# - `nb_iterations`: maximum number of BO iterations (experiment budget)\n",
    "# - `which_acquisition`: which acquisition function to implement\n",
    "# ` `store_explore_exploit_terms`: whether or not to keep track of the explore and exploit \n",
    "#                                  terms from the acqisition for the acquired material at each iteration\n",
    "# - `sample_gp`: whether or not to store sample GP functions\n",
    "# - `initialize_with`: specify which and/or how many materials to initialize the search\n",
    "# - `kwargs`: dictionary of optional keyword arguments\n",
    "# \"\"\"\n",
    "# function run_bayesian_optimization(X, y1, y2, nb_iterations::Int, \n",
    "#                                    nb_COFs_initialization::Int;\n",
    "#                                    which_acquisition::Symbol=:EI,\n",
    "#                                    store_explore_exploit_terms::Bool=false,\n",
    "#                                    sample_gp::Bool=false,\n",
    "#                                    initialize_with::Union{Array{Int, 1}, Nothing}=nothing,\n",
    "#                                    kwargs::Dict{Symbol, Any}=Dict{Symbol, Any}())\n",
    "#     # quick checks\n",
    "#     @assert nb_iterations > nb_COFs_initialization \"More initializations than itterations not allowed.\"\n",
    "#     @assert which_acquisition in [:EI] \"Acquisition function not supported:\\t $(which_acquisition)\"\n",
    "    \n",
    "#     # create array to store explore-explot terms if needed\n",
    "#     if store_explore_exploit_terms\n",
    "#         # store as (explore, exploit, fidelity)\n",
    "#         explore_exploit_balance = Tuple{Float64, Float64, Int64}[]\n",
    "#     end\n",
    "    \n",
    "#     ###\n",
    "#     #  1. randomly select COF IDs for training initial GP\n",
    "#     ###\n",
    "#     if isnothing(initialize_with)\n",
    "#         ids_acquired = StatsBase.sample(1:nb_COFs, nb_COFs_initialization, replace=false)\n",
    "#         @assert length(unique(ids_acquired)) == nb_COFs_initialization\n",
    "#     else\n",
    "#         # initialize using a specified set of indecies\n",
    "#         ids_acquired = initialize_with\n",
    "#         fidelity = 1\n",
    "#         @assert length(unique(ids_acquired)) == nb_COFs_initialization\n",
    "#     end\n",
    "#     # initialize using ONLY the high-fidelity results\n",
    "#     x = X[ids_acquired, :]\n",
    "#     train_X = torch.from_numpy(x)       # feature vectors\n",
    "#     y1 = torch.from_numpy(gcmc_y[ids_acquired])  # low-fidelity\n",
    "#     y2 = torch.from_numpy(gcmc_y[ids_acquired])  # high-fidelity\n",
    "#     train_y = torch.stack([y1, y2], -1)\n",
    "#     # standardize outputs using *only currently acquired data*\n",
    "#     y_acquired = (y_acquired - torch.mean(y_acquired)) / torch.std(y_acquired)\n",
    "    \n",
    "#     # uses ICM [here](https://botorch.org/api/models.html#multitaskgp)\n",
    "#     # botorch.models.multitask.MultiTaskGP(train_X, train_Y, task_feature, \n",
    "#     #     task_covar_prior=None, output_tasks=None, \n",
    "#     #     rank=None, input_transform=None, outcome_transform=None)\n",
    "#     model = botorch.models.multitask.MultiTaskGP(train_X, train_Y, -1)\n",
    "    \n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67c43a6",
   "metadata": {},
   "source": [
    "## RUN MTBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233c55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
