{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3386c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613aa76",
   "metadata": {},
   "source": [
    "## System Description\n",
    "1. We have a set of COFs from a database. Each COF is characterized by a feature vector $$x_{COF} \\in X \\subset R^d$$ were d=14.\n",
    "\n",
    "\n",
    "2. We have **two different types** of simulations to calculate **the same material property $S_{Xe/Kr}$**. Therefore, we have a Single-Task/Objective (find the material with the optimal selevtivity), Multi-Fidelity problem. \n",
    "    1. low-fidelity  = Henry coefficient calculation - MC integration \n",
    "    2. high-fidelity = GCMC mixture simulation - 80:20 (Kr:Xe) at 298 K and 1.0 bar \n",
    "\n",
    "\n",
    "3. We will initialize the system with a few COFs at **both** fidelities in order to initialize the Covariance Matrix.\n",
    "    1. The fist COF will be the one closest to the center of the normalized feature space\n",
    "    2. The rest will be chosen to maximize diversity of the training set\n",
    "\n",
    "\n",
    "4. Each surrogate model will **only train on data acquired at its level of fidelity** (Heterotopic data). $$X_{lf} \\neq X_{hf} \\subset X$$\n",
    "    1. We could use the augmented EI acquisition function from [here](https://link.springer.com/content/pdf/10.1007/s00158-005-0587-0.pdf)\n",
    "    2. We could use a naive implementation of the [misoKG](https://papers.nips.cc/paper/2017/file/df1f1d20ee86704251795841e6a9405a-Paper.pdf) acquisition function\n",
    "    3. Helpful [tutorial](https://botorch.org/tutorials/discrete_multi_fidelity_bo)\n",
    "\n",
    "\n",
    "5. **kernel model**: \n",
    "    1.  We need a Gaussian Process (GP) that will give a *correlated output for each fidelity* i.e. we need a vector-valued kernel\n",
    "    2. Given the *cost aware* acquisition function, we anticipate the number of training points at each fidelity *will not* be equal (asymmetric scenario) $$n_{lf} > n_{hf}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f78a6f",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "- put timer in code that reports the time for the BO search (if this takes long, not good). should report that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7679eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from botorch.models import SingleTaskMultiFidelityGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch import fit_gpytorch_model\n",
    "from scipy.stats import norm\n",
    "from sklearn.decomposition import PCA\n",
    "import math \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "# config plot settings\n",
    "plt.rcParams[\"font.size\"] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa45b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data - \n",
      "\tX: torch.Size([608, 14])\n",
      "\tfidelity: 0\n",
      "\t\ty: torch.Size([608])\n",
      "\t\tcost:  torch.Size([608])\n",
      "\tfidelity: 1\n",
      "\t\ty: torch.Size([608])\n",
      "\t\tcost:  torch.Size([608])\n",
      "\n",
      "Ensure features are normalized - \n",
      "max:\n",
      " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       dtype=torch.float64)\n",
      "min:\n",
      " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  Load Data\n",
    "###\n",
    "file = h5py.File(\"targets_and_normalized_features.jld2\", \"r\")\n",
    "# feature matrix\n",
    "X = torch.from_numpy(np.transpose(file[\"X\"][:]))\n",
    "# simulation data\n",
    "y = [torch.from_numpy(np.transpose(file[\"henry_y\"][:])), \n",
    "     torch.from_numpy(np.transpose(file[\"gcmc_y\"][:]))]\n",
    "# associated simulation costs\n",
    "cost = [torch.from_numpy(np.transpose(file[\"henry_total_elapsed_time\"][:])), \n",
    "        torch.from_numpy(np.transpose(file[\"gcmc_elapsed_time\"][:]))]\n",
    "\n",
    "# total number of COFs in data set\n",
    "nb_COFs = X.shape[0] \n",
    "\n",
    "print(\"raw data - \\n\\tX:\", X.shape)\n",
    "for f in range(2):\n",
    "    print(\"\\tfidelity:\", f)\n",
    "    print(\"\\t\\ty:\", y[f].shape)\n",
    "    print(\"\\t\\tcost: \", cost[f].shape)\n",
    "    \n",
    "    \n",
    "print(\"\\nEnsure features are normalized - \")\n",
    "print(\"max:\\n\", torch.max(X, 0).values)\n",
    "print(\"min:\\n\", torch.min(X, 0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99796cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average high-fidelity cost: 230.0783918372241 [min]\n",
      "average low-fidelity cost:  16.57287046034216 [min]\n",
      "average cost ratio:\t    13.444745568580501\n"
     ]
    }
   ],
   "source": [
    "print(\"average high-fidelity cost:\", torch.mean(cost[1]).item(), \"[min]\")\n",
    "print(\"average low-fidelity cost: \", torch.mean(cost[0]).item(), \"[min]\")\n",
    "print(\"average cost ratio:\\t   \", torch.mean(cost[1] / cost[0]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d14a9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10076.3052, dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_lf_cost = sum(cost[0])\n",
    "total_lf_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c5e4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(139887.6622, dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_hf_cost = sum(cost[1])\n",
    "total_hf_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f84bd4",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "#### Construct Initial Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9389e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find COF closest to the center of feature space\n",
    "def get_initializing_COF(X):\n",
    "    # center of feature space\n",
    "    feature_center = np.ones(X.shape[1]) * 0.5\n",
    "    # max possible distance between normalized features\n",
    "    return np.argmin(np.linalg.norm(X - feature_center, axis=1))\n",
    "\n",
    "def diverse_set(X, train_size):\n",
    "    # initialize with one random point; pick others in a max diverse fashion\n",
    "    ids_train = [get_initializing_COF(X)]\n",
    "    # select remaining training points\n",
    "    for j in range(train_size - 1):\n",
    "        # for each point in data set, compute its min dist to training set\n",
    "        dist_to_train_set = np.linalg.norm(X - X[ids_train, None, :], axis=2)\n",
    "        assert np.shape(dist_to_train_set) == (len(ids_train), nb_COFs)\n",
    "        min_dist_to_a_training_pt = np.min(dist_to_train_set, axis=0)\n",
    "        assert np.size(min_dist_to_a_training_pt) == nb_COFs\n",
    "        \n",
    "        # acquire point with max(min distance to train set) i.e. Furthest from train set\n",
    "        ids_train.append(np.argmax(min_dist_to_a_training_pt))\n",
    "    assert np.size(np.unique(ids_train)) == train_size # must be unique\n",
    "    return np.array(ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e61b6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct feature matrix of acquired points\n",
    "def build_X_train(acquired_set):\n",
    "    ids_acq = [j[0] for j in acquired_set]\n",
    "    fid_acq = torch.tensor([j[1] for j in acquired_set])\n",
    "    return torch.cat((X[ids_acq, :], fid_acq.unsqueeze(dim=-1)), dim=1)\n",
    "\n",
    "# construct output vector for acquired points\n",
    "def build_y_train(acquired_set):\n",
    "    for i, [cof_id, f_id] in enumerate(acquired_set):\n",
    "        y_t = y[f_id][cof_id].unsqueeze(-1)\n",
    "        if i == 0:\n",
    "            y_train = y_t # nitialize\n",
    "        else:\n",
    "            y_train = torch.cat((y_train, y_t))\n",
    "    return y_train.unsqueeze(-1)\n",
    "\n",
    "# construct vector to track accumulated cost of acquired points\n",
    "def build_cost(acquired_set):\n",
    "    for i, [cof_id, f_id] in enumerate(acquired_set):\n",
    "        c = torch.ones((1, 1), dtype=float) * cost[f_id][cof_id]\n",
    "        if i == 0:\n",
    "            costs_acquired = c # initialize\n",
    "        else:\n",
    "            costs_acquired = torch.cat((costs_acquired, c))\n",
    "            \n",
    "    return costs_acquired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "156b7a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_initializing_functions(X, y):\n",
    "#     # number of COFs to initialize with at each fidelity\n",
    "#     nb_COFs_initialization = 3\n",
    "#     # select COFs to train initial GP\n",
    "#     initializing_COFs = torch.from_numpy(np.array([1, 3, 4]))\n",
    "#     # track COFs acquired\n",
    "#     ids_acquired = torch.from_numpy(np.array([1, 3, 4]))\n",
    "#     print(\"Test -\\n\\tids acquired\", ids_acquired)\n",
    "#     # track the fidelity at which COFs are acquired\n",
    "#     fidelity_acquired = torch.from_numpy(np.array([1, 0, 0]))\n",
    "#     print(\"\\tfidelity acquired\", fidelity_acquired)\n",
    "#     # construct training sets\n",
    "#     X_train = build_X_train(ids_acquired, fidelity_acquired)\n",
    "#     y_train = build_y_train(ids_acquired, fidelity_acquired)\n",
    "#     # Test that the constructor functions are working properly\n",
    "#     assert np.allclose(X[1, :], X_train[0, :14])\n",
    "#     assert X_train[0, 14] == 1\n",
    "#     assert X_train[1, 14] == 0\n",
    "#     assert y_train[0] == y[0]\n",
    "#     return\n",
    "\n",
    "# test_initializing_functions(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d57717a",
   "metadata": {},
   "source": [
    "#### Surrogate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73c5e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_surrogate_model(X_train, y_train):\n",
    "    model = SingleTaskMultiFidelityGP(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        outcome_transform=Standardize(m=1), # m is the output dimension\n",
    "        data_fidelity=X_train.shape[1] - 1\n",
    "    )   \n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_model(mll)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce88b3c",
   "metadata": {},
   "source": [
    "#### Acquisition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70bb7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate posterior mean and variance\n",
    "def mu_sigma(model, X, fidelity):\n",
    "    f = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) * fidelity\n",
    "    X_f = torch.cat((X, f), dim=1) # last col is associated fidelity\n",
    "    f_posterior = model.posterior(X_f)\n",
    "    return f_posterior.mean.squeeze().detach().numpy(), f_posterior.variance.squeeze().detach().numpy()\n",
    "\n",
    "# get the current \"effective best solution\"\n",
    "def get_y_max(acquired_set, desired_fidelity):\n",
    "    y_max = 0\n",
    "    for i, [cof_id, f_id] in enumerate(acquired_set):\n",
    "        if (f_id == desired_fidelity) & (y[f_id][cof_id].item() > y_max):\n",
    "            y_max = y[f_id][cof_id].item()\n",
    "    return y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "16f7f5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 15])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "260b3f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_surrogate_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1dd49803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScaleKernel(\n",
       "  (base_kernel): LinearTruncatedFidelityKernel(\n",
       "    (raw_power_constraint): Positive()\n",
       "    (power_prior): GammaPrior()\n",
       "    (covar_module_unbiased): MaternKernel(\n",
       "      (lengthscale_prior): GammaPrior()\n",
       "      (raw_lengthscale_constraint): Positive()\n",
       "      (distance_module): Distance()\n",
       "    )\n",
       "    (covar_module_biased): MaternKernel(\n",
       "      (lengthscale_prior): GammaPrior()\n",
       "      (raw_lengthscale_constraint): Positive()\n",
       "      (distance_module): Distance()\n",
       "    )\n",
       "  )\n",
       "  (outputscale_prior): GammaPrior()\n",
       "  (raw_outputscale_constraint): Positive()\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.covar_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a37f2730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6667], dtype=torch.float64, grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.covar_module.base_kernel.power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c3dccb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.covar_module.base_kernel.covar_module_biased.lengthscale = torch.rand(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7739c950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3335, 0.3333, 0.3334, 0.3334, 0.3334, 0.3331, 0.3329, 0.3332, 0.3333,\n",
       "         0.3333, 0.3333, 0.3317, 0.3333, 0.3332]], dtype=torch.float64,\n",
       "       grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.covar_module.base_kernel.covar_module_unbiased.lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2d0928fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f63acf79dd0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.covar_module.base_kernel.covar_module_unbiased.distance_module.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.covar_module.base_kernel.covar_module_unbiased.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6906b28a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7468, dtype=torch.float64, grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.covar_module.outputscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6e26138d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4936, 0.6543, 0.6118,  ..., 0.5638, 0.5706, 0.5969],\n",
       "        [0.6543, 1.4936, 1.2461,  ..., 0.8155, 0.8789, 0.9567],\n",
       "        [0.6118, 1.2461, 1.4936,  ..., 0.9787, 1.0947, 1.0479],\n",
       "        ...,\n",
       "        [0.5638, 0.8155, 0.9787,  ..., 1.4936, 1.3986, 1.0209],\n",
       "        [0.5706, 0.8789, 1.0947,  ..., 1.3986, 1.4936, 1.1551],\n",
       "        [0.5969, 0.9567, 1.0479,  ..., 1.0209, 1.1551, 1.4936]],\n",
       "       dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f   = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) * 0\n",
    "X_f = torch.cat((X, f), dim=1) # last col is associated fidelity\n",
    "\n",
    "model.forward(X_f).covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5cbbb144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4936, 0.6543, 0.6118,  ..., 0.5638, 0.5706, 0.5969],\n",
       "        [0.6543, 1.4936, 1.2461,  ..., 0.8155, 0.8789, 0.9567],\n",
       "        [0.6118, 1.2461, 1.4936,  ..., 0.9787, 1.0947, 1.0479],\n",
       "        ...,\n",
       "        [0.5638, 0.8155, 0.9787,  ..., 1.4936, 1.3986, 1.0209],\n",
       "        [0.5706, 0.8789, 1.0947,  ..., 1.3986, 1.4936, 1.1551],\n",
       "        [0.5969, 0.9567, 1.0479,  ..., 1.0209, 1.1551, 1.4936]],\n",
       "       dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get posterior for high-fidelity\n",
    "hf = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) \n",
    "X_hf = torch.cat((X, hf), dim=1) # last col is associated fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0717af4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468, 0.7468,\n",
       "        0.7468, 0.7468, 0.7468, 0.7468, 0.7468], dtype=torch.float64,\n",
       "       grad_fn=<DiagBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all_fid = torch.cat((X_f, X_hf), dim=0)\n",
    "\n",
    "# looking at the top right corner of the matrix\n",
    "Sigma = torch.diag(model.forward(X_all_fid).covariance_matrix[:X_f.size()[0], X_f.size()[0]:])\n",
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4142749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([608, 15])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_f.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  Multi-fideltiy correlation \n",
    "#  corr[] = k - k_1K^-1k_0???\n",
    "###\n",
    "def multi_fidelity_correlation(model, X, fidelity, acquired_set):\n",
    "    # get covariance matrix of acquired data points\n",
    "    sigma_yy  = model.covar_module(X_train).evaluate() \n",
    "    sigma_yy_inv = torch.inverse(sigma_yy) # take the inverse\n",
    "\n",
    "    # get posterior for fidelity f\n",
    "    f   = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) * fidelity\n",
    "    X_f = torch.cat((X, f), dim=1) # last col is associated fidelity\n",
    "    var_f = torch.flatten(model.posterior(X_f).variance)\n",
    "\n",
    "    # get posterior for high-fidelity\n",
    "    hf = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) \n",
    "    X_hf = torch.cat((X, hf), dim=1) # last col is associated fidelity\n",
    "    var_hf = torch.flatten(model.posterior(X_hf).variance)\n",
    "\n",
    "    # Compute the covariance between X_hf and X_f, using covariance kernel\n",
    "    sigma_xx = model.covar_module.forward(X_hf, X_f, diag=True) # want diag\n",
    "\n",
    "    # Compute the covariance between X_f and X_train \n",
    "    # rows are [k(x,s), (x_1, s_1), ..., k((x, s), (x_N, s_N))]\n",
    "    cov_f_and_data = model.covar_module.forward(X_f, X_train).evaluate()\n",
    "\n",
    "    # Compute the covariance between X_hf and X_train\n",
    "    # rows are [k(x,s'), (x_1, s_1), ..., k((x, s'), (x_N, s_N))]\n",
    "    cov_hf_and_data = model.covar_module.forward(X_hf, X_train).evaluate()\n",
    "\n",
    "    # perform matrix multiplication: k_f * K_inv * k_hf\n",
    "    sigma_reduction = torch.matmul(torch.matmul(cov_f_and_data, K_inv), \n",
    "                       torch.t(cov_hf_and_data)).diag()\n",
    "    # calculate covariance\n",
    "    posterior_cov = sigma_prior - sigma_reduction\n",
    "    # calculate the correlation\n",
    "    corr = posterior_cov / (torch.sqrt(var_f) * torch.sqrt(var_hf))\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85e47050",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  Cost ratio\n",
    "###\n",
    "def cost_ratio(fidelity, acquired_set, costs_acquired):\n",
    "    # get fidelities from acquired set\n",
    "    f_acq = torch.tensor([acq_[1].item() for acq_ in acquired_set])\n",
    "    \n",
    "    avg_cost_f  = torch.mean(costs_acquired[f_acq == fidelity]).item()\n",
    "    avg_cost_hf = torch.mean(costs_acquired[f_acq == 1]).item()\n",
    "    return avg_cost_hf / avg_cost_f\n",
    "\n",
    "###\n",
    "#  Expected Imrovement function, only uses hf\n",
    "###\n",
    "def EI_hf(model, X, acquired_set):\n",
    "    hf_mu, hf_sigma = mu_sigma(model, X, 1)\n",
    "    y_max = get_y_max(acquired_set, 1)\n",
    "    \n",
    "    z = (hf_mu - y_max) / hf_sigma\n",
    "    explore_term = hf_sigma * norm.pdf(z) \n",
    "    exploit_term = (hf_mu - y_max) * norm.cdf(z) \n",
    "    ei = explore_term + exploit_term\n",
    "    return np.maximum(ei, np.zeros(nb_COFs))\n",
    "\n",
    "###\n",
    "#  Acquisition function\n",
    "###\n",
    "def acquisition(model, X, fidelity, acquired_set, costs_acquired):\n",
    "    # expected improvement for high-fidelity\n",
    "    ei = EI_hf(model, X, acquired_set) \n",
    "    \n",
    "    # augmenting functions\n",
    "    a1 = multi_fidelity_correlation(model, X, fidelity, acquired_set)\n",
    "    a2 = 1.0 # no systematic random error noise \n",
    "    a3 = cost_ratio(fidelity, acquired_set, costs_acquired)\n",
    "\n",
    "    acquisition_values = torch.from_numpy(ei) * a1 * a2 * a3\n",
    "    return acquisition_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd075cf",
   "metadata": {},
   "source": [
    "# Run MFBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eadc1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_initial_inputs(X, y, nb_COFs_initialization, discrete_fidelities):\n",
    "    initializing_COFs = diverse_set(X, nb_COFs_initialization)\n",
    "    init_flag = True \n",
    "    for i, cof_id in enumerate(initializing_COFs):\n",
    "        for j ,f_id in enumerate(discrete_fidelities):\n",
    "            acq_ = torch.tensor([[cof_id, f_id]], dtype=int)\n",
    "            if i == 0 and j == 0:\n",
    "                acquired_set = acq_ # initialize\n",
    "            else:\n",
    "                acquired_set = torch.cat((acquired_set, acq_))\n",
    "            \n",
    "    costs_acquired = build_cost(acquired_set)\n",
    "    return acquired_set, costs_acquired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c09823b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization - \n",
      "\n",
      "\tid acquired =  [25, 25, 494, 494, 523, 523]\n",
      "\tfidelity acquired =  [0, 1, 0, 1, 0, 1]\n",
      "\tcosts acquired =  [ 33.25071268 399.7576661   33.2388743  171.99848711   6.12068812\n",
      " 280.45236813]  [min]\n",
      "\n",
      "\tTraining data:\n",
      "\n",
      "\t\t X train shape =  torch.Size([6, 15])\n",
      "\t\t y train shape =  torch.Size([6, 1])\n",
      "\t\t training feature vector = \n",
      " tensor([0.1500, 0.4533, 0.1088, 0.5523, 0.4387, 0.1463, 0.3480, 0.2643, 0.0000,\n",
      "        0.1769, 0.2237, 0.0000, 0.0000, 0.3471, 0.0000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  construct initial inputs\n",
    "###\n",
    "discrete_fidelities = [0, 1] # set of discrete fidelities to select from\n",
    "nb_COFs_initialization = 3   # at each fidelity, number of COFs to initialize with\n",
    "nb_iterations = 100          # BO budget, includes initializing COFs\n",
    "\n",
    "acquired_set, costs_acquired = construct_initial_inputs(X, y, nb_COFs_initialization, discrete_fidelities)\n",
    "\n",
    "X_train = build_X_train(acquired_set)\n",
    "y_train = build_y_train(acquired_set)\n",
    "\n",
    "print(\"Initialization - \\n\")\n",
    "print(\"\\tid acquired = \", [acq_[0].item() for acq_ in acquired_set])\n",
    "print(\"\\tfidelity acquired = \", [acq_[1].item() for acq_ in acquired_set])\n",
    "print(\"\\tcosts acquired = \", costs_acquired.squeeze().detach().numpy(), \" [min]\")\n",
    "\n",
    "print(\"\\n\\tTraining data:\\n\")\n",
    "print(\"\\t\\t X train shape = \", X_train.shape)\n",
    "print(\"\\t\\t y train shape = \", y_train.shape)\n",
    "print(\"\\t\\t training feature vector = \\n\", X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aeffc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  Run Search\n",
    "###\n",
    "for i in range(nb_COFs_initialization * len(discrete_fidelities), nb_iterations + 1):\n",
    "    ###\n",
    "    #  Train Model\n",
    "    ###\n",
    "    model = train_surrogate_model(X_train, y_train)\n",
    "\n",
    "    ###\n",
    "    #  Evaluate Acquisition Function\n",
    "    ###\n",
    "    ids_acquired = torch.tensor([acq_[0].item() for acq_ in acquired_set])\n",
    "#     ids_acquired = torch.tensor(list(zip(*acquired_set))[0])\n",
    "\n",
    "    acquisition_values = []\n",
    "    f_id_acq    = -1 # dummy val we know will be overwritten\n",
    "    cof_id_acq  = -1\n",
    "    max_acq_val = 0\n",
    "    for fidelity in discrete_fidelities:\n",
    "        # evaluate acquisition function at given fidelity\n",
    "        f_acquisition_values = acquisition(model, X, fidelity, acquired_set, costs_acquired)\n",
    "        # sort in descending order\n",
    "        f_acquisition_sorted = f_acquisition_values.argsort(descending=True)\n",
    "        ### Strategy here: ####\n",
    "        #  1. loop through sorted indexes \n",
    "        #  2. check that the COF is in the list of acquired values with the given fidelity.\n",
    "        #     a) If the cof_id isn't in the acquired_set, then we don't need to check the fidelity\n",
    "        #     b) If it is in the acquired_set, then we have to check at which fidelity it was acquired\n",
    "        #  3. check if the acquisition value for the proposed cof_id at this fidelity is higher \n",
    "        #     than the highest acquisition values for the other ids and fidelities checked so far\n",
    "        #     a) if TRUE, store it -> becomes our new highest acquisition value to check against\n",
    "        #  4. once we've gone through all discrete fidelity levels, \n",
    "        #     we acquire the (cof_id, f_id) pair which had the highest value\n",
    "        ###\n",
    "        for sorted_id in f_acquisition_sorted:\n",
    "            if len(np.where(ids_acquired == sorted_id)[0]) == 0:\n",
    "                # this cof_id is not in the current acquired_set\n",
    "                f_id_max_aquisition = sorted_id.item()\n",
    "                break\n",
    "            elif (0 < len(np.where(ids_acquired == sorted_id)[0]) and \n",
    "                  len(np.where(ids_acquired == sorted_id)[0]) < len(discrete_fidelities)):\n",
    "                # check if this cof_id has already been sampled at both fidelities\n",
    "                if acquired_set[np.where(ids_acquired == sorted_id)[0].item()][1] != fidelity:\n",
    "                    # if the fidelity acquired for this COF is not the fidelity we are proposing, \n",
    "                    # store cof_id comparison (allow potential acquisition at proposed fidelity)\n",
    "                    f_id_max_aquisition = sorted_id.item()\n",
    "                    break\n",
    "        # check if proposed acquisition is the max across evaluated fidelities\n",
    "        if f_acquisition_values[f_id_max_aquisition] > max_acq_val:\n",
    "            # update max acquisition value\n",
    "            max_acq_val = f_acquisition_values[f_id_max_aquisition]\n",
    "            # update cof_id of max acquisition value\n",
    "            cof_id_acq  = f_id_max_aquisition\n",
    "            # update f_id of max acquisition value\n",
    "            f_id_acq = fidelity\n",
    "    ###\n",
    "    #  Updates\n",
    "    ###\n",
    "    # Update acquired_set\n",
    "    acq_ = torch.tensor([[cof_id_acq, f_id_acq]], dtype=int)\n",
    "    acquired_set = torch.cat((acquired_set, acq_))\n",
    "\n",
    "    # Update training sets and cost\n",
    "    X_train = build_X_train(acquired_set)\n",
    "    y_train = build_y_train(acquired_set)\n",
    "    costs_acquired = build_cost(acquired_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "615085b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "# look at unique COFs acquired\n",
    "###\n",
    "ids_acquired = torch.tensor([acq_[0].item() for acq_ in acquired_set])\n",
    "len(np.unique(ids_acquired))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e89cead",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdbd424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X_2D = pca.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6a7b6",
   "metadata": {},
   "source": [
    "## PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c00d7608",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fids_acquired' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5662/2746631192.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids_acquired\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnet_cost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosts_acquired\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mfids_acquired\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mselectivity_acquired\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mids_acquired\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mselectivity_acquired\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fids_acquired' is not defined"
     ]
    }
   ],
   "source": [
    "max_selectivity  = np.zeros(len(ids_acquired), dtype=float)\n",
    "selectivity_acquired = np.zeros(len(ids_acquired), dtype=float)\n",
    "net_cost  = np.zeros(len(ids_acquired), dtype=float)\n",
    "\n",
    "hl = 2 * nb_COFs_initialization\n",
    "y_max = 0\n",
    "\n",
    "for i in range(len(ids_acquired)):\n",
    "    net_cost[i] = sum(costs_acquired[:i])\n",
    "    if fids_acquired[i] == 1:\n",
    "        selectivity_acquired[i] = y[1][ids_acquired[i]]\n",
    "        if selectivity_acquired[i] > y_max:\n",
    "            y_max = selectivity_acquired[i]\n",
    "        max_selectivity[i] = y_max\n",
    "    else:\n",
    "        max_selectivity[i] = y_max\n",
    "        selectivity_acquired[i] = y[0][ids_acquired[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3cf5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "plt.axvline(x=hl, label=\"initialization\", color=\"k\", alpha=0.25, linestyle=\"--\", lw=2)\n",
    "plt.plot(range(len(ids_acquired)), net_cost, label=\"cost\", color=\"tab:blue\")\n",
    "plt.legend(fontsize=12)\n",
    "plt.ylabel(\"accumulated cost [min]\")\n",
    "plt.xlim(xmin=0, xmax=nb_iterations)\n",
    "plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "plt.ylim(ymin=0, ymax=25000)\n",
    "\n",
    "plt.subplot(2, 1, 2, sharex=ax1)\n",
    "plt.axhline(y=max(y[1]), label=\"global maximm\", color=\"tab:green\", ls=\"--\", lw=1.5)\n",
    "plt.axvline(x=hl, label=\"initialization\", color=\"k\", alpha=0.25, linestyle=\"--\", lw=2)\n",
    "plt.plot(range(len(ids_acquired)), max_selectivity, label=\"MFBO\", color=\"tab:red\", zorder=3)\n",
    "plt.ylim(ymin=0, ymax=20)\n",
    "plt.xlabel(\"# evaluated COFs\")\n",
    "plt.ylabel(\"max. $S_{Xe/Kr}$ acquired\")\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"figs/mfbo/multi_fidelity_bo_search_efficientcy_curve.png\", dpi=600, format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1136d825",
   "metadata": {},
   "source": [
    "### PCA viz\n",
    "\n",
    "\n",
    "one for low-fidelity and one for high-fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ab0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_acquired = torch.tensor(list(zip(*acquired_set))[0])\n",
    "fid_acquired = torch.tensor(list(zip(*acquired_set))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b71218",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_acquired = [2*nb_COFs_initialization, 20, 40, 60, 80]\n",
    "max_y_seen = np.zeros(len(nb_acquired))\n",
    "fig, ax = plt.subplots(1, len(nb_acquired), sharey=True, sharex=True, figsize=[3*6.4, 4.8])\n",
    "# gray background\n",
    "for a in ax:\n",
    "    a.set_aspect('equal', 'box')\n",
    "    a.hexbin(X_2D[:, 0], X_2D[:, 1], C=0.3 * np.ones(nb_COFs), cmap=\"binary\", vmin=0, vmax=1)\n",
    "    \n",
    "for i in range(len(nb_acquired)):\n",
    "    ids  = ids_acquired[:nb_acquired[i]].detach().numpy()\n",
    "    fids = fid_acquired[:nb_acquired[i]].detach().numpy()\n",
    "    max_y_seen[i] = y_max[nb_acquired[i]]\n",
    "    assert len(ids) == nb_acquired[i]\n",
    "    # use above colorbar to assign color!\n",
    "    ax[i].scatter(X_2D[ids, 0], X_2D[ids, 1], \n",
    "                  c=y[ids], marker=\"+\", s=55, vmin=cb.vmin, vmax=cb.vmax)\n",
    "    if i == 0:\n",
    "        ax[i].set_title('(initialization)\\n{} acquired COFs'.format(nb_acquired[i]))\n",
    "    else:\n",
    "        ax[i].set_title('{} acquired COFs'.format(nb_acquired[i]))\n",
    "    ax[i].tick_params(axis='x')\n",
    "ax[0].set_ylabel('PC 2', fontsize=14)\n",
    "\n",
    "ax[2].tick_params(axis='y', labelsize=0)\n",
    "\n",
    "\n",
    "fig.text(0.5, 0.02, 'PC 1', ha='center')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"feature_space_acquired_COFs.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a569e564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
