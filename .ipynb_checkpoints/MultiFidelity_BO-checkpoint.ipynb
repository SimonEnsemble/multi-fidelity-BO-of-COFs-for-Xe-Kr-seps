{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d087dd2",
   "metadata": {},
   "source": [
    "## System Description\n",
    "1. We have a set of COFs from a database. Each COF is characterized by a feature vector $$x_{COF} \\in X \\subset R^d$$ were d=14.\n",
    "\n",
    "\n",
    "2. We have **two different types** of simulations to calculate **the same material property $S_{Xe/Kr}$**. Therefore, we have a Single-Task/Objective \n",
    "$$argmax_{x_{COF} \\in X}[S_{Xe/Kr}(x_{COF})]$$\n",
    "\n",
    "3. Multi-Fidelity problem. \n",
    "    1. low-fidelity  => Henry coefficient calculation - MC integration: $S_{Xe/Kr} = \\frac{H_{Xe}}{H_{Kr}}$\n",
    "    2. high-fidelity => GCMC mixture simulation - 80:20 (Kr:Xe) at 298 K and 1.0 bar: $S_{Xe/Kr} = \\frac{n_{Xe} / n_{Kr}}{y_{Xe}/y_{Kr}}$\n",
    "\n",
    "\n",
    "3. We will initialize the system with a few COFs at **both** fidelities in order to initialize the Covariance Matrix.\n",
    "    1. The fist COF will be the one closest to the center of the normalized feature space\n",
    "    2. The rest will be chosen to maximize diversity of the training set\n",
    "\n",
    "\n",
    "4. Each surrogate model will **only train on data acquired at its level of fidelity** (Heterotopic data). $$X_{lf} \\neq X_{hf} \\subset X$$\n",
    "    1. We  use the augmented-EI (aEI) acquisition function from [here](https://link.springer.com/content/pdf/10.1007/s00158-005-0587-0.pdf)\n",
    "    2. Botorch GP surrogate model: [SingleTaskMultiFidelityGP](https://botorch.org/api/models.html#module-botorch.models.gp_regression_fidelity)\n",
    "    3. Needed to use [this](https://botorch.org/api/optim.html#module-botorch.optim.fit) optimizer to correct matrix jitter\n",
    "    4. Helpful [tutorial](https://botorch.org/tutorials/discrete_multi_fidelity_bo) for a similar BoTorch Model used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "669c708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from botorch.models import SingleTaskMultiFidelityGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch import fit_gpytorch_model\n",
    "from botorch.optim.fit import fit_gpytorch_torch # fix Cholecky jitter error\n",
    "from scipy.stats import norm\n",
    "from sklearn.decomposition import PCA\n",
    "import math \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import h5py # for .jld2 files\n",
    "import os\n",
    "\n",
    "# config plot settings\n",
    "plt.rcParams[\"font.size\"] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c603cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data - \n",
      "\tX: torch.Size([608, 14])\n",
      "\tfidelity: 0\n",
      "\t\ty: torch.Size([608])\n",
      "\t\tcost:  (608,)\n",
      "\tfidelity: 1\n",
      "\t\ty: torch.Size([608])\n",
      "\t\tcost:  (608,)\n",
      "\n",
      "Ensure features are normalized - \n",
      "max:\n",
      " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       dtype=torch.float64)\n",
      "min:\n",
      " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  Load Data\n",
    "###\n",
    "file = h5py.File(\"targets_and_normalized_features.jld2\", \"r\")\n",
    "# feature matrix\n",
    "X = torch.from_numpy(np.transpose(file[\"X\"][:]))\n",
    "# simulation data\n",
    "y = [torch.from_numpy(np.transpose(file[\"henry_y\"][:])), \n",
    "     torch.from_numpy(np.transpose(file[\"gcmc_y\"][:]))]\n",
    "# associated simulation costs\n",
    "cost = [np.transpose(file[\"henry_total_elapsed_time\"][:]), \n",
    "        np.transpose(file[\"gcmc_elapsed_time\"][:])]\n",
    "\n",
    "# total number of COFs in data set\n",
    "nb_COFs = X.shape[0] \n",
    "\n",
    "print(\"raw data - \\n\\tX:\", X.shape)\n",
    "for f in range(2):\n",
    "    print(\"\\tfidelity:\", f)\n",
    "    print(\"\\t\\ty:\", y[f].shape)\n",
    "    print(\"\\t\\tcost: \", cost[f].shape)\n",
    "    \n",
    "print(\"\\nEnsure features are normalized - \")\n",
    "print(\"max:\\n\", torch.max(X, 0).values)\n",
    "print(\"min:\\n\", torch.min(X, 0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfcd12ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total high-fidelity cost: 139887.66223703226 [min]\n",
      "total low-fidelity cost:  10076.305239888028 [min]\n",
      "\n",
      "average high-fidelity cost: 230.0783918372241 [min]\n",
      "average low-fidelity cost:  16.57287046034216 [min]\n",
      "average cost ratio:\t    13.444745568580501\n"
     ]
    }
   ],
   "source": [
    "print(\"total high-fidelity cost:\", sum(cost[1]).item(), \"[min]\")\n",
    "print(\"total low-fidelity cost: \", sum(cost[0]).item(), \"[min]\\n\")\n",
    "\n",
    "print(\"average high-fidelity cost:\", np.mean(cost[1]), \"[min]\")\n",
    "print(\"average low-fidelity cost: \", np.mean(cost[0]), \"[min]\")\n",
    "print(\"average cost ratio:\\t   \", np.mean(cost[1] / cost[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f9ab59",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "#### Construct Initial Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fbc1845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find COF closest to the center of feature space\n",
    "def get_initializing_COF(X):\n",
    "    # center of feature space\n",
    "    feature_center = np.ones(X.shape[1]) * 0.5\n",
    "    # max possible distance between normalized features\n",
    "    return np.argmin(np.linalg.norm(X - feature_center, axis=1))\n",
    "\n",
    "# yields np.array([25, 494, 523])\n",
    "def diverse_set(X, train_size):\n",
    "    # initialize with one random point; pick others in a max diverse fashion\n",
    "    ids_train = [get_initializing_COF(X)]\n",
    "    # select remaining training points\n",
    "    for j in range(train_size - 1):\n",
    "        # for each point in data set, compute its min dist to training set\n",
    "        dist_to_train_set = np.linalg.norm(X - X[ids_train, None, :], axis=2)\n",
    "        assert np.shape(dist_to_train_set) == (len(ids_train), nb_COFs)\n",
    "        min_dist_to_a_training_pt = np.min(dist_to_train_set, axis=0)\n",
    "        assert np.size(min_dist_to_a_training_pt) == nb_COFs\n",
    "        \n",
    "        # acquire point with max(min distance to train set) i.e. Furthest from train set\n",
    "        ids_train.append(np.argmax(min_dist_to_a_training_pt))\n",
    "    assert np.size(np.unique(ids_train)) == train_size # must be unique\n",
    "    return np.array(ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f187575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_acquired_set(X, y, nb_COFs_initialization, discrete_fidelities):\n",
    "    cof_ids = diverse_set(X, nb_COFs_initialization) # np.array(ids_train)\n",
    "    return torch.tensor([[f_id, cof_id] for cof_id in cof_ids for f_id in discrete_fidelities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "300bcf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct feature matrix of acquired points\n",
    "def build_X_train(acquired_set):\n",
    "    cof_ids = [a[1] for a in acquired_set]\n",
    "    f_ids = torch.tensor([a[0] for a in acquired_set])\n",
    "    return torch.cat((X[cof_ids, :], f_ids.unsqueeze(dim=-1)), dim=1)\n",
    "\n",
    "# construct output vector for acquired points\n",
    "def build_y_train(acquired_set):\n",
    "    return torch.tensor([y[f_id][cof_id] for f_id, cof_id in acquired_set]).unsqueeze(-1)\n",
    "\n",
    "# construct vector to track accumulated cost of acquired points\n",
    "def build_cost(acquired_set):\n",
    "    return torch.tensor([cost[f_id][cof_id] for f_id, cof_id in acquired_set]).unsqueeze(-1)\n",
    "\n",
    "# construct vector to track accumulated cost of acquired points\n",
    "def build_cost_fidelity(acquired_set, fidelity):\n",
    "    return torch.tensor([cost[f_id][cof_id] for f_id, cof_id in acquired_set if f_id == fidelity]).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec40fbc",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f1f9678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_initializing_functions(X, y):\n",
    "    ###\n",
    "    #  Construct training sets\n",
    "    ###\n",
    "    # list of (cof_id, fid_id)'s\n",
    "    acquired_set = [[1, 10], [0, 3], [0, 4]]\n",
    "    \n",
    "    # Training Sets\n",
    "    X_train = build_X_train(acquired_set)\n",
    "    y_train = build_y_train(acquired_set)\n",
    "    \n",
    "    ###\n",
    "    #  Test that the constructor functions are working properly\n",
    "    ###\n",
    "    assert np.allclose(X[10, :], X_train[0, :14])\n",
    "    assert X_train[0, 14] == 1\n",
    "    assert X_train[1, 14] == 0\n",
    "    assert y_train[0] == y[1][10] # y[fid_id][cof_id]\n",
    "    assert y_train[2] == y[0][4]\n",
    "    return\n",
    "\n",
    "test_initializing_functions(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d2ef9b",
   "metadata": {},
   "source": [
    "#### Surrogate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b21c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_surrogate_model(X_train, y_train):\n",
    "    model = SingleTaskMultiFidelityGP(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        outcome_transform=Standardize(m=1), # m is the output dimension\n",
    "        data_fidelity=X_train.shape[1] - 1\n",
    "    )   \n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_model(mll, optimizer=fit_gpytorch_torch)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a87aeb",
   "metadata": {},
   "source": [
    "#### Acquisition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6672eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate posterior mean and variance for a given fidelity\n",
    "def mu_sigma(model, X, fidelity):\n",
    "    f = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) * fidelity\n",
    "    X_f = torch.cat((X, f), dim=1) # last col is associated fidelity\n",
    "    f_posterior = model.posterior(X_f)\n",
    "    return f_posterior.mean.squeeze().detach().numpy(), np.sqrt(f_posterior.variance.squeeze().detach().numpy())\n",
    "\n",
    "# get the current best y-value of desired_fidelity in the acquired set\n",
    "def get_y_max(acquired_set, desired_fidelity):\n",
    "    return np.max([y[f_id][cof_id] for f_id, cof_id in acquired_set if f_id == desired_fidelity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ccf3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# efficient multi-fidelity correlation function\n",
    "# corr(y at given fidelity, y at high-fidelity)\n",
    "# (see notes)\n",
    "###\n",
    "def mfbo_correlation_function(model, X, fidelity):\n",
    "    # given fidelity\n",
    "    f   = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) * fidelity\n",
    "    X_f = torch.cat((X, f), dim=1) # last col is associated fidelity\n",
    "    \n",
    "    #  high-fidelity\n",
    "    hf   = torch.tensor((), dtype=torch.float64).new_ones((nb_COFs, 1)) \n",
    "    X_hf = torch.cat((X, hf), dim=1) # last col is associated fidelity\n",
    "\n",
    "    # combine into a single tensor\n",
    "    X_all_fid = torch.cat((X_f, X_hf), dim=0)\n",
    "    \n",
    "    # get variance for each fidelity\n",
    "    var_f = torch.flatten(model.posterior(X_f).variance)\n",
    "    var_hf = torch.flatten(model.posterior(X_hf).variance) # variance\n",
    "    \n",
    "    # posterior covariance \n",
    "    cov = torch.diag(model(X_all_fid).covariance_matrix[:X_f.size()[0], X_f.size()[0]:])\n",
    "    \n",
    "    corr = cov / (torch.sqrt(var_f) * torch.sqrt(var_hf))\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b278ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  Cost ratio\n",
    "###\n",
    "def estimate_cost_ratio(fidelity, acquired_set):\n",
    "    avg_cost_f  = torch.mean(build_cost_fidelity(acquired_set, fidelity))\n",
    "    avg_cost_hf = torch.mean(build_cost_fidelity(acquired_set, 1))\n",
    "    cr = avg_cost_hf / avg_cost_f\n",
    "    return cr.item()\n",
    "\n",
    "###\n",
    "#  Expected Imrovement function, only uses hf\n",
    "###\n",
    "def EI_hf(model, X, acquired_set):\n",
    "    hf_mu, hf_sigma = mu_sigma(model, X, 1)\n",
    "    y_max = get_y_max(acquired_set, 1)\n",
    "    \n",
    "    z = (hf_mu - y_max) / hf_sigma\n",
    "    explore_term = hf_sigma * norm.pdf(z) \n",
    "    exploit_term = (hf_mu - y_max) * norm.cdf(z) \n",
    "    ei = explore_term + exploit_term\n",
    "    return np.maximum(ei, np.zeros(nb_COFs))\n",
    "\n",
    "###\n",
    "#  Acquisition function\n",
    "###\n",
    "def acquisition_scores(model, X, fidelity, acquired_set):\n",
    "    # expected improvement for high-fidelity\n",
    "    ei = EI_hf(model, X, acquired_set) \n",
    "    \n",
    "    # augmenting functions\n",
    "    corr_f1_f0 = mfbo_correlation_function(model, X, fidelity)\n",
    "    \n",
    "    cr = estimate_cost_ratio(fidelity, acquired_set)\n",
    "\n",
    "    scores = torch.from_numpy(ei) * corr_f1_f0 * cr\n",
    "    return scores.detach().numpy()\n",
    "\n",
    "def in_acquired_set(f_id, cof_id, acquired_set):\n",
    "    for this_f_id, this_cof_id in acquired_set:\n",
    "        if this_cof_id == cof_id and this_f_id == f_id:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2130854c",
   "metadata": {},
   "source": [
    "# Run MFBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa07e691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization - \n",
      "\n",
      "\tid acquired =  [0, 1, 0, 1, 0, 1]\n",
      "\tfidelity acquired =  [25, 25, 494, 494, 523, 523]\n",
      "\tcosts acquired =  tensor([[ 33.2507],\n",
      "        [399.7577],\n",
      "        [ 33.2389],\n",
      "        [171.9985],\n",
      "        [  6.1207],\n",
      "        [280.4524]], dtype=torch.float64)  [min]\n",
      "\n",
      "\tTraining data:\n",
      "\n",
      "\t\t X train shape =  torch.Size([6, 15])\n",
      "\t\t y train shape =  torch.Size([6, 1])\n",
      "\t\t training feature vector = \n",
      " tensor([[0.1500, 0.4533, 0.1088, 0.5523, 0.4387, 0.1463, 0.3480, 0.2643, 0.0000,\n",
      "         0.1769, 0.2237, 0.0000, 0.0000, 0.3471, 0.0000],\n",
      "        [0.1500, 0.4533, 0.1088, 0.5523, 0.4387, 0.1463, 0.3480, 0.2643, 0.0000,\n",
      "         0.1769, 0.2237, 0.0000, 0.0000, 0.3471, 1.0000],\n",
      "        [0.8347, 0.9979, 0.9053, 0.0040, 0.0161, 0.0623, 0.0000, 0.0095, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.8347, 0.9979, 0.9053, 0.0040, 0.0161, 0.0623, 0.0000, 0.0095, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0509, 0.2570, 0.4148, 0.6881, 0.4814, 0.4971, 0.8866, 0.0000, 0.0000,\n",
      "         0.0000, 0.3800, 1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0509, 0.2570, 0.4148, 0.6881, 0.4814, 0.4971, 0.8866, 0.0000, 0.0000,\n",
      "         0.0000, 0.3800, 1.0000, 0.0000, 0.0000, 1.0000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  construct initial inputs\n",
    "###\n",
    "discrete_fidelities = [0, 1] # set of discrete fidelities to select from\n",
    "nb_COFs_initialization = 3   # at each fidelity, number of COFs to initialize with\n",
    "nb_iterations = 50          # BO budget, includes initializing COFs\n",
    "\n",
    "acquired_set = initialize_acquired_set(X, y, nb_COFs_initialization, discrete_fidelities)\n",
    "\n",
    "X_train = build_X_train(acquired_set)\n",
    "y_train = build_y_train(acquired_set)\n",
    "\n",
    "print(\"Initialization - \\n\")\n",
    "print(\"\\tid acquired = \", [acq_[0].item() for acq_ in acquired_set])\n",
    "print(\"\\tfidelity acquired = \", [acq_[1].item() for acq_ in acquired_set])\n",
    "print(\"\\tcosts acquired = \", build_cost(acquired_set), \" [min]\")\n",
    "\n",
    "print(\"\\n\\tTraining data:\\n\")\n",
    "print(\"\\t\\t X train shape = \", X_train.shape)\n",
    "print(\"\\t\\t y train shape = \", y_train.shape)\n",
    "print(\"\\t\\t training feature vector = \\n\", X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ae82c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BO iteration:  6\n",
      "Iter 10/100: 8.649342013940094\n",
      "Iter 20/100: 6.261137550553084\n",
      "Iter 30/100: 4.990258879375678\n",
      "Iter 40/100: 4.189199617403134\n",
      "Iter 50/100: 3.9705665875735296\n",
      "Iter 60/100: 3.861769073961766\n",
      "Iter 70/100: 3.8169358792521293\n",
      "Iter 80/100: 3.795750757562434\n",
      "Iter 90/100: 3.7861843682757677\n",
      "Iter 100/100: 3.7794894791133067\n",
      "\tacquired COF  521  at fidelity,  0\n",
      "\t\ty =  15.30972918212556\n",
      "\t\tcost =  6.206935115655263\n",
      "BO iteration:  7\n",
      "Iter 10/100: 7.614303650099994\n",
      "Iter 20/100: 5.5481737176964065\n",
      "Iter 30/100: 4.4193375753205375\n",
      "Iter 40/100: 3.6769469794672327\n",
      "Iter 50/100: 3.513558616402799\n",
      "Iter 60/100: 3.428943284770009\n",
      "Iter 70/100: 3.3896726465679157\n",
      "Iter 80/100: 3.3695011054234394\n",
      "Iter 90/100: 3.3575767043886984\n",
      "Iter 100/100: 3.347487472544626\n",
      "\tacquired COF  522  at fidelity,  0\n",
      "\t\ty =  15.951650673989429\n",
      "\t\tcost =  6.0286850492159525\n",
      "BO iteration:  8\n",
      "Iter 10/100: 6.850133783119505\n",
      "Iter 20/100: 5.027511893864176\n",
      "Iter 30/100: 4.017520396009643\n",
      "Iter 40/100: 3.334977681387051\n",
      "Iter 50/100: 3.207249960866922\n",
      "Iter 60/100: 3.1371892739627727\n",
      "Iter 70/100: 3.102250335692138\n",
      "Iter 80/100: 3.082457738315475\n",
      "Iter 90/100: 3.0693220621859405\n",
      "Iter 100/100: 3.0569681276770346\n",
      "\tacquired COF  583  at fidelity,  0\n",
      "\t\ty =  2.848405682526983\n",
      "\t\tcost =  24.38421953121821\n",
      "BO iteration:  9\n",
      "Iter 10/100: 6.2718023493026855\n",
      "Iter 20/100: 4.643357801296398\n",
      "Iter 30/100: 3.740426745638074\n",
      "Iter 40/100: 3.141060587078603\n",
      "Iter 50/100: 3.0193826350508552\n",
      "Iter 60/100: 2.9564958502217484\n",
      "Iter 70/100: 2.925718086578548\n",
      "Iter 80/100: 2.9084775774754164\n",
      "Iter 90/100: 2.8971051963217445\n",
      "Iter 100/100: 2.886593765264876\n",
      "\tacquired COF  524  at fidelity,  0\n",
      "\t\ty =  6.472940599293585\n",
      "\t\tcost =  4.269400648276012\n",
      "BO iteration:  10\n",
      "Iter 10/100: 5.797035457331448\n",
      "Iter 20/100: 4.3222469419462115\n",
      "Iter 30/100: 3.4959332215807373\n",
      "Iter 40/100: 2.9400391682154585\n",
      "Iter 50/100: 2.835743445418519\n",
      "Iter 60/100: 2.7809874904928242\n",
      "Iter 70/100: 2.752928918406733\n",
      "Iter 80/100: 2.736210723659348\n",
      "Iter 90/100: 2.7243197830185286\n",
      "Iter 100/100: 2.712888331334978\n",
      "\tacquired COF  0  at fidelity,  0\n",
      "\t\ty =  1.5805050493821187\n",
      "\t\tcost =  3.4525069634119667\n",
      "BO iteration:  11\n",
      "Iter 10/100: 5.41096347468792\n",
      "Iter 20/100: 4.06274673674083\n",
      "Iter 30/100: 3.302890678895645\n",
      "Iter 40/100: 2.7854788112297912\n",
      "Iter 50/100: 2.6950047394136174\n",
      "Iter 60/100: 2.646480505438719\n",
      "Iter 70/100: 2.6205218974928712\n",
      "Iter 80/100: 2.604285288013379\n",
      "Iter 90/100: 2.5921223027418607\n",
      "Iter 100/100: 2.580138698341468\n",
      "\tacquired COF  223  at fidelity,  0\n",
      "\t\ty =  4.261607264546673\n",
      "\t\tcost =  9.34896615346273\n",
      "BO iteration:  12\n",
      "Iter 10/100: 5.086933525786033\n",
      "Iter 20/100: 3.843600431682356\n",
      "Iter 30/100: 3.1370631108644376\n",
      "Iter 40/100: 2.6518602722625295\n",
      "Iter 50/100: 2.5721323584181914\n",
      "Iter 60/100: 2.5291123717071335\n",
      "Iter 70/100: 2.504536467156498\n",
      "Iter 80/100: 2.4884889587365\n",
      "Iter 90/100: 2.476085560457181\n",
      "Iter 100/100: 2.4636884880333714\n",
      "\tacquired COF  9  at fidelity,  0\n",
      "\t\ty =  4.5299255458988075\n",
      "\t\tcost =  28.559914251168568\n",
      "BO iteration:  13\n",
      "Iter 10/100: 4.812050790221514\n",
      "Iter 20/100: 3.657037679334282\n",
      "Iter 30/100: 2.994754708400861\n",
      "Iter 40/100: 2.537096906510757\n",
      "Iter 50/100: 2.4653804145099474\n",
      "Iter 60/100: 2.4260605973687475\n",
      "Iter 70/100: 2.4029613312537963\n",
      "Iter 80/100: 2.3871391318429356\n",
      "Iter 90/100: 2.3742498101482385\n",
      "Iter 100/100: 2.361101097984507\n",
      "\tacquired COF  73  at fidelity,  0\n",
      "\t\ty =  4.159682969326826\n",
      "\t\tcost =  3.758783952395121\n",
      "BO iteration:  14\n",
      "Iter 10/100: 4.57625734723482\n",
      "Iter 20/100: 3.496377181225939\n",
      "Iter 30/100: 2.8731446404679724\n",
      "Iter 40/100: 2.4370836340112354\n",
      "Iter 50/100: 2.3732205991159794\n",
      "Iter 60/100: 2.3373040404022976\n",
      "Iter 70/100: 2.315074190201187\n",
      "Iter 80/100: 2.299168615051625\n",
      "Iter 90/100: 2.285665587420053\n",
      "Iter 100/100: 2.271617504498877\n",
      "\tacquired COF  338  at fidelity,  0\n",
      "\t\ty =  1.1153962862564593\n",
      "\t\tcost =  34.08373984893163\n",
      "BO iteration:  15\n",
      "Iter 10/100: 4.371211452564325\n",
      "Iter 20/100: 3.355643587206589\n",
      "Iter 30/100: 2.766002260312492\n",
      "Iter 40/100: 2.3435662950776903\n",
      "Iter 50/100: 2.290691666661148\n",
      "Iter 60/100: 2.2577641893241163\n",
      "Iter 70/100: 2.2357292997595968\n",
      "Iter 80/100: 2.219439795013405\n",
      "Iter 90/100: 2.2047956463305147\n",
      "Iter 100/100: 2.18904954628466\n",
      "\tacquired COF  520  at fidelity,  0\n",
      "\t\ty =  6.140702426978196\n",
      "\t\tcost =  11.222975416978201\n",
      "BO iteration:  16\n",
      "Iter 10/100: 4.193318867629737\n",
      "Iter 20/100: 3.2342484852678033\n",
      "Iter 30/100: 2.6768760090664783\n",
      "Iter 40/100: 2.2757916563839835\n",
      "Iter 50/100: 2.2275674342474145\n",
      "Iter 60/100: 2.1946289678269055\n",
      "Iter 70/100: 2.17386529752046\n",
      "Iter 80/100: 2.1582856810827034\n",
      "Iter 90/100: 2.1438461032396026\n",
      "Iter 100/100: 2.128519628814477\n",
      "\tacquired COF  521  at fidelity,  1\n",
      "\t\ty =  15.766064256252303\n",
      "\t\tcost =  602.2006956656774\n",
      "BO iteration:  17\n",
      "Iter 10/100: 4.022939400143419\n",
      "Iter 20/100: 3.1089180266276744\n",
      "Iter 30/100: 2.56153856893429\n",
      "Iter 40/100: 2.2010808630384293\n",
      "Iter 50/100: 2.0977188824195245\n",
      "Iter 60/100: 2.033227709857579\n",
      "Iter 70/100: 2.010542058556338\n",
      "Iter 80/100: 2.001941642984137\n",
      "Iter 90/100: 1.9996302957913528\n",
      "Iter 100/100: 1.9988339572267133\n",
      "\tacquired COF  98  at fidelity,  0\n",
      "\t\ty =  0.07902535518803018\n",
      "\t\tcost =  1.1220028042793273\n",
      "BO iteration:  18\n",
      "Iter 10/100: 3.882987283285372\n",
      "Iter 20/100: 3.0123359046198317\n",
      "Iter 30/100: 2.487698350368662\n",
      "Iter 40/100: 2.1357869479819374\n",
      "Iter 50/100: 2.040981691470556\n",
      "Iter 60/100: 1.978946674553797\n",
      "Iter 70/100: 1.9559972996331487\n",
      "Iter 80/100: 1.9472074100436094\n",
      "Iter 90/100: 1.9448952131474353\n",
      "Iter 100/100: 1.9442446883097533\n",
      "\tacquired COF  224  at fidelity,  0\n",
      "\t\ty =  3.6801115645243847\n",
      "\t\tcost =  8.110053702195486\n",
      "BO iteration:  19\n",
      "Iter 10/100: 3.7551051894374834\n",
      "Iter 20/100: 2.92352857232499\n",
      "Iter 30/100: 2.4179700088372456\n",
      "Iter 40/100: 2.0749937607901074\n",
      "Iter 50/100: 1.986281935627596\n",
      "Iter 60/100: 1.926291689664411\n",
      "Iter 70/100: 1.9041222227898063\n",
      "Iter 80/100: 1.8956302067471125\n",
      "Iter 90/100: 1.8935676965255548\n",
      "Iter 100/100: 1.8929365190444016\n",
      "\tacquired COF  463  at fidelity,  0\n",
      "\t\ty =  5.863058699494186\n",
      "\t\tcost =  22.66465273300807\n",
      "BO iteration:  20\n",
      "Iter 10/100: 3.6426702171568364\n",
      "Iter 20/100: 2.8464873925543066\n",
      "Iter 30/100: 2.360813176274749\n",
      "Iter 40/100: 2.0306054249634493\n",
      "Iter 50/100: 1.9485752482603473\n",
      "Iter 60/100: 1.8917955766319436\n",
      "Iter 70/100: 1.8686144352467497\n",
      "Iter 80/100: 1.8596995649769439\n",
      "Iter 90/100: 1.8575293712497447\n",
      "Iter 100/100: 1.8570261352608448\n",
      "\tacquired COF  155  at fidelity,  0\n",
      "\t\ty =  8.124910921699056\n",
      "\t\tcost =  4.178414964675904\n",
      "BO iteration:  21\n",
      "Iter 10/100: 3.5432402522402215\n",
      "Iter 20/100: 2.7801818638422717\n",
      "Iter 30/100: 2.316428331044657\n",
      "Iter 40/100: 2.003874007879766\n",
      "Iter 50/100: 1.9279020514576284\n",
      "Iter 60/100: 1.8710157181123876\n",
      "Iter 70/100: 1.8492192407973147\n",
      "Iter 80/100: 1.8406236382648444\n",
      "Iter 90/100: 1.8377480242417565\n",
      "Iter 100/100: 1.8369214653579686\n",
      "\tacquired COF  84  at fidelity,  0\n",
      "\t\ty =  3.8805251683537945\n",
      "\t\tcost =  14.227486248811086\n",
      "BO iteration:  22\n",
      "Iter 10/100: 3.4472921961922185\n",
      "Iter 20/100: 2.713600906764736\n",
      "Iter 30/100: 2.263376747003274\n",
      "Iter 40/100: 1.9590682194657645\n",
      "Iter 50/100: 1.8868870829069075\n",
      "Iter 60/100: 1.8325593864202885\n",
      "Iter 70/100: 1.81137878461521\n",
      "Iter 80/100: 1.803163505549936\n",
      "Iter 90/100: 1.80038605944402\n",
      "Iter 100/100: 1.799581834511554\n",
      "\tacquired COF  262  at fidelity,  0\n",
      "\t\ty =  0.6837883369606389\n",
      "\t\tcost =  7.507218949000041\n",
      "BO iteration:  23\n",
      "Iter 10/100: 3.3610489806026407\n",
      "Iter 20/100: 2.654322029095936\n",
      "Iter 30/100: 2.2185730785734505\n",
      "Iter 40/100: 1.9290402984755401\n",
      "Iter 50/100: 1.8595872103430224\n",
      "Iter 60/100: 1.8082768857420641\n",
      "Iter 70/100: 1.7884122306897154\n",
      "Iter 80/100: 1.7807262375520856\n",
      "Iter 90/100: 1.778029846976613\n",
      "Iter 100/100: 1.7772260090364658\n",
      "\tacquired COF  41  at fidelity,  0\n",
      "\t\ty =  5.794893007842867\n",
      "\t\tcost =  4.09711453517278\n",
      "BO iteration:  24\n",
      "Iter 10/100: 3.281788658316992\n",
      "Iter 20/100: 2.5998798736068336\n",
      "Iter 30/100: 2.1764971848301315\n",
      "Iter 40/100: 1.893760966111529\n",
      "Iter 50/100: 1.8271090839197133\n",
      "Iter 60/100: 1.7772240233094163\n",
      "Iter 70/100: 1.757928309550695\n",
      "Iter 80/100: 1.7504447957060367\n",
      "Iter 90/100: 1.7478230275688549\n",
      "Iter 100/100: 1.7470619885373762\n",
      "\tacquired COF  522  at fidelity,  1\n",
      "\t\ty =  12.350590208958222\n",
      "\t\tcost =  255.85366715192794\n",
      "BO iteration:  25\n",
      "Iter 10/100: 3.202091157434694\n",
      "Iter 20/100: 2.540824389069665\n",
      "Iter 30/100: 2.1187904075895387\n",
      "Iter 40/100: 1.8196848717800789\n",
      "Iter 50/100: 1.7665116798388232\n",
      "Iter 60/100: 1.7072188257816134\n",
      "Iter 70/100: 1.6916511584750014\n",
      "Iter 80/100: 1.684119517050342\n",
      "Iter 90/100: 1.681589591501559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100/100: 1.6806714650796797\n",
      "\tacquired COF  14  at fidelity,  0\n",
      "\t\ty =  6.87856134030866\n",
      "\t\tcost =  3.751832369963328\n",
      "BO iteration:  26\n",
      "Iter 10/100: 3.1356438535229225\n",
      "Iter 20/100: 2.49601031455512\n",
      "Iter 30/100: 2.0860708270206634\n",
      "Iter 40/100: 1.793930739085024\n",
      "Iter 50/100: 1.7438991783835032\n",
      "Iter 60/100: 1.6823221189822783\n",
      "Iter 70/100: 1.6690108880228733\n",
      "Iter 80/100: 1.6616256854226903\n",
      "Iter 90/100: 1.6594131314011162\n",
      "Iter 100/100: 1.6585558436766183\n",
      "\tacquired COF  500  at fidelity,  0\n",
      "\t\ty =  3.190230055315174\n",
      "\t\tcost =  20.45252423286438\n",
      "BO iteration:  27\n",
      "Iter 10/100: 3.074354048536836\n",
      "Iter 20/100: 2.453267564477352\n",
      "Iter 30/100: 2.052246118906989\n",
      "Iter 40/100: 1.7656276108637423\n",
      "Iter 50/100: 1.7170077300700601\n",
      "Iter 60/100: 1.6590471110744052\n",
      "Iter 70/100: 1.6446989843161846\n",
      "Iter 80/100: 1.6374617634050423\n",
      "Iter 90/100: 1.635042465647385\n",
      "Iter 100/100: 1.634172816789661\n",
      "\tacquired COF  237  at fidelity,  0\n",
      "\t\ty =  17.508435556234446\n",
      "\t\tcost =  5.643308317661285\n",
      "BO iteration:  28\n",
      "Iter 10/100: 3.035193919014089\n",
      "Iter 20/100: 2.4407900327850376\n",
      "Iter 30/100: 2.0832917507988573\n",
      "Iter 40/100: 1.8613617779623102\n",
      "Iter 50/100: 1.7758234748225181\n",
      "Iter 60/100: 1.7369580621734477\n",
      "Iter 70/100: 1.722469024333096\n",
      "Iter 80/100: 1.7165322606191578\n",
      "Iter 90/100: 1.714926506445597\n",
      "Iter 100/100: 1.7143015714967247\n",
      "\tacquired COF  237  at fidelity,  1\n",
      "\t\ty =  18.170979513751256\n",
      "\t\tcost =  233.49063474734623\n",
      "BO iteration:  29\n",
      "Iter 10/100: 2.9807007943358617\n",
      "Iter 20/100: 2.3984291695214957\n",
      "Iter 30/100: 2.036167023695423\n",
      "Iter 40/100: 1.7740045122066905\n",
      "Iter 50/100: 1.7089350289341019\n",
      "Iter 60/100: 1.6629854245327234\n",
      "Iter 70/100: 1.6495793774150516\n",
      "Iter 80/100: 1.6441692876814065\n",
      "Iter 90/100: 1.6424411772979877\n",
      "Iter 100/100: 1.6416957362635243\n",
      "\tacquired COF  212  at fidelity,  0\n",
      "\t\ty =  14.953579818605947\n",
      "\t\tcost =  2.68871523141861\n",
      "BO iteration:  30\n",
      "Iter 10/100: 2.936843822973437\n",
      "Iter 20/100: 2.3743771295873075\n",
      "Iter 30/100: 2.030446713344125\n",
      "Iter 40/100: 1.7812037133530472\n",
      "Iter 50/100: 1.7020948154827626\n",
      "Iter 60/100: 1.6644187602840057\n",
      "Iter 70/100: 1.6478941989190363\n",
      "Iter 80/100: 1.6427347408269406\n",
      "Iter 90/100: 1.640588819830956\n",
      "Iter 100/100: 1.6399311698782821\n",
      "\tacquired COF  319  at fidelity,  0\n",
      "\t\ty =  17.91655148977698\n",
      "\t\tcost =  2.3083270311355593\n",
      "BO iteration:  31\n",
      "Iter 10/100: 2.8977822415589323\n",
      "Iter 20/100: 2.353835412853437\n",
      "Iter 30/100: 2.0329474566409877\n",
      "Iter 40/100: 1.8242161698133625\n",
      "Iter 50/100: 1.7162567745621709\n",
      "Iter 60/100: 1.686695395435225\n",
      "Iter 70/100: 1.6690937125450158\n",
      "Iter 80/100: 1.6633234474636107\n",
      "Iter 90/100: 1.6613736853331473\n",
      "Iter 100/100: 1.660801043545443\n",
      "\tacquired COF  135  at fidelity,  0\n",
      "\t\ty =  5.512355662197943\n",
      "\t\tcost =  3.0984362999598183\n",
      "BO iteration:  32\n",
      "Iter 10/100: 2.8544495081967955\n",
      "Iter 20/100: 2.324225993414011\n",
      "Iter 30/100: 2.011034125372469\n",
      "Iter 40/100: 1.8102075545139003\n",
      "Iter 50/100: 1.7008325081029863\n",
      "Iter 60/100: 1.6717379429347416\n",
      "Iter 70/100: 1.6552017805997157\n",
      "Iter 80/100: 1.6494741881219808\n",
      "Iter 90/100: 1.647429348543554\n",
      "Iter 100/100: 1.6468282777787215\n",
      "\tacquired COF  319  at fidelity,  1\n",
      "\t\ty =  16.85103319560969\n",
      "\t\tcost =  201.78864438533782\n",
      "BO iteration:  33\n",
      "Iter 10/100: 2.809654095802879\n",
      "Iter 20/100: 2.2889148476434875\n",
      "Iter 30/100: 1.9712409573172873\n",
      "Iter 40/100: 1.7346712976401941\n",
      "Iter 50/100: 1.657564648151676\n",
      "Iter 60/100: 1.6083234657229852\n",
      "Iter 70/100: 1.5944401425532464\n",
      "Iter 80/100: 1.587711406529172\n",
      "Iter 90/100: 1.586088472851378\n",
      "Iter 100/100: 1.5852752524455218\n",
      "\tacquired COF  45  at fidelity,  0\n",
      "\t\ty =  6.9040236041623775\n",
      "\t\tcost =  3.538982967535655\n",
      "BO iteration:  34\n",
      "Iter 10/100: 2.7723204990202848\n",
      "Iter 20/100: 2.2632783105633685\n",
      "Iter 30/100: 1.9524754557009227\n",
      "Iter 40/100: 1.7246558839942956\n",
      "Iter 50/100: 1.638901705931315\n",
      "Iter 60/100: 1.6011168093349695\n",
      "Iter 70/100: 1.5829697222918668\n",
      "Iter 80/100: 1.57860722109256\n",
      "Iter 90/100: 1.5762702595878675\n",
      "Iter 100/100: 1.575512550415651\n",
      "\tacquired COF  79  at fidelity,  0\n",
      "\t\ty =  9.149907633968926\n",
      "\t\tcost =  3.9594157338142395\n",
      "BO iteration:  35\n",
      "Iter 10/100: 2.7375909755875973\n",
      "Iter 20/100: 2.2401558569242352\n",
      "Iter 30/100: 1.9375446050024212\n",
      "Iter 40/100: 1.7230529448995282\n",
      "Iter 50/100: 1.6243547765320774\n",
      "Iter 60/100: 1.5954167516625488\n",
      "Iter 70/100: 1.580197235407998\n",
      "Iter 80/100: 1.5747756669708124\n",
      "Iter 90/100: 1.572632406545093\n",
      "Iter 100/100: 1.5719749582540445\n",
      "\tacquired COF  335  at fidelity,  0\n",
      "\t\ty =  5.7583972916382535\n",
      "\t\tcost =  41.68300148248673\n",
      "BO iteration:  36\n",
      "Iter 10/100: 2.7026213330719395\n",
      "Iter 20/100: 2.215713175208602\n",
      "Iter 30/100: 1.9178563540208882\n",
      "Iter 40/100: 1.7062538304004078\n",
      "Iter 50/100: 1.6096506555387675\n",
      "Iter 60/100: 1.5807438345928757\n",
      "Iter 70/100: 1.5658445585733267\n",
      "Iter 80/100: 1.5607400737177675\n",
      "Iter 90/100: 1.5587545386928339\n",
      "Iter 100/100: 1.5580896982231844\n",
      "\tacquired COF  367  at fidelity,  0\n",
      "\t\ty =  2.18506035799339\n",
      "\t\tcost =  3.4525225003560385\n",
      "BO iteration:  37\n",
      "Iter 10/100: 2.6679985297225923\n",
      "Iter 20/100: 2.1905708745328782\n",
      "Iter 30/100: 1.8954745196952743\n",
      "Iter 40/100: 1.684873460948598\n",
      "Iter 50/100: 1.5912855058728614\n",
      "Iter 60/100: 1.5626654473884927\n",
      "Iter 70/100: 1.5476132094573418\n",
      "Iter 80/100: 1.5423868317994713\n",
      "Iter 90/100: 1.5404178555200474\n",
      "Iter 100/100: 1.5398053617733047\n",
      "\tacquired COF  336  at fidelity,  0\n",
      "\t\ty =  1.0194351735182752\n",
      "\t\tcost =  36.358710781733194\n",
      "BO iteration:  38\n",
      "Iter 10/100: 2.6365530296710835\n",
      "Iter 20/100: 2.16837792630328\n",
      "Iter 30/100: 1.8764153393744039\n",
      "Iter 40/100: 1.6633635544212932\n",
      "Iter 50/100: 1.5762992454098013\n",
      "Iter 60/100: 1.5468354216661122\n",
      "Iter 70/100: 1.5302620093932255\n",
      "Iter 80/100: 1.5247164270791247\n",
      "Iter 90/100: 1.5229431402679097\n",
      "Iter 100/100: 1.5224388573654601\n",
      "\tacquired COF  318  at fidelity,  0\n",
      "\t\ty =  4.332835922781191\n",
      "\t\tcost =  10.68512853384018\n",
      "BO iteration:  39\n",
      "Iter 10/100: 2.6070683192574613\n",
      "Iter 20/100: 2.147791897216737\n",
      "Iter 30/100: 1.8595383699181651\n",
      "Iter 40/100: 1.6477503969307248\n",
      "Iter 50/100: 1.5642490394316\n",
      "Iter 60/100: 1.5346508394025364\n",
      "Iter 70/100: 1.5176604060245593\n",
      "Iter 80/100: 1.512420225771666\n",
      "Iter 90/100: 1.51079996587965\n",
      "Iter 100/100: 1.5102865635975036\n",
      "\tacquired COF  83  at fidelity,  0\n",
      "\t\ty =  4.708848064234706\n",
      "\t\tcost =  3.1653184016545612\n",
      "BO iteration:  40\n",
      "Iter 10/100: 2.5773591906534863\n",
      "Iter 20/100: 2.126970142951617\n",
      "Iter 30/100: 1.8424850669322883\n",
      "Iter 40/100: 1.6329943266556497\n",
      "Iter 50/100: 1.5486031554725557\n",
      "Iter 60/100: 1.519766819753424\n",
      "Iter 70/100: 1.5041249011160207\n",
      "Iter 80/100: 1.4986038745652228\n",
      "Iter 90/100: 1.4969199671364652\n",
      "Iter 100/100: 1.4964288570707924\n",
      "\tacquired COF  212  at fidelity,  1\n",
      "\t\ty =  14.992345956579042\n",
      "\t\tcost =  194.7327691356341\n",
      "BO iteration:  41\n",
      "Iter 10/100: 2.546792977234608\n",
      "Iter 20/100: 2.102164214080154\n",
      "Iter 30/100: 1.8127725565762458\n",
      "Iter 40/100: 1.5755546594117509\n",
      "Iter 50/100: 1.509294647127128\n",
      "Iter 60/100: 1.4773808463764517\n",
      "Iter 70/100: 1.4598894560632714\n",
      "Iter 80/100: 1.4543836787241167\n",
      "Iter 90/100: 1.4528420176809924\n",
      "Iter 100/100: 1.4521799747689548\n",
      "\tacquired COF  71  at fidelity,  0\n",
      "\t\ty =  6.903680638373734\n",
      "\t\tcost =  2.7140065828959146\n",
      "BO iteration:  42\n",
      "Iter 10/100: 2.5222107525659943\n",
      "Iter 20/100: 2.0853329273946035\n",
      "Iter 30/100: 1.8002410254121564\n",
      "Iter 40/100: 1.5683973198355876\n",
      "Iter 50/100: 1.504125828255371\n",
      "Iter 60/100: 1.4704460344579235\n",
      "Iter 70/100: 1.4526507551869163\n",
      "Iter 80/100: 1.4481945688561821\n",
      "Iter 90/100: 1.446277344683691\n",
      "Iter 100/100: 1.4455049312206572\n",
      "\tacquired COF  189  at fidelity,  0\n",
      "\t\ty =  3.2467580347114993\n",
      "\t\tcost =  9.966407251358032\n",
      "BO iteration:  43\n",
      "Iter 10/100: 2.497114488955022\n",
      "Iter 20/100: 2.067366564213622\n",
      "Iter 30/100: 1.784684817143071\n",
      "Iter 40/100: 1.5529154681114965\n",
      "Iter 50/100: 1.4864540453594977\n",
      "Iter 60/100: 1.457177802054391\n",
      "Iter 70/100: 1.4406971187846793\n",
      "Iter 80/100: 1.4349649211104243\n",
      "Iter 90/100: 1.4334956959837255\n",
      "Iter 100/100: 1.4329153841139741\n",
      "\tacquired COF  48  at fidelity,  0\n",
      "\t\ty =  2.805948915898106\n",
      "\t\tcost =  17.12719488143921\n",
      "BO iteration:  44\n",
      "Iter 10/100: 2.472491509298235\n",
      "Iter 20/100: 2.049331277393085\n",
      "Iter 30/100: 1.768465570129299\n",
      "Iter 40/100: 1.5377337513391636\n",
      "Iter 50/100: 1.4676956128584515\n",
      "Iter 60/100: 1.441504363605428\n",
      "Iter 70/100: 1.4277899730985395\n",
      "Iter 80/100: 1.4218509560141184\n",
      "Iter 90/100: 1.4200543959889453\n",
      "Iter 100/100: 1.41946733478181\n",
      "\tacquired COF  375  at fidelity,  0\n",
      "\t\ty =  19.56430271904108\n",
      "\t\tcost =  13.845126247406007\n",
      "BO iteration:  45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10/100: 2.4600637640957057\n",
      "Iter 20/100: 2.049730163080566\n",
      "Iter 30/100: 1.7945530927942352\n",
      "Iter 40/100: 1.6314184597778247\n",
      "Iter 50/100: 1.5312014511736218\n",
      "Iter 60/100: 1.5110472877992607\n",
      "Iter 70/100: 1.4957296284567994\n",
      "Iter 80/100: 1.491157355705427\n",
      "Iter 90/100: 1.4893816188374518\n",
      "Iter 100/100: 1.488805914070356\n",
      "\tacquired COF  376  at fidelity,  0\n",
      "\t\ty =  19.420085742018372\n",
      "\t\tcost =  16.50269153515498\n",
      "BO iteration:  46\n",
      "Iter 10/100: 2.43816173222178\n",
      "Iter 20/100: 2.033685969628027\n",
      "Iter 30/100: 1.7746242762630764\n",
      "Iter 40/100: 1.5571959901648342\n",
      "Iter 50/100: 1.5017935685109247\n",
      "Iter 60/100: 1.4484310288266646\n",
      "Iter 70/100: 1.4375321352967694\n",
      "Iter 80/100: 1.4306857304952805\n",
      "Iter 90/100: 1.4291939871403505\n",
      "Iter 100/100: 1.4282224413644533\n",
      "\tacquired COF  375  at fidelity,  1\n",
      "\t\ty =  18.53448594783226\n",
      "\t\tcost =  1002.6888410488765\n",
      "BO iteration:  47\n",
      "Iter 10/100: 2.411731639324082\n",
      "Iter 20/100: 2.0082525523276344\n",
      "Iter 30/100: 1.7382894886427092\n",
      "Iter 40/100: 1.4943734503585742\n",
      "Iter 50/100: 1.4292260827460603\n",
      "Iter 60/100: 1.4014704445371076\n",
      "Iter 70/100: 1.384646555001498\n",
      "Iter 80/100: 1.3786171665575835\n",
      "Iter 90/100: 1.3762048127529858\n",
      "Iter 100/100: 1.375395576378909\n",
      "\tacquired COF  376  at fidelity,  1\n",
      "\t\ty =  18.396015574220662\n",
      "\t\tcost =  1178.0223760167758\n",
      "BO iteration:  48\n",
      "Iter 10/100: 2.3850124835278015\n",
      "Iter 20/100: 1.9828698849578197\n",
      "Iter 30/100: 1.703913624550741\n",
      "Iter 40/100: 1.4407328899945455\n",
      "Iter 50/100: 1.4006623005781054\n",
      "Iter 60/100: 1.3449503312189417\n",
      "Iter 70/100: 1.3320670406281883\n",
      "Iter 80/100: 1.3259303714239117\n",
      "Iter 90/100: 1.3230959642215891\n",
      "Iter 100/100: 1.3223931269573053\n",
      "\tacquired COF  65  at fidelity,  0\n",
      "\t\ty =  3.7516039067182674\n",
      "\t\tcost =  14.547406915823618\n",
      "BO iteration:  49\n",
      "Iter 10/100: 2.364615832882993\n",
      "Iter 20/100: 1.9679744725045114\n",
      "Iter 30/100: 1.69065848462738\n",
      "Iter 40/100: 1.4302891902193966\n",
      "Iter 50/100: 1.3979513165802309\n",
      "Iter 60/100: 1.3338275777340904\n",
      "Iter 70/100: 1.3268281794834533\n",
      "Iter 80/100: 1.3177727496741054\n",
      "Iter 90/100: 1.31612146164348\n",
      "Iter 100/100: 1.3154914872037495\n",
      "\tacquired COF  196  at fidelity,  0\n",
      "\t\ty =  3.6163628554350997\n",
      "\t\tcost =  31.162790449460346\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  Run Search\n",
    "###\n",
    "for i in range(nb_COFs_initialization * len(discrete_fidelities), nb_iterations): \n",
    "    print(\"BO iteration: \", i)\n",
    "    ###\n",
    "    #  Train Model\n",
    "    ###\n",
    "    model = train_surrogate_model(X_train, y_train)\n",
    "\n",
    "    ###\n",
    "    # Acquire new (COF, fidelity) not yet acquired.\n",
    "    ###\n",
    "    # entry (fid_id, cof_id) is the acquisition value for fidelity f_id and cof cof_id\n",
    "    the_acquisition_scores = np.array([acquisition_scores(model, X, f_id, acquired_set) for f_id in discrete_fidelities])\n",
    "    # overwrite acquired COFs/fidelities with negative infinity to not choose these.\n",
    "    for f_id, cof_id in acquired_set:\n",
    "        the_acquisition_scores[f_id, cof_id] = - np.inf\n",
    "    # select COF/fidelity with highest aquisition score.\n",
    "    f_id, cof_id = np.unravel_index(np.argmax(the_acquisition_scores), np.shape(the_acquisition_scores))\n",
    "    assert not in_acquired_set(f_id, cof_id, acquired_set)\n",
    "    # Update acquired_set\n",
    "    acq = torch.tensor([[f_id, cof_id]], dtype=int)\n",
    "    acquired_set = torch.cat((acquired_set, acq))\n",
    "    \n",
    "    ###\n",
    "    #\n",
    "    ###\n",
    "    print(\"\\tacquired COF \", cof_id, \" at fidelity, \", f_id)\n",
    "    print(\"\\t\\ty = \", y[f_id][cof_id].item())\n",
    "    print(\"\\t\\tcost = \", cost[f_id][cof_id])\n",
    "            \n",
    "    # Update training sets\n",
    "    X_train = build_X_train(acquired_set)\n",
    "    y_train = build_y_train(acquired_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b72adb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of unique COFs acquired 40\n",
      "woo, top COF acquired!\n",
      "iteration we acquire top COF =  45\n",
      "accumulated cost up to observation of top COF =  2776.702110997835  [min]\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# look at unique COFs acquired\n",
    "###\n",
    "cof_ids_acquired = torch.tensor([acq[1] for acq in acquired_set])\n",
    "n_unique_cofs_acquired = len(np.unique(cof_ids_acquired))\n",
    "print(\"total number of unique COFs acquired\", n_unique_cofs_acquired)\n",
    "\n",
    "###\n",
    "#  Iterations until top COF and accumulated \n",
    "###\n",
    "if np.argmax(y[1]) in cof_ids_acquired:\n",
    "    print(\"woo, top COF acquired!\")\n",
    "else:\n",
    "    print(\"oh no, top COF not acquired!\")\n",
    "    \n",
    "BO_iter_top_cof_acquired = np.argmax(cof_ids_acquired == np.argmax(y[1]))\n",
    "top_cof_acc_cost = sum(build_cost(acquired_set)[:BO_iter_top_cof_acquired])\n",
    "\n",
    "print(\"iteration we acquire top COF = \", BO_iter_top_cof_acquired.item() + 1)\n",
    "print(\"accumulated cost up to observation of top COF = \", top_cof_acc_cost.item(), \" [min]\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21be3bd",
   "metadata": {},
   "source": [
    "# Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe080e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfbo_res = dict({'acquired_set': acquired_set.detach().numpy(),\n",
    "                 'cost_acquired': build_cost(acquired_set).flatten().detach().numpy(),\n",
    "                 'nb_COFs_initialization': nb_COFs_initialization,\n",
    "                 'BO_iter_top_cof_acquired': BO_iter_top_cof_acquired\n",
    "                })\n",
    "\n",
    "with open('search_results/mfbo_results_with_EI.pkl', 'wb') as file:\n",
    "    pickle.dump(mfbo_res, file)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "873b9eed737f4a6d896d154d73024f53",
   "lastKernelId": "464ee535-3ea4-4199-a625-569df1ee6433"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
