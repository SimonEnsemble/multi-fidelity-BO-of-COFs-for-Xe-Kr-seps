{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c0523b5",
   "metadata": {},
   "source": [
    "## Strategy\n",
    "1. implement SingleTaskMultiFidelity botorch model\n",
    "2. get augmented EI working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69942a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from botorch.models import SingleTaskMultiFidelityGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15fa53c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.test_functions.multi_fidelity import AugmentedHartmann\n",
    "\n",
    "\n",
    "problem = AugmentedHartmann(negate=True).to()\n",
    "fidelities = torch.tensor([0.5, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d82158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example code\n",
    "train_x = torch.linspace(0, 1, 100)\n",
    "\n",
    "train_y = torch.stack([\n",
    "    torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 2.0,\n",
    "    torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 2.0\n",
    "], -1)\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eb34ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###\n",
    "# #  import data\n",
    "# ###\n",
    "# f = h5py.File(\"targets_and_normalized_features.jld2\", \"r\")\n",
    "\n",
    "# X = torch.from_numpy(np.transpose(f[\"X\"][:]))\n",
    "# henry_y = torch.from_numpy(np.transpose(f[\"henry_y\"][:]))\n",
    "# gcmc_y  = torch.from_numpy(np.transpose(f[\"gcmc_y\"][:]))\n",
    "# print(\"data - \\nX:\", X.shape)\n",
    "# print(\"henry_y:\", henry_y.shape)\n",
    "# print(\"gcmc_y: \", gcmc_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79bc7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###\n",
    "# #  construct initial inputs\n",
    "# #  1. get initial points\n",
    "# #  2. standardize outputs\n",
    "# #  3. stack into tensor\n",
    "# ###\n",
    "# nb_COFs = henry_y.shape[0]\n",
    "# nb_COFs_initialization = 15\n",
    "# ids_acquired = np.random.choice(np.arange((nb_COFs)), size=nb_COFs_initialization, replace=False)\n",
    "# # y_acquired = (y_acquired - torch.mean(y_acquired)) / torch.std(y_acquired)\n",
    "# # y1 = (henry_y[ids_acquired] - torch.mean(henry_y[ids_acquired])) / torch.std(henry_y[ids_acquired])\n",
    "# # y2 = (gcmc_y[ids_acquired] - torch.mean(gcmc_y[ids_acquired])) / torch.std(gcmc_y[ids_acquired])\n",
    "\n",
    "# y1 = henry_y[ids_acquired]\n",
    "# y2 = gcmc_y[ids_acquired]\n",
    "# train_y = torch.stack([y1, y2], -1)\n",
    "# train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a4d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x = X[ids_acquired, :]\n",
    "# train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5607ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ConstantMean(), num_tasks=2\n",
    "        )\n",
    "        self.covar_module = gpytorch.kernels.MultitaskKernel(\n",
    "            gpytorch.kernels.RBFKernel(), num_tasks=2, rank=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "670ac134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultitaskGaussianLikelihood(\n",
       "  (raw_task_noises_constraint): GreaterThan(1.000E-04)\n",
       "  (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\n",
    "likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2b76526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultitaskGPModel(\n",
       "  (likelihood): MultitaskGaussianLikelihood(\n",
       "    (raw_task_noises_constraint): GreaterThan(1.000E-04)\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       "  (mean_module): MultitaskMean(\n",
       "    (base_means): ModuleList(\n",
       "      (0): ConstantMean()\n",
       "      (1): ConstantMean()\n",
       "    )\n",
       "  )\n",
       "  (covar_module): MultitaskKernel(\n",
       "    (task_covar_module): IndexKernel(\n",
       "      (raw_var_constraint): Positive()\n",
       "    )\n",
       "    (data_covar_module): RBFKernel(\n",
       "      (raw_lengthscale_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultitaskGPModel(train_x, train_y, likelihood)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8407b38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultitaskGPModel(\n",
       "  (likelihood): MultitaskGaussianLikelihood(\n",
       "    (raw_task_noises_constraint): GreaterThan(1.000E-04)\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       "  (mean_module): MultitaskMean(\n",
       "    (base_means): ModuleList(\n",
       "      (0): ConstantMean()\n",
       "      (1): ConstantMean()\n",
       "    )\n",
       "  )\n",
       "  (covar_module): MultitaskKernel(\n",
       "    (task_covar_module): IndexKernel(\n",
       "      (raw_var_constraint): Positive()\n",
       "    )\n",
       "    (data_covar_module): RBFKernel(\n",
       "      (raw_lengthscale_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoke_test = ('CI' in os.environ)\n",
    "training_iterations = 2 if smoke_test else 50\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7449708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultitaskGaussianLikelihood(\n",
       "  (raw_task_noises_constraint): GreaterThan(1.000E-04)\n",
       "  (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97c91a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExactMarginalLogLikelihood(\n",
       "  (likelihood): MultitaskGaussianLikelihood(\n",
       "    (raw_task_noises_constraint): GreaterThan(1.000E-04)\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       "  (model): MultitaskGPModel(\n",
       "    (likelihood): MultitaskGaussianLikelihood(\n",
       "      (raw_task_noises_constraint): GreaterThan(1.000E-04)\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "    (mean_module): MultitaskMean(\n",
       "      (base_means): ModuleList(\n",
       "        (0): ConstantMean()\n",
       "        (1): ConstantMean()\n",
       "      )\n",
       "    )\n",
       "    (covar_module): MultitaskKernel(\n",
       "      (task_covar_module): IndexKernel(\n",
       "        (raw_var_constraint): Positive()\n",
       "      )\n",
       "      (data_covar_module): RBFKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "mll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "504e2d33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50 - Loss: 2.406\n",
      "Iter 2/50 - Loss: 2.350\n",
      "Iter 3/50 - Loss: 2.302\n",
      "Iter 4/50 - Loss: 2.261\n",
      "Iter 5/50 - Loss: 2.227\n",
      "Iter 6/50 - Loss: 2.198\n",
      "Iter 7/50 - Loss: 2.175\n",
      "Iter 8/50 - Loss: 2.156\n",
      "Iter 9/50 - Loss: 2.141\n",
      "Iter 10/50 - Loss: 2.128\n",
      "Iter 11/50 - Loss: 2.118\n",
      "Iter 12/50 - Loss: 2.109\n",
      "Iter 13/50 - Loss: 2.102\n",
      "Iter 14/50 - Loss: 2.096\n",
      "Iter 15/50 - Loss: 2.091\n",
      "Iter 16/50 - Loss: 2.086\n",
      "Iter 17/50 - Loss: 2.083\n",
      "Iter 18/50 - Loss: 2.081\n",
      "Iter 19/50 - Loss: 2.079\n",
      "Iter 20/50 - Loss: 2.077\n",
      "Iter 21/50 - Loss: 2.076\n",
      "Iter 22/50 - Loss: 2.075\n",
      "Iter 23/50 - Loss: 2.074\n",
      "Iter 24/50 - Loss: 2.074\n",
      "Iter 25/50 - Loss: 2.073\n",
      "Iter 26/50 - Loss: 2.073\n",
      "Iter 27/50 - Loss: 2.073\n",
      "Iter 28/50 - Loss: 2.072\n",
      "Iter 29/50 - Loss: 2.072\n",
      "Iter 30/50 - Loss: 2.072\n",
      "Iter 31/50 - Loss: 2.071\n",
      "Iter 32/50 - Loss: 2.070\n",
      "Iter 33/50 - Loss: 2.069\n",
      "Iter 34/50 - Loss: 2.068\n",
      "Iter 35/50 - Loss: 2.068\n",
      "Iter 36/50 - Loss: 2.067\n",
      "Iter 37/50 - Loss: 2.066\n",
      "Iter 38/50 - Loss: 2.066\n",
      "Iter 39/50 - Loss: 2.065\n",
      "Iter 40/50 - Loss: 2.065\n",
      "Iter 41/50 - Loss: 2.064\n",
      "Iter 42/50 - Loss: 2.064\n",
      "Iter 43/50 - Loss: 2.063\n",
      "Iter 44/50 - Loss: 2.062\n",
      "Iter 45/50 - Loss: 2.062\n",
      "Iter 46/50 - Loss: 2.062\n",
      "Iter 47/50 - Loss: 2.062\n",
      "Iter 48/50 - Loss: 2.061\n",
      "Iter 49/50 - Loss: 2.061\n",
      "Iter 50/50 - Loss: 2.060\n"
     ]
    }
   ],
   "source": [
    "for i in range(training_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_x)\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8efd44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
